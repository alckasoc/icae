  0%|                                                                          | 0/20 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
 10%|██████▌                                                           | 2/20 [00:00<00:06,  2.89it/s]
{'loss': 4.625, 'grad_norm': 1.1667596101760864, 'learning_rate': 4.75e-05, 'epoch': 1.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.5938, 'grad_norm': 1.1689269542694092, 'learning_rate': 4.5e-05, 'epoch': 2.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.5625, 'grad_norm': 1.1811084747314453, 'learning_rate': 4.25e-05, 'epoch': 3.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.5312, 'grad_norm': 1.2240726947784424, 'learning_rate': 4e-05, 'epoch': 4.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.4688, 'grad_norm': 1.2899748086929321, 'learning_rate': 3.7500000000000003e-05, 'epoch': 5.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.4375, 'grad_norm': 1.2794206142425537, 'learning_rate': 3.5e-05, 'epoch': 6.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.375, 'grad_norm': 1.2789314985275269, 'learning_rate': 3.2500000000000004e-05, 'epoch': 7.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.3438, 'grad_norm': 1.2720011472702026, 'learning_rate': 3e-05, 'epoch': 8.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.3125, 'grad_norm': 1.229209303855896, 'learning_rate': 2.7500000000000004e-05, 'epoch': 9.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.25, 'grad_norm': 1.1807959079742432, 'learning_rate': 2.5e-05, 'epoch': 10.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.2188, 'grad_norm': 1.1429513692855835, 'learning_rate': 2.25e-05, 'epoch': 11.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.1875, 'grad_norm': 1.1743018627166748, 'learning_rate': 2e-05, 'epoch': 12.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.1562, 'grad_norm': 1.1577494144439697, 'learning_rate': 1.75e-05, 'epoch': 13.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.125, 'grad_norm': 1.1653856039047241, 'learning_rate': 1.5e-05, 'epoch': 14.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.0938, 'grad_norm': 1.1921207904815674, 'learning_rate': 1.25e-05, 'epoch': 15.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.0625, 'grad_norm': 1.1897574663162231, 'learning_rate': 1e-05, 'epoch': 16.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.0625, 'grad_norm': 1.2073003053665161, 'learning_rate': 7.5e-06, 'epoch': 17.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.0625, 'grad_norm': 1.2030709981918335, 'learning_rate': 5e-06, 'epoch': 18.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.0312, 'grad_norm': 1.2210081815719604, 'learning_rate': 2.5e-06, 'epoch': 19.0}
input_ids shape:  torch.Size([1, 8])
prompt_answer_ids shape:  torch.Size([1, 269])
labels shape:  torch.Size([1, 269])
num_segments:  1
segment_length:  8
prompt_answer_embs shape:  torch.Size([1, 269, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 8
segment_input_ids shape:  torch.Size([1, 8])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 136])
mem_flag shape:  torch.Size([1, 136])
segment_input_embedding shape:  torch.Size([1, 136, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 136, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 269])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 269, 128256])
effective_logits shape:  torch.Size([268, 128256])
target_ids shape:  torch.Size([268])
{'loss': 4.0312, 'grad_norm': 1.2092968225479126, 'learning_rate': 0.0, 'epoch': 20.0}
{'train_runtime': 4.4261, 'train_samples_per_second': 4.519, 'train_steps_per_second': 4.519, 'train_loss': 4.2765625, 'epoch': 20.0}
***** train metrics *****
  epoch                    =       20.0
  total_flos               =        0GF
  train_loss               =     4.2766
  train_runtime            = 0:00:04.42
  train_samples_per_second =      4.519
  train_steps_per_second   =      4.519
input_ids shape:  torch.Size([1, 96])
prompt_answer_ids shape:  torch.Size([1, 226])
labels shape:  torch.Size([1, 226])
num_segments:  1
segment_length:  96
prompt_answer_embs shape:  torch.Size([1, 226, 2048])
max_compressed_length:  128
compress_outputs shape:  torch.Size([128, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 96
segment_input_ids shape:  torch.Size([1, 96])
append_sequence shape:
segment_input_ids shape after concat:  torch.Size([1, 224])
mem_flag shape:  torch.Size([1, 224])
segment_input_embedding shape:  torch.Size([1, 224, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 224, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 226])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 226, 128388])
effective_logits shape:  torch.Size([225, 128388])
target_ids shape:  torch.Size([225])
100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2235.77it/s]
***** eval metrics *****
  epoch                   =       20.0
  eval_loss               =     3.6562
  eval_runtime            = 0:00:00.15
  eval_samples_per_second =      6.521
  eval_steps_per_second   =      6.521
Finished training...
