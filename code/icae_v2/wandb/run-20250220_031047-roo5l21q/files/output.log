Loaded from the checkpoint: None
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|                                                                                                                                                                                    | 0/20 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                                                          | 2/20 [00:01<00:09,  1.98it/s]
{'loss': 1.5781, 'grad_norm': 0.05697740986943245, 'learning_rate': 4.75e-05, 'epoch': 1.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5703, 'grad_norm': 0.05707069858908653, 'learning_rate': 4.5e-05, 'epoch': 2.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5703, 'grad_norm': 0.05682834982872009, 'learning_rate': 4.25e-05, 'epoch': 3.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5703, 'grad_norm': 0.05761471763253212, 'learning_rate': 4e-05, 'epoch': 4.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5703, 'grad_norm': 0.05752718076109886, 'learning_rate': 3.7500000000000003e-05, 'epoch': 5.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5703, 'grad_norm': 0.057871587574481964, 'learning_rate': 3.5e-05, 'epoch': 6.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.0583532340824604, 'learning_rate': 3.2500000000000004e-05, 'epoch': 7.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5703, 'grad_norm': 0.05922135338187218, 'learning_rate': 3e-05, 'epoch': 8.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.05922336131334305, 'learning_rate': 2.7500000000000004e-05, 'epoch': 9.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.05955787003040314, 'learning_rate': 2.5e-05, 'epoch': 10.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.0601646713912487, 'learning_rate': 2.25e-05, 'epoch': 11.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5547, 'grad_norm': 0.06027452275156975, 'learning_rate': 2e-05, 'epoch': 12.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.06085488572716713, 'learning_rate': 1.75e-05, 'epoch': 13.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.061454832553863525, 'learning_rate': 1.5e-05, 'epoch': 14.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.06208832189440727, 'learning_rate': 1.25e-05, 'epoch': 15.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.06210355833172798, 'learning_rate': 1e-05, 'epoch': 16.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5547, 'grad_norm': 0.06278117001056671, 'learning_rate': 7.5e-06, 'epoch': 17.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.06301083415746689, 'learning_rate': 5e-06, 'epoch': 18.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5547, 'grad_norm': 0.06265541911125183, 'learning_rate': 2.5e-06, 'epoch': 19.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.0633685439825058, 'learning_rate': 0.0, 'epoch': 20.0}
{'train_runtime': 5.2586, 'train_samples_per_second': 3.803, 'train_steps_per_second': 3.803, 'train_loss': 1.564453125, 'epoch': 20.0}
***** train metrics *****
  epoch                    =       20.0
  total_flos               =        0GF
  train_loss               =     1.5645
  train_runtime            = 0:00:05.25
  train_samples_per_second =      3.803
  train_steps_per_second   =      3.803
input_ids shape:  torch.Size([1, 131])
prompt_answer_ids shape:  torch.Size([1, 85])
labels shape:  torch.Size([1, 85])
num_segments:  1
segment_length:  131
prompt_answer_embs shape:  torch.Size([1, 85, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 131
segment_input_ids shape:  torch.Size([1, 131])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 132])
mem_flag shape:  torch.Size([1, 132])
segment_input_embedding shape:  torch.Size([1, 132, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 132, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 85])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 85, 128261])
effective_logits shape:  torch.Size([84, 128261])
target_ids shape:  torch.Size([84])
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1081.84it/s]
***** eval metrics *****
  epoch                   =       20.0
  eval_loss               =     2.3906
  eval_runtime            = 0:00:00.10
  eval_samples_per_second =      9.496
  eval_steps_per_second   =      9.496
Freezing the decoder...
trainable params: 13639680 || all params: 2485278720 || trainable%: 0.5488189268365039
Enabling gradient checkpointing...
Loading trained checkpoint from ./output
Running inference
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.77s/it]
=========================== START ============================
Current line:  Four adults with 32 teeth went to the dentist for a checkup after realizing they were having severe tooth pain. They were found to have different numbers of damaged teeth, and each person had some teeth removed. The first person had 1/4 of all his teeth removed, and the second person had 3/8 of his teeth removed, the third person had half of his teeth removed, while the last person only had 4 teeth removed. What's the total number of teeth removed at the dental clinic?
input_ids shape:  torch.Size([1, 105])
memory_slots shape:  torch.Size([1, 2048])
prompt_ids shape:  torch.Size([1, 1])
prompt_answer_embs shape:  torch.Size([1, 1, 2048])
decoder_input_embeddings shape:  torch.Size([1, 2, 2048])
output shape:  torch.Size([1, 2, 2048])
=========================== END ============================
Four adults with 32 teeth went to the dentist for a checkup after realizing they were having severe tooth pain. They were found to have different numbers of damaged teeth, and each person had some teeth removed. The first person had 1/4 of all his teeth removed, and the second person had 3/8 of his teeth removed, the third person had half of his teeth removed, while the last person only had 4 teeth removed. What's the total number of teeth removed at the dental clinic?
 Bi-U-U-A-A-A-A-A-A-A-A-A-A-A-A-A-A a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a 1- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a- a-
=========================================================================
