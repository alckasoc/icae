Loaded from the checkpoint: None
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|                                                                                                                                                                                  | 0/2000 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
  0%|▏                                                                                                                                                                         | 2/2000 [00:00<11:23,  2.93it/s]
{'loss': 1.5859, 'grad_norm': 0.05580689758062363, 'learning_rate': 4.9975e-05, 'epoch': 1.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5938, 'grad_norm': 0.056054845452308655, 'learning_rate': 4.995e-05, 'epoch': 2.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5859, 'grad_norm': 0.056545618921518326, 'learning_rate': 4.992500000000001e-05, 'epoch': 3.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5859, 'grad_norm': 0.05731253698468208, 'learning_rate': 4.99e-05, 'epoch': 4.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5859, 'grad_norm': 0.05715198442339897, 'learning_rate': 4.9875000000000006e-05, 'epoch': 5.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5781, 'grad_norm': 0.05816233158111572, 'learning_rate': 4.9850000000000006e-05, 'epoch': 6.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5781, 'grad_norm': 0.0589875653386116, 'learning_rate': 4.9825000000000005e-05, 'epoch': 7.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5781, 'grad_norm': 0.059511080384254456, 'learning_rate': 4.9800000000000004e-05, 'epoch': 8.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5781, 'grad_norm': 0.060160212218761444, 'learning_rate': 4.9775000000000004e-05, 'epoch': 9.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5703, 'grad_norm': 0.06079358980059624, 'learning_rate': 4.975e-05, 'epoch': 10.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5703, 'grad_norm': 0.062054675072431564, 'learning_rate': 4.9725e-05, 'epoch': 11.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.06315163522958755, 'learning_rate': 4.97e-05, 'epoch': 12.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.06375745683908463, 'learning_rate': 4.967500000000001e-05, 'epoch': 13.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.06513673067092896, 'learning_rate': 4.965e-05, 'epoch': 14.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5625, 'grad_norm': 0.06611700356006622, 'learning_rate': 4.962500000000001e-05, 'epoch': 15.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5547, 'grad_norm': 0.06757383048534393, 'learning_rate': 4.96e-05, 'epoch': 16.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5547, 'grad_norm': 0.06921885162591934, 'learning_rate': 4.9575000000000006e-05, 'epoch': 17.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5469, 'grad_norm': 0.07107837498188019, 'learning_rate': 4.9550000000000005e-05, 'epoch': 18.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5469, 'grad_norm': 0.07294490933418274, 'learning_rate': 4.9525000000000004e-05, 'epoch': 19.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5391, 'grad_norm': 0.07518861442804337, 'learning_rate': 4.9500000000000004e-05, 'epoch': 20.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5391, 'grad_norm': 0.07806336134672165, 'learning_rate': 4.9475e-05, 'epoch': 21.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5312, 'grad_norm': 0.08148651570081711, 'learning_rate': 4.945e-05, 'epoch': 22.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5234, 'grad_norm': 0.08492521196603775, 'learning_rate': 4.9425e-05, 'epoch': 23.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5156, 'grad_norm': 0.09048633277416229, 'learning_rate': 4.94e-05, 'epoch': 24.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5078, 'grad_norm': 0.0963687151670456, 'learning_rate': 4.937500000000001e-05, 'epoch': 25.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5078, 'grad_norm': 0.10116185992956161, 'learning_rate': 4.935e-05, 'epoch': 26.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.5, 'grad_norm': 0.11000515520572662, 'learning_rate': 4.9325000000000006e-05, 'epoch': 27.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.4922, 'grad_norm': 0.11976160109043121, 'learning_rate': 4.93e-05, 'epoch': 28.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.4766, 'grad_norm': 0.1295931488275528, 'learning_rate': 4.9275000000000005e-05, 'epoch': 29.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.4688, 'grad_norm': 0.14046627283096313, 'learning_rate': 4.9250000000000004e-05, 'epoch': 30.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.4609, 'grad_norm': 0.1483861654996872, 'learning_rate': 4.9225000000000004e-05, 'epoch': 31.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.4453, 'grad_norm': 0.1511821299791336, 'learning_rate': 4.92e-05, 'epoch': 32.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.4375, 'grad_norm': 0.14655765891075134, 'learning_rate': 4.9175e-05, 'epoch': 33.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.4219, 'grad_norm': 0.1420338898897171, 'learning_rate': 4.915e-05, 'epoch': 34.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.4141, 'grad_norm': 0.13914473354816437, 'learning_rate': 4.9125e-05, 'epoch': 35.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.3984, 'grad_norm': 0.14092221856117249, 'learning_rate': 4.91e-05, 'epoch': 36.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.3906, 'grad_norm': 0.1475083976984024, 'learning_rate': 4.907500000000001e-05, 'epoch': 37.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.3828, 'grad_norm': 0.15760628879070282, 'learning_rate': 4.905e-05, 'epoch': 38.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.3672, 'grad_norm': 0.16990596055984497, 'learning_rate': 4.9025000000000006e-05, 'epoch': 39.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.3594, 'grad_norm': 0.18339186906814575, 'learning_rate': 4.9e-05, 'epoch': 40.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.3438, 'grad_norm': 0.1961871087551117, 'learning_rate': 4.8975000000000005e-05, 'epoch': 41.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.3281, 'grad_norm': 0.213517963886261, 'learning_rate': 4.8950000000000004e-05, 'epoch': 42.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.3125, 'grad_norm': 0.22593292593955994, 'learning_rate': 4.8925e-05, 'epoch': 43.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.2969, 'grad_norm': 0.23933424055576324, 'learning_rate': 4.89e-05, 'epoch': 44.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.2812, 'grad_norm': 0.24895000457763672, 'learning_rate': 4.8875e-05, 'epoch': 45.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.2656, 'grad_norm': 0.25970765948295593, 'learning_rate': 4.885e-05, 'epoch': 46.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.2422, 'grad_norm': 0.2681232690811157, 'learning_rate': 4.8825e-05, 'epoch': 47.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.2188, 'grad_norm': 0.2798566222190857, 'learning_rate': 4.88e-05, 'epoch': 48.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.2031, 'grad_norm': 0.29082581400871277, 'learning_rate': 4.8775000000000007e-05, 'epoch': 49.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.1797, 'grad_norm': 0.3017536699771881, 'learning_rate': 4.875e-05, 'epoch': 50.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.1562, 'grad_norm': 0.3162313401699066, 'learning_rate': 4.8725000000000005e-05, 'epoch': 51.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.1328, 'grad_norm': 0.3301430344581604, 'learning_rate': 4.87e-05, 'epoch': 52.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.1094, 'grad_norm': 0.34440821409225464, 'learning_rate': 4.8675000000000004e-05, 'epoch': 53.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.0859, 'grad_norm': 0.3548966944217682, 'learning_rate': 4.8650000000000003e-05, 'epoch': 54.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.0625, 'grad_norm': 0.3628104627132416, 'learning_rate': 4.8625e-05, 'epoch': 55.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.0391, 'grad_norm': 0.37155914306640625, 'learning_rate': 4.86e-05, 'epoch': 56.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 1.0078, 'grad_norm': 0.3798760175704956, 'learning_rate': 4.8575e-05, 'epoch': 57.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.9844, 'grad_norm': 0.39272814989089966, 'learning_rate': 4.855e-05, 'epoch': 58.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.9609, 'grad_norm': 0.4011864960193634, 'learning_rate': 4.8525e-05, 'epoch': 59.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.9258, 'grad_norm': 0.4133915901184082, 'learning_rate': 4.85e-05, 'epoch': 60.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.8945, 'grad_norm': 0.43184614181518555, 'learning_rate': 4.8475000000000006e-05, 'epoch': 61.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.8711, 'grad_norm': 0.44481295347213745, 'learning_rate': 4.845e-05, 'epoch': 62.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.8398, 'grad_norm': 0.46648848056793213, 'learning_rate': 4.8425000000000005e-05, 'epoch': 63.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.8086, 'grad_norm': 0.49034932255744934, 'learning_rate': 4.8400000000000004e-05, 'epoch': 64.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.7773, 'grad_norm': 0.5183892846107483, 'learning_rate': 4.8375000000000004e-05, 'epoch': 65.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.7461, 'grad_norm': 0.5509219765663147, 'learning_rate': 4.835e-05, 'epoch': 66.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.7109, 'grad_norm': 0.5870217084884644, 'learning_rate': 4.8325e-05, 'epoch': 67.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.6719, 'grad_norm': 0.6212904453277588, 'learning_rate': 4.83e-05, 'epoch': 68.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.6367, 'grad_norm': 0.6216637492179871, 'learning_rate': 4.8275e-05, 'epoch': 69.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.6016, 'grad_norm': 0.9385212659835815, 'learning_rate': 4.825e-05, 'epoch': 70.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.5664, 'grad_norm': 0.7448463439941406, 'learning_rate': 4.822500000000001e-05, 'epoch': 71.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.5312, 'grad_norm': 0.639122724533081, 'learning_rate': 4.82e-05, 'epoch': 72.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.5, 'grad_norm': 0.6370888352394104, 'learning_rate': 4.8175000000000005e-05, 'epoch': 73.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.4688, 'grad_norm': 0.6493246555328369, 'learning_rate': 4.815e-05, 'epoch': 74.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.4355, 'grad_norm': 0.615082323551178, 'learning_rate': 4.8125000000000004e-05, 'epoch': 75.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.4082, 'grad_norm': 0.5923085808753967, 'learning_rate': 4.8100000000000004e-05, 'epoch': 76.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.3809, 'grad_norm': 0.6103308796882629, 'learning_rate': 4.8075e-05, 'epoch': 77.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.3594, 'grad_norm': 0.4998505711555481, 'learning_rate': 4.805e-05, 'epoch': 78.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.3418, 'grad_norm': 0.47207579016685486, 'learning_rate': 4.8025e-05, 'epoch': 79.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.3262, 'grad_norm': 0.4895203113555908, 'learning_rate': 4.8e-05, 'epoch': 80.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.3066, 'grad_norm': 0.42367464303970337, 'learning_rate': 4.7975e-05, 'epoch': 81.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.293, 'grad_norm': 0.43634966015815735, 'learning_rate': 4.795e-05, 'epoch': 82.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.2773, 'grad_norm': 0.39137622714042664, 'learning_rate': 4.7925000000000006e-05, 'epoch': 83.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.2637, 'grad_norm': 0.381803423166275, 'learning_rate': 4.79e-05, 'epoch': 84.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.252, 'grad_norm': 0.37118491530418396, 'learning_rate': 4.7875000000000005e-05, 'epoch': 85.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.2393, 'grad_norm': 0.41938427090644836, 'learning_rate': 4.785e-05, 'epoch': 86.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.2275, 'grad_norm': 0.36127132177352905, 'learning_rate': 4.7825000000000004e-05, 'epoch': 87.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.2158, 'grad_norm': 0.38751161098480225, 'learning_rate': 4.78e-05, 'epoch': 88.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.2041, 'grad_norm': 0.4141117334365845, 'learning_rate': 4.7775e-05, 'epoch': 89.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1953, 'grad_norm': 0.29012489318847656, 'learning_rate': 4.775e-05, 'epoch': 90.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1875, 'grad_norm': 0.3984948396682739, 'learning_rate': 4.7725e-05, 'epoch': 91.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1787, 'grad_norm': 0.34569528698921204, 'learning_rate': 4.77e-05, 'epoch': 92.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1709, 'grad_norm': 0.27578675746917725, 'learning_rate': 4.7675e-05, 'epoch': 93.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.168, 'grad_norm': 1.1315122842788696, 'learning_rate': 4.765e-05, 'epoch': 94.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1611, 'grad_norm': 0.27615925669670105, 'learning_rate': 4.7625000000000006e-05, 'epoch': 95.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1592, 'grad_norm': 0.4241078495979309, 'learning_rate': 4.76e-05, 'epoch': 96.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1562, 'grad_norm': 0.303114116191864, 'learning_rate': 4.7575000000000004e-05, 'epoch': 97.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1514, 'grad_norm': 0.14429639279842377, 'learning_rate': 4.755e-05, 'epoch': 98.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1514, 'grad_norm': 0.27340489625930786, 'learning_rate': 4.7525e-05, 'epoch': 99.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1504, 'grad_norm': 0.26837512850761414, 'learning_rate': 4.75e-05, 'epoch': 100.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1484, 'grad_norm': 0.16712114214897156, 'learning_rate': 4.7475e-05, 'epoch': 101.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1465, 'grad_norm': 0.12987485527992249, 'learning_rate': 4.745e-05, 'epoch': 102.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1455, 'grad_norm': 0.13388337194919586, 'learning_rate': 4.7425e-05, 'epoch': 103.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1445, 'grad_norm': 0.16282565891742706, 'learning_rate': 4.74e-05, 'epoch': 104.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1445, 'grad_norm': 0.19385714828968048, 'learning_rate': 4.7375e-05, 'epoch': 105.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1426, 'grad_norm': 0.10446639358997345, 'learning_rate': 4.735e-05, 'epoch': 106.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1416, 'grad_norm': 0.06563252210617065, 'learning_rate': 4.7325000000000005e-05, 'epoch': 107.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1416, 'grad_norm': 0.06434094160795212, 'learning_rate': 4.73e-05, 'epoch': 108.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1406, 'grad_norm': 0.14941471815109253, 'learning_rate': 4.7275000000000004e-05, 'epoch': 109.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1406, 'grad_norm': 0.1280532032251358, 'learning_rate': 4.7249999999999997e-05, 'epoch': 110.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1406, 'grad_norm': 0.10788150876760483, 'learning_rate': 4.7225e-05, 'epoch': 111.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1387, 'grad_norm': 0.07214539498090744, 'learning_rate': 4.72e-05, 'epoch': 112.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1387, 'grad_norm': 0.04874465614557266, 'learning_rate': 4.7175e-05, 'epoch': 113.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1387, 'grad_norm': 0.08456539362668991, 'learning_rate': 4.715e-05, 'epoch': 114.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1387, 'grad_norm': 0.10194505006074905, 'learning_rate': 4.7125e-05, 'epoch': 115.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1387, 'grad_norm': 0.07051462680101395, 'learning_rate': 4.71e-05, 'epoch': 116.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1377, 'grad_norm': 0.07473012059926987, 'learning_rate': 4.7075e-05, 'epoch': 117.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1377, 'grad_norm': 0.06095350161194801, 'learning_rate': 4.705e-05, 'epoch': 118.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1367, 'grad_norm': 0.04288053140044212, 'learning_rate': 4.7025000000000005e-05, 'epoch': 119.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1367, 'grad_norm': 0.038161758333444595, 'learning_rate': 4.7e-05, 'epoch': 120.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1367, 'grad_norm': 0.05265789479017258, 'learning_rate': 4.6975000000000003e-05, 'epoch': 121.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1367, 'grad_norm': 0.04736786335706711, 'learning_rate': 4.695e-05, 'epoch': 122.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1357, 'grad_norm': 0.07489180564880371, 'learning_rate': 4.6925e-05, 'epoch': 123.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1357, 'grad_norm': 0.03761620447039604, 'learning_rate': 4.69e-05, 'epoch': 124.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1357, 'grad_norm': 0.0370146743953228, 'learning_rate': 4.6875e-05, 'epoch': 125.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1357, 'grad_norm': 0.03369148075580597, 'learning_rate': 4.685000000000001e-05, 'epoch': 126.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1357, 'grad_norm': 0.03338911756873131, 'learning_rate': 4.6825e-05, 'epoch': 127.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1348, 'grad_norm': 0.03321332111954689, 'learning_rate': 4.6800000000000006e-05, 'epoch': 128.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1348, 'grad_norm': 0.032750748097896576, 'learning_rate': 4.6775000000000005e-05, 'epoch': 129.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1348, 'grad_norm': 0.03548867255449295, 'learning_rate': 4.6750000000000005e-05, 'epoch': 130.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1338, 'grad_norm': 0.03171529620885849, 'learning_rate': 4.6725000000000004e-05, 'epoch': 131.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1338, 'grad_norm': 0.03205744922161102, 'learning_rate': 4.6700000000000003e-05, 'epoch': 132.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1338, 'grad_norm': 0.03609408810734749, 'learning_rate': 4.6675e-05, 'epoch': 133.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1338, 'grad_norm': 0.034216780215501785, 'learning_rate': 4.665e-05, 'epoch': 134.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1338, 'grad_norm': 0.03424632549285889, 'learning_rate': 4.6625e-05, 'epoch': 135.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1338, 'grad_norm': 0.032282277941703796, 'learning_rate': 4.660000000000001e-05, 'epoch': 136.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1338, 'grad_norm': 0.032356224954128265, 'learning_rate': 4.6575e-05, 'epoch': 137.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1328, 'grad_norm': 0.030194375663995743, 'learning_rate': 4.655000000000001e-05, 'epoch': 138.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1328, 'grad_norm': 0.034255873411893845, 'learning_rate': 4.6525e-05, 'epoch': 139.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1318, 'grad_norm': 0.03147133067250252, 'learning_rate': 4.6500000000000005e-05, 'epoch': 140.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1328, 'grad_norm': 0.0316755510866642, 'learning_rate': 4.6475000000000005e-05, 'epoch': 141.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1318, 'grad_norm': 0.030228856950998306, 'learning_rate': 4.6450000000000004e-05, 'epoch': 142.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1318, 'grad_norm': 0.030407218262553215, 'learning_rate': 4.6425000000000004e-05, 'epoch': 143.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1318, 'grad_norm': 0.030788887292146683, 'learning_rate': 4.64e-05, 'epoch': 144.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1318, 'grad_norm': 0.030729152262210846, 'learning_rate': 4.6375e-05, 'epoch': 145.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1309, 'grad_norm': 0.031163077801465988, 'learning_rate': 4.635e-05, 'epoch': 146.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1309, 'grad_norm': 0.03088994137942791, 'learning_rate': 4.6325e-05, 'epoch': 147.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1309, 'grad_norm': 0.03089248202741146, 'learning_rate': 4.630000000000001e-05, 'epoch': 148.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1309, 'grad_norm': 0.031086506322026253, 'learning_rate': 4.6275e-05, 'epoch': 149.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1309, 'grad_norm': 0.03075007162988186, 'learning_rate': 4.6250000000000006e-05, 'epoch': 150.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1299, 'grad_norm': 0.033064138144254684, 'learning_rate': 4.6225e-05, 'epoch': 151.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1299, 'grad_norm': 0.030718743801116943, 'learning_rate': 4.6200000000000005e-05, 'epoch': 152.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1299, 'grad_norm': 0.030919741839170456, 'learning_rate': 4.6175000000000004e-05, 'epoch': 153.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1299, 'grad_norm': 0.03292085975408554, 'learning_rate': 4.6150000000000004e-05, 'epoch': 154.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1289, 'grad_norm': 0.041508715599775314, 'learning_rate': 4.6125e-05, 'epoch': 155.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1289, 'grad_norm': 0.03415583819150925, 'learning_rate': 4.61e-05, 'epoch': 156.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1289, 'grad_norm': 0.03157505765557289, 'learning_rate': 4.6075e-05, 'epoch': 157.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1289, 'grad_norm': 0.031846288591623306, 'learning_rate': 4.605e-05, 'epoch': 158.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1289, 'grad_norm': 0.04208957776427269, 'learning_rate': 4.6025e-05, 'epoch': 159.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1279, 'grad_norm': 0.049571700394153595, 'learning_rate': 4.600000000000001e-05, 'epoch': 160.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1289, 'grad_norm': 0.03802889212965965, 'learning_rate': 4.5975e-05, 'epoch': 161.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1279, 'grad_norm': 0.03441336378455162, 'learning_rate': 4.5950000000000006e-05, 'epoch': 162.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1279, 'grad_norm': 0.03396333381533623, 'learning_rate': 4.5925e-05, 'epoch': 163.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1279, 'grad_norm': 0.032836899161338806, 'learning_rate': 4.5900000000000004e-05, 'epoch': 164.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1279, 'grad_norm': 0.034040454775094986, 'learning_rate': 4.5875000000000004e-05, 'epoch': 165.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.127, 'grad_norm': 0.03589077666401863, 'learning_rate': 4.585e-05, 'epoch': 166.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.127, 'grad_norm': 0.039424680173397064, 'learning_rate': 4.5825e-05, 'epoch': 167.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.127, 'grad_norm': 0.04592438042163849, 'learning_rate': 4.58e-05, 'epoch': 168.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.127, 'grad_norm': 0.03582068532705307, 'learning_rate': 4.5775e-05, 'epoch': 169.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.127, 'grad_norm': 0.03874044492840767, 'learning_rate': 4.575e-05, 'epoch': 170.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.126, 'grad_norm': 0.03372303023934364, 'learning_rate': 4.5725e-05, 'epoch': 171.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.126, 'grad_norm': 0.040804050862789154, 'learning_rate': 4.5700000000000006e-05, 'epoch': 172.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.126, 'grad_norm': 0.03583511337637901, 'learning_rate': 4.5675e-05, 'epoch': 173.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.125, 'grad_norm': 0.034378550946712494, 'learning_rate': 4.5650000000000005e-05, 'epoch': 174.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.125, 'grad_norm': 0.04003472253680229, 'learning_rate': 4.5625e-05, 'epoch': 175.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1245, 'grad_norm': 0.03720569983124733, 'learning_rate': 4.5600000000000004e-05, 'epoch': 176.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1245, 'grad_norm': 0.05676357448101044, 'learning_rate': 4.5575e-05, 'epoch': 177.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.124, 'grad_norm': 0.035006217658519745, 'learning_rate': 4.555e-05, 'epoch': 178.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.124, 'grad_norm': 0.035620324313640594, 'learning_rate': 4.5525e-05, 'epoch': 179.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1235, 'grad_norm': 0.03717032074928284, 'learning_rate': 4.55e-05, 'epoch': 180.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1235, 'grad_norm': 0.06758060306310654, 'learning_rate': 4.5475e-05, 'epoch': 181.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1235, 'grad_norm': 0.03784900903701782, 'learning_rate': 4.545000000000001e-05, 'epoch': 182.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1226, 'grad_norm': 0.03959168866276741, 'learning_rate': 4.5425e-05, 'epoch': 183.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1226, 'grad_norm': 0.04020633548498154, 'learning_rate': 4.5400000000000006e-05, 'epoch': 184.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1221, 'grad_norm': 0.037800293415784836, 'learning_rate': 4.5375e-05, 'epoch': 185.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1216, 'grad_norm': 0.037826456129550934, 'learning_rate': 4.5350000000000005e-05, 'epoch': 186.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1221, 'grad_norm': 0.03684428334236145, 'learning_rate': 4.5325000000000004e-05, 'epoch': 187.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1211, 'grad_norm': 0.03984004259109497, 'learning_rate': 4.53e-05, 'epoch': 188.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1211, 'grad_norm': 0.046147819608449936, 'learning_rate': 4.5275e-05, 'epoch': 189.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1211, 'grad_norm': 0.03808971866965294, 'learning_rate': 4.525e-05, 'epoch': 190.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1206, 'grad_norm': 0.03735591843724251, 'learning_rate': 4.5225e-05, 'epoch': 191.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1201, 'grad_norm': 0.03785446286201477, 'learning_rate': 4.52e-05, 'epoch': 192.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1201, 'grad_norm': 0.03795524314045906, 'learning_rate': 4.5175e-05, 'epoch': 193.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1196, 'grad_norm': 0.03968930244445801, 'learning_rate': 4.5150000000000006e-05, 'epoch': 194.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1191, 'grad_norm': 0.03753736987709999, 'learning_rate': 4.5125e-05, 'epoch': 195.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1187, 'grad_norm': 0.03882252052426338, 'learning_rate': 4.5100000000000005e-05, 'epoch': 196.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1187, 'grad_norm': 0.07826772332191467, 'learning_rate': 4.5075e-05, 'epoch': 197.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1182, 'grad_norm': 0.04169030115008354, 'learning_rate': 4.5050000000000004e-05, 'epoch': 198.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1182, 'grad_norm': 0.04505184665322304, 'learning_rate': 4.5025000000000003e-05, 'epoch': 199.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1177, 'grad_norm': 0.04884810373187065, 'learning_rate': 4.5e-05, 'epoch': 200.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1177, 'grad_norm': 0.06950260698795319, 'learning_rate': 4.4975e-05, 'epoch': 201.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1172, 'grad_norm': 0.04450628161430359, 'learning_rate': 4.495e-05, 'epoch': 202.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1167, 'grad_norm': 0.04027736932039261, 'learning_rate': 4.4925e-05, 'epoch': 203.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1162, 'grad_norm': 0.0435975156724453, 'learning_rate': 4.49e-05, 'epoch': 204.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1162, 'grad_norm': 0.05848437920212746, 'learning_rate': 4.4875e-05, 'epoch': 205.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1157, 'grad_norm': 0.04103340208530426, 'learning_rate': 4.4850000000000006e-05, 'epoch': 206.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1152, 'grad_norm': 0.04243968427181244, 'learning_rate': 4.4825e-05, 'epoch': 207.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1147, 'grad_norm': 0.04120984673500061, 'learning_rate': 4.4800000000000005e-05, 'epoch': 208.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1147, 'grad_norm': 0.04838128015398979, 'learning_rate': 4.4775e-05, 'epoch': 209.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1138, 'grad_norm': 0.04860338568687439, 'learning_rate': 4.4750000000000004e-05, 'epoch': 210.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1133, 'grad_norm': 0.04192892834544182, 'learning_rate': 4.4725e-05, 'epoch': 211.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1133, 'grad_norm': 0.04379645362496376, 'learning_rate': 4.47e-05, 'epoch': 212.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1128, 'grad_norm': 0.04228290915489197, 'learning_rate': 4.4675e-05, 'epoch': 213.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1123, 'grad_norm': 0.04461752250790596, 'learning_rate': 4.465e-05, 'epoch': 214.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1118, 'grad_norm': 0.04635373130440712, 'learning_rate': 4.4625e-05, 'epoch': 215.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1113, 'grad_norm': 0.06524480134248734, 'learning_rate': 4.46e-05, 'epoch': 216.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1108, 'grad_norm': 0.046614889055490494, 'learning_rate': 4.4575e-05, 'epoch': 217.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1104, 'grad_norm': 0.04771852120757103, 'learning_rate': 4.4550000000000005e-05, 'epoch': 218.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1099, 'grad_norm': 0.08865457773208618, 'learning_rate': 4.4525e-05, 'epoch': 219.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1099, 'grad_norm': 0.04435838758945465, 'learning_rate': 4.4500000000000004e-05, 'epoch': 220.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1094, 'grad_norm': 0.05009691044688225, 'learning_rate': 4.4475e-05, 'epoch': 221.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1089, 'grad_norm': 0.044122856110334396, 'learning_rate': 4.445e-05, 'epoch': 222.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1084, 'grad_norm': 0.0504046231508255, 'learning_rate': 4.4425e-05, 'epoch': 223.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1084, 'grad_norm': 0.048817913979291916, 'learning_rate': 4.44e-05, 'epoch': 224.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1074, 'grad_norm': 0.06045449525117874, 'learning_rate': 4.4375e-05, 'epoch': 225.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1069, 'grad_norm': 0.07628690451383591, 'learning_rate': 4.435e-05, 'epoch': 226.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1069, 'grad_norm': 0.049013152718544006, 'learning_rate': 4.4325e-05, 'epoch': 227.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.106, 'grad_norm': 0.046935420483350754, 'learning_rate': 4.43e-05, 'epoch': 228.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1055, 'grad_norm': 0.09727896004915237, 'learning_rate': 4.4275e-05, 'epoch': 229.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1045, 'grad_norm': 0.06998926401138306, 'learning_rate': 4.4250000000000005e-05, 'epoch': 230.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1045, 'grad_norm': 0.04956633970141411, 'learning_rate': 4.4225e-05, 'epoch': 231.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1035, 'grad_norm': 0.08128758519887924, 'learning_rate': 4.4200000000000004e-05, 'epoch': 232.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1035, 'grad_norm': 0.09418492764234543, 'learning_rate': 4.4174999999999996e-05, 'epoch': 233.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1035, 'grad_norm': 0.07389742881059647, 'learning_rate': 4.415e-05, 'epoch': 234.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1025, 'grad_norm': 0.11977848410606384, 'learning_rate': 4.4125e-05, 'epoch': 235.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1021, 'grad_norm': 0.055506136268377304, 'learning_rate': 4.41e-05, 'epoch': 236.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1016, 'grad_norm': 0.07290095090866089, 'learning_rate': 4.4075e-05, 'epoch': 237.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1006, 'grad_norm': 0.054147299379110336, 'learning_rate': 4.405e-05, 'epoch': 238.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1006, 'grad_norm': 0.053556639701128006, 'learning_rate': 4.4025e-05, 'epoch': 239.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0996, 'grad_norm': 0.06813201308250427, 'learning_rate': 4.4000000000000006e-05, 'epoch': 240.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0996, 'grad_norm': 0.0564853735268116, 'learning_rate': 4.3975e-05, 'epoch': 241.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0986, 'grad_norm': 0.05690617486834526, 'learning_rate': 4.3950000000000004e-05, 'epoch': 242.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0981, 'grad_norm': 0.048569366335868835, 'learning_rate': 4.3925e-05, 'epoch': 243.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0977, 'grad_norm': 0.05806361511349678, 'learning_rate': 4.39e-05, 'epoch': 244.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0977, 'grad_norm': 0.06650834530591965, 'learning_rate': 4.3875e-05, 'epoch': 245.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0967, 'grad_norm': 0.06750326603651047, 'learning_rate': 4.385e-05, 'epoch': 246.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0962, 'grad_norm': 0.05970584228634834, 'learning_rate': 4.3825e-05, 'epoch': 247.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0957, 'grad_norm': 0.12306775152683258, 'learning_rate': 4.38e-05, 'epoch': 248.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0947, 'grad_norm': 0.05101732537150383, 'learning_rate': 4.3775e-05, 'epoch': 249.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0942, 'grad_norm': 0.07278892397880554, 'learning_rate': 4.375e-05, 'epoch': 250.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0938, 'grad_norm': 0.08045046031475067, 'learning_rate': 4.3725000000000006e-05, 'epoch': 251.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0928, 'grad_norm': 0.050419408828020096, 'learning_rate': 4.3700000000000005e-05, 'epoch': 252.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0918, 'grad_norm': 0.0642148032784462, 'learning_rate': 4.3675000000000005e-05, 'epoch': 253.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0918, 'grad_norm': 0.08144133538007736, 'learning_rate': 4.3650000000000004e-05, 'epoch': 254.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0913, 'grad_norm': 0.04895766079425812, 'learning_rate': 4.3625e-05, 'epoch': 255.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0903, 'grad_norm': 0.04863731935620308, 'learning_rate': 4.36e-05, 'epoch': 256.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0908, 'grad_norm': 0.0589754693210125, 'learning_rate': 4.3575e-05, 'epoch': 257.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0894, 'grad_norm': 0.05952762812376022, 'learning_rate': 4.355e-05, 'epoch': 258.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0894, 'grad_norm': 0.07995740324258804, 'learning_rate': 4.352500000000001e-05, 'epoch': 259.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0884, 'grad_norm': 0.07592321187257767, 'learning_rate': 4.35e-05, 'epoch': 260.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0874, 'grad_norm': 0.09218887239694595, 'learning_rate': 4.3475000000000006e-05, 'epoch': 261.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0879, 'grad_norm': 0.09685257077217102, 'learning_rate': 4.345e-05, 'epoch': 262.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0864, 'grad_norm': 0.06822541356086731, 'learning_rate': 4.3425000000000005e-05, 'epoch': 263.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0859, 'grad_norm': 0.08197309076786041, 'learning_rate': 4.3400000000000005e-05, 'epoch': 264.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0854, 'grad_norm': 0.09435545653104782, 'learning_rate': 4.3375000000000004e-05, 'epoch': 265.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.085, 'grad_norm': 0.0595070943236351, 'learning_rate': 4.335e-05, 'epoch': 266.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.085, 'grad_norm': 0.09943436086177826, 'learning_rate': 4.3325e-05, 'epoch': 267.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0835, 'grad_norm': 0.0637679249048233, 'learning_rate': 4.33e-05, 'epoch': 268.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.083, 'grad_norm': 0.07422388345003128, 'learning_rate': 4.3275e-05, 'epoch': 269.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0825, 'grad_norm': 0.07646195590496063, 'learning_rate': 4.325e-05, 'epoch': 270.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0825, 'grad_norm': 0.0849347785115242, 'learning_rate': 4.322500000000001e-05, 'epoch': 271.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0815, 'grad_norm': 0.06290210783481598, 'learning_rate': 4.32e-05, 'epoch': 272.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0811, 'grad_norm': 0.09077892452478409, 'learning_rate': 4.3175000000000006e-05, 'epoch': 273.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0811, 'grad_norm': 0.09828626364469528, 'learning_rate': 4.315e-05, 'epoch': 274.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0806, 'grad_norm': 0.07877891510725021, 'learning_rate': 4.3125000000000005e-05, 'epoch': 275.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0791, 'grad_norm': 0.06861798465251923, 'learning_rate': 4.3100000000000004e-05, 'epoch': 276.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0791, 'grad_norm': 0.10652843117713928, 'learning_rate': 4.3075000000000003e-05, 'epoch': 277.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0786, 'grad_norm': 0.08723829686641693, 'learning_rate': 4.305e-05, 'epoch': 278.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0781, 'grad_norm': 0.0511762872338295, 'learning_rate': 4.3025e-05, 'epoch': 279.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0776, 'grad_norm': 0.07998509705066681, 'learning_rate': 4.3e-05, 'epoch': 280.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0771, 'grad_norm': 0.09822102636098862, 'learning_rate': 4.2975e-05, 'epoch': 281.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0771, 'grad_norm': 0.19656012952327728, 'learning_rate': 4.295e-05, 'epoch': 282.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0762, 'grad_norm': 0.08277392387390137, 'learning_rate': 4.2925000000000007e-05, 'epoch': 283.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0767, 'grad_norm': 0.42177772521972656, 'learning_rate': 4.29e-05, 'epoch': 284.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0752, 'grad_norm': 0.1152346059679985, 'learning_rate': 4.2875000000000005e-05, 'epoch': 285.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0767, 'grad_norm': 0.25855761766433716, 'learning_rate': 4.285e-05, 'epoch': 286.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0757, 'grad_norm': 0.11659328639507294, 'learning_rate': 4.2825000000000004e-05, 'epoch': 287.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0747, 'grad_norm': 0.06885086745023727, 'learning_rate': 4.2800000000000004e-05, 'epoch': 288.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0742, 'grad_norm': 0.10843116044998169, 'learning_rate': 4.2775e-05, 'epoch': 289.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0737, 'grad_norm': 0.0995355024933815, 'learning_rate': 4.275e-05, 'epoch': 290.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0732, 'grad_norm': 0.11391906440258026, 'learning_rate': 4.2725e-05, 'epoch': 291.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0732, 'grad_norm': 0.10552120953798294, 'learning_rate': 4.27e-05, 'epoch': 292.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0728, 'grad_norm': 0.0923420786857605, 'learning_rate': 4.2675e-05, 'epoch': 293.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0728, 'grad_norm': 0.07333142310380936, 'learning_rate': 4.265e-05, 'epoch': 294.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0718, 'grad_norm': 0.08758971095085144, 'learning_rate': 4.2625000000000006e-05, 'epoch': 295.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0718, 'grad_norm': 0.06662565469741821, 'learning_rate': 4.26e-05, 'epoch': 296.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0713, 'grad_norm': 0.07203148305416107, 'learning_rate': 4.2575000000000005e-05, 'epoch': 297.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0713, 'grad_norm': 0.07529337704181671, 'learning_rate': 4.2550000000000004e-05, 'epoch': 298.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0703, 'grad_norm': 0.060771528631448746, 'learning_rate': 4.2525000000000004e-05, 'epoch': 299.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0703, 'grad_norm': 0.0888923853635788, 'learning_rate': 4.25e-05, 'epoch': 300.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0698, 'grad_norm': 0.04532913863658905, 'learning_rate': 4.2475e-05, 'epoch': 301.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0698, 'grad_norm': 0.07648225128650665, 'learning_rate': 4.245e-05, 'epoch': 302.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0693, 'grad_norm': 0.07936812937259674, 'learning_rate': 4.2425e-05, 'epoch': 303.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0693, 'grad_norm': 0.06162853538990021, 'learning_rate': 4.24e-05, 'epoch': 304.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0693, 'grad_norm': 0.03911737725138664, 'learning_rate': 4.237500000000001e-05, 'epoch': 305.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0693, 'grad_norm': 0.06129981577396393, 'learning_rate': 4.235e-05, 'epoch': 306.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0688, 'grad_norm': 0.0995163843035698, 'learning_rate': 4.2325000000000006e-05, 'epoch': 307.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0684, 'grad_norm': 0.048097118735313416, 'learning_rate': 4.23e-05, 'epoch': 308.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0684, 'grad_norm': 0.04187069460749626, 'learning_rate': 4.2275000000000004e-05, 'epoch': 309.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0684, 'grad_norm': 0.09537874162197113, 'learning_rate': 4.2250000000000004e-05, 'epoch': 310.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0679, 'grad_norm': 0.05292458459734917, 'learning_rate': 4.2225e-05, 'epoch': 311.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0679, 'grad_norm': 0.06569139659404755, 'learning_rate': 4.22e-05, 'epoch': 312.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0679, 'grad_norm': 0.047179851680994034, 'learning_rate': 4.2175e-05, 'epoch': 313.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0674, 'grad_norm': 0.049355633556842804, 'learning_rate': 4.215e-05, 'epoch': 314.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0674, 'grad_norm': 0.07173895090818405, 'learning_rate': 4.2125e-05, 'epoch': 315.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0674, 'grad_norm': 0.040814515203237534, 'learning_rate': 4.21e-05, 'epoch': 316.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0669, 'grad_norm': 0.037682462483644485, 'learning_rate': 4.2075000000000006e-05, 'epoch': 317.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0669, 'grad_norm': 0.028128525242209435, 'learning_rate': 4.205e-05, 'epoch': 318.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0669, 'grad_norm': 0.026844635605812073, 'learning_rate': 4.2025000000000005e-05, 'epoch': 319.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0664, 'grad_norm': 0.14598989486694336, 'learning_rate': 4.2e-05, 'epoch': 320.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0664, 'grad_norm': 0.08349679410457611, 'learning_rate': 4.1975000000000004e-05, 'epoch': 321.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0664, 'grad_norm': 0.11563708633184433, 'learning_rate': 4.195e-05, 'epoch': 322.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0659, 'grad_norm': 0.041502464562654495, 'learning_rate': 4.1925e-05, 'epoch': 323.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0654, 'grad_norm': 0.0669272318482399, 'learning_rate': 4.19e-05, 'epoch': 324.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0659, 'grad_norm': 0.04298481345176697, 'learning_rate': 4.1875e-05, 'epoch': 325.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0659, 'grad_norm': 0.04953765124082565, 'learning_rate': 4.185e-05, 'epoch': 326.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0659, 'grad_norm': 0.0412018708884716, 'learning_rate': 4.1825e-05, 'epoch': 327.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0654, 'grad_norm': 0.03603575378656387, 'learning_rate': 4.18e-05, 'epoch': 328.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0654, 'grad_norm': 0.030495746061205864, 'learning_rate': 4.1775000000000006e-05, 'epoch': 329.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0649, 'grad_norm': 0.034541040658950806, 'learning_rate': 4.175e-05, 'epoch': 330.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0649, 'grad_norm': 0.0322815403342247, 'learning_rate': 4.1725000000000005e-05, 'epoch': 331.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0649, 'grad_norm': 0.029124008491635323, 'learning_rate': 4.17e-05, 'epoch': 332.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0649, 'grad_norm': 0.028222469612956047, 'learning_rate': 4.1675e-05, 'epoch': 333.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0645, 'grad_norm': 0.02776160091161728, 'learning_rate': 4.165e-05, 'epoch': 334.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0645, 'grad_norm': 0.03951263055205345, 'learning_rate': 4.1625e-05, 'epoch': 335.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0645, 'grad_norm': 0.041674960404634476, 'learning_rate': 4.16e-05, 'epoch': 336.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.064, 'grad_norm': 0.030294105410575867, 'learning_rate': 4.1575e-05, 'epoch': 337.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0645, 'grad_norm': 0.028613170608878136, 'learning_rate': 4.155e-05, 'epoch': 338.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0645, 'grad_norm': 0.042365662753582, 'learning_rate': 4.1525e-05, 'epoch': 339.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.064, 'grad_norm': 0.041249096393585205, 'learning_rate': 4.15e-05, 'epoch': 340.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.064, 'grad_norm': 0.021781127899885178, 'learning_rate': 4.1475000000000005e-05, 'epoch': 341.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.064, 'grad_norm': 0.027001941576600075, 'learning_rate': 4.145e-05, 'epoch': 342.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.064, 'grad_norm': 0.03637246787548065, 'learning_rate': 4.1425000000000004e-05, 'epoch': 343.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.064, 'grad_norm': 0.0404510498046875, 'learning_rate': 4.14e-05, 'epoch': 344.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0635, 'grad_norm': 0.03447555750608444, 'learning_rate': 4.1375e-05, 'epoch': 345.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0635, 'grad_norm': 0.038758959621191025, 'learning_rate': 4.135e-05, 'epoch': 346.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0635, 'grad_norm': 0.04708332195878029, 'learning_rate': 4.1325e-05, 'epoch': 347.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0635, 'grad_norm': 0.08317818492650986, 'learning_rate': 4.13e-05, 'epoch': 348.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.063, 'grad_norm': 0.03375138342380524, 'learning_rate': 4.1275e-05, 'epoch': 349.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0635, 'grad_norm': 0.031897906213998795, 'learning_rate': 4.125e-05, 'epoch': 350.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.063, 'grad_norm': 0.04311509430408478, 'learning_rate': 4.1225e-05, 'epoch': 351.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.063, 'grad_norm': 0.07911749929189682, 'learning_rate': 4.12e-05, 'epoch': 352.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.063, 'grad_norm': 0.027629593387246132, 'learning_rate': 4.1175000000000005e-05, 'epoch': 353.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.063, 'grad_norm': 0.02791729010641575, 'learning_rate': 4.115e-05, 'epoch': 354.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.063, 'grad_norm': 0.026848038658499718, 'learning_rate': 4.1125000000000004e-05, 'epoch': 355.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.063, 'grad_norm': 0.06804247200489044, 'learning_rate': 4.11e-05, 'epoch': 356.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.063, 'grad_norm': 0.029386267066001892, 'learning_rate': 4.1075e-05, 'epoch': 357.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0625, 'grad_norm': 0.035377565771341324, 'learning_rate': 4.105e-05, 'epoch': 358.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0625, 'grad_norm': 0.026354506611824036, 'learning_rate': 4.1025e-05, 'epoch': 359.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0625, 'grad_norm': 0.03139602392911911, 'learning_rate': 4.1e-05, 'epoch': 360.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0625, 'grad_norm': 0.023150373250246048, 'learning_rate': 4.0975e-05, 'epoch': 361.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0623, 'grad_norm': 0.03789188340306282, 'learning_rate': 4.095e-05, 'epoch': 362.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.062, 'grad_norm': 0.03625663369894028, 'learning_rate': 4.0925000000000005e-05, 'epoch': 363.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0623, 'grad_norm': 0.03254032880067825, 'learning_rate': 4.09e-05, 'epoch': 364.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.062, 'grad_norm': 0.04680934548377991, 'learning_rate': 4.0875000000000004e-05, 'epoch': 365.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0618, 'grad_norm': 0.02300162799656391, 'learning_rate': 4.085e-05, 'epoch': 366.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.062, 'grad_norm': 0.07504311203956604, 'learning_rate': 4.0825e-05, 'epoch': 367.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.062, 'grad_norm': 0.03635341301560402, 'learning_rate': 4.08e-05, 'epoch': 368.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0623, 'grad_norm': 0.04965943470597267, 'learning_rate': 4.0775e-05, 'epoch': 369.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0618, 'grad_norm': 0.0620553158223629, 'learning_rate': 4.075e-05, 'epoch': 370.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0618, 'grad_norm': 0.02540225349366665, 'learning_rate': 4.0725e-05, 'epoch': 371.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0618, 'grad_norm': 0.03373771905899048, 'learning_rate': 4.07e-05, 'epoch': 372.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0615, 'grad_norm': 0.027346689254045486, 'learning_rate': 4.0675e-05, 'epoch': 373.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0615, 'grad_norm': 0.04473688080906868, 'learning_rate': 4.065e-05, 'epoch': 374.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0615, 'grad_norm': 0.06250742822885513, 'learning_rate': 4.0625000000000005e-05, 'epoch': 375.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0613, 'grad_norm': 0.041099853813648224, 'learning_rate': 4.0600000000000004e-05, 'epoch': 376.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0613, 'grad_norm': 0.045628778636455536, 'learning_rate': 4.0575000000000004e-05, 'epoch': 377.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.061, 'grad_norm': 0.06290483474731445, 'learning_rate': 4.055e-05, 'epoch': 378.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.061, 'grad_norm': 0.04338524863123894, 'learning_rate': 4.0525e-05, 'epoch': 379.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0613, 'grad_norm': 0.025852110236883163, 'learning_rate': 4.05e-05, 'epoch': 380.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0613, 'grad_norm': 0.0638771653175354, 'learning_rate': 4.0475e-05, 'epoch': 381.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.061, 'grad_norm': 0.02775024063885212, 'learning_rate': 4.045000000000001e-05, 'epoch': 382.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.061, 'grad_norm': 0.03494333103299141, 'learning_rate': 4.0425e-05, 'epoch': 383.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0608, 'grad_norm': 0.029499657452106476, 'learning_rate': 4.0400000000000006e-05, 'epoch': 384.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0608, 'grad_norm': 0.02530185878276825, 'learning_rate': 4.0375e-05, 'epoch': 385.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0603, 'grad_norm': 0.04438631609082222, 'learning_rate': 4.0350000000000005e-05, 'epoch': 386.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0605, 'grad_norm': 0.02871067076921463, 'learning_rate': 4.0325000000000004e-05, 'epoch': 387.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0605, 'grad_norm': 0.025563813745975494, 'learning_rate': 4.0300000000000004e-05, 'epoch': 388.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0603, 'grad_norm': 0.04010370746254921, 'learning_rate': 4.0275e-05, 'epoch': 389.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0605, 'grad_norm': 0.03118761256337166, 'learning_rate': 4.025e-05, 'epoch': 390.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0601, 'grad_norm': 0.027687469497323036, 'learning_rate': 4.0225e-05, 'epoch': 391.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0603, 'grad_norm': 0.041920457035303116, 'learning_rate': 4.02e-05, 'epoch': 392.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0605, 'grad_norm': 0.037556033581495285, 'learning_rate': 4.0175e-05, 'epoch': 393.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0605, 'grad_norm': 0.04691862687468529, 'learning_rate': 4.015000000000001e-05, 'epoch': 394.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0603, 'grad_norm': 0.0425153411924839, 'learning_rate': 4.0125e-05, 'epoch': 395.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0601, 'grad_norm': 0.026204273104667664, 'learning_rate': 4.0100000000000006e-05, 'epoch': 396.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0601, 'grad_norm': 0.06061423197388649, 'learning_rate': 4.0075e-05, 'epoch': 397.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0601, 'grad_norm': 0.03454158827662468, 'learning_rate': 4.0050000000000004e-05, 'epoch': 398.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0603, 'grad_norm': 0.04327012598514557, 'learning_rate': 4.0025000000000004e-05, 'epoch': 399.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0601, 'grad_norm': 0.03224608302116394, 'learning_rate': 4e-05, 'epoch': 400.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0596, 'grad_norm': 0.026545673608779907, 'learning_rate': 3.9975e-05, 'epoch': 401.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0596, 'grad_norm': 0.03550184518098831, 'learning_rate': 3.995e-05, 'epoch': 402.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0596, 'grad_norm': 0.06006920337677002, 'learning_rate': 3.9925e-05, 'epoch': 403.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0598, 'grad_norm': 0.057292331010103226, 'learning_rate': 3.99e-05, 'epoch': 404.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0596, 'grad_norm': 0.04428860917687416, 'learning_rate': 3.9875e-05, 'epoch': 405.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0596, 'grad_norm': 0.09914006292819977, 'learning_rate': 3.9850000000000006e-05, 'epoch': 406.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0598, 'grad_norm': 0.04433291032910347, 'learning_rate': 3.9825e-05, 'epoch': 407.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0593, 'grad_norm': 0.024786321446299553, 'learning_rate': 3.9800000000000005e-05, 'epoch': 408.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0591, 'grad_norm': 0.052052367478609085, 'learning_rate': 3.9775e-05, 'epoch': 409.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0593, 'grad_norm': 0.0810801163315773, 'learning_rate': 3.9750000000000004e-05, 'epoch': 410.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0596, 'grad_norm': 0.02962600812315941, 'learning_rate': 3.9725e-05, 'epoch': 411.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0591, 'grad_norm': 0.05123979225754738, 'learning_rate': 3.97e-05, 'epoch': 412.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0591, 'grad_norm': 0.02657322585582733, 'learning_rate': 3.9675e-05, 'epoch': 413.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0591, 'grad_norm': 0.07863983511924744, 'learning_rate': 3.965e-05, 'epoch': 414.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0591, 'grad_norm': 0.03669220954179764, 'learning_rate': 3.9625e-05, 'epoch': 415.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0591, 'grad_norm': 0.03429316356778145, 'learning_rate': 3.960000000000001e-05, 'epoch': 416.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0591, 'grad_norm': 0.02950340323150158, 'learning_rate': 3.9575e-05, 'epoch': 417.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0591, 'grad_norm': 0.13829323649406433, 'learning_rate': 3.9550000000000006e-05, 'epoch': 418.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0586, 'grad_norm': 0.03303030505776405, 'learning_rate': 3.9525e-05, 'epoch': 419.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0588, 'grad_norm': 0.03787819296121597, 'learning_rate': 3.9500000000000005e-05, 'epoch': 420.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0591, 'grad_norm': 0.07135292142629623, 'learning_rate': 3.9475000000000004e-05, 'epoch': 421.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0586, 'grad_norm': 0.12333372235298157, 'learning_rate': 3.9450000000000003e-05, 'epoch': 422.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0586, 'grad_norm': 0.040458161383867264, 'learning_rate': 3.9425e-05, 'epoch': 423.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0586, 'grad_norm': 0.06954915821552277, 'learning_rate': 3.94e-05, 'epoch': 424.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0586, 'grad_norm': 0.07836684584617615, 'learning_rate': 3.9375e-05, 'epoch': 425.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0586, 'grad_norm': 0.0853632465004921, 'learning_rate': 3.935e-05, 'epoch': 426.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0581, 'grad_norm': 0.029943808913230896, 'learning_rate': 3.9325e-05, 'epoch': 427.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0581, 'grad_norm': 0.03598666191101074, 'learning_rate': 3.9300000000000007e-05, 'epoch': 428.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0586, 'grad_norm': 0.2724510431289673, 'learning_rate': 3.9275e-05, 'epoch': 429.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0583, 'grad_norm': 0.07444124668836594, 'learning_rate': 3.9250000000000005e-05, 'epoch': 430.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0586, 'grad_norm': 0.2578844428062439, 'learning_rate': 3.9225e-05, 'epoch': 431.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0583, 'grad_norm': 0.1712484359741211, 'learning_rate': 3.9200000000000004e-05, 'epoch': 432.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0583, 'grad_norm': 0.08060512691736221, 'learning_rate': 3.9175000000000004e-05, 'epoch': 433.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0583, 'grad_norm': 0.06705683469772339, 'learning_rate': 3.915e-05, 'epoch': 434.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0583, 'grad_norm': 0.10888698697090149, 'learning_rate': 3.9125e-05, 'epoch': 435.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0581, 'grad_norm': 0.05430244654417038, 'learning_rate': 3.91e-05, 'epoch': 436.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0581, 'grad_norm': 0.06638650596141815, 'learning_rate': 3.9075e-05, 'epoch': 437.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0581, 'grad_norm': 0.06165086477994919, 'learning_rate': 3.905e-05, 'epoch': 438.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0581, 'grad_norm': 0.08899373561143875, 'learning_rate': 3.9025e-05, 'epoch': 439.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0581, 'grad_norm': 0.06204608827829361, 'learning_rate': 3.9000000000000006e-05, 'epoch': 440.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0576, 'grad_norm': 0.03786906972527504, 'learning_rate': 3.8975e-05, 'epoch': 441.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0579, 'grad_norm': 0.04833552613854408, 'learning_rate': 3.8950000000000005e-05, 'epoch': 442.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0579, 'grad_norm': 0.14109311997890472, 'learning_rate': 3.8925e-05, 'epoch': 443.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0576, 'grad_norm': 0.05099277198314667, 'learning_rate': 3.8900000000000004e-05, 'epoch': 444.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0579, 'grad_norm': 0.09166086465120316, 'learning_rate': 3.8875e-05, 'epoch': 445.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0576, 'grad_norm': 0.08138053864240646, 'learning_rate': 3.885e-05, 'epoch': 446.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0571, 'grad_norm': 0.04572136700153351, 'learning_rate': 3.8825e-05, 'epoch': 447.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0571, 'grad_norm': 0.03807319700717926, 'learning_rate': 3.88e-05, 'epoch': 448.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0571, 'grad_norm': 0.05730600282549858, 'learning_rate': 3.8775e-05, 'epoch': 449.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0574, 'grad_norm': 0.06617250293493271, 'learning_rate': 3.875e-05, 'epoch': 450.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0571, 'grad_norm': 0.04699141904711723, 'learning_rate': 3.8725e-05, 'epoch': 451.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0569, 'grad_norm': 0.04670841619372368, 'learning_rate': 3.8700000000000006e-05, 'epoch': 452.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0569, 'grad_norm': 0.03465057164430618, 'learning_rate': 3.8675e-05, 'epoch': 453.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0569, 'grad_norm': 0.04259517788887024, 'learning_rate': 3.8650000000000004e-05, 'epoch': 454.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0571, 'grad_norm': 0.04288353770971298, 'learning_rate': 3.8625e-05, 'epoch': 455.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0569, 'grad_norm': 0.06307334452867508, 'learning_rate': 3.86e-05, 'epoch': 456.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0566, 'grad_norm': 0.040134839713573456, 'learning_rate': 3.8575e-05, 'epoch': 457.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0566, 'grad_norm': 0.05112774297595024, 'learning_rate': 3.855e-05, 'epoch': 458.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0566, 'grad_norm': 0.03927529230713844, 'learning_rate': 3.8525e-05, 'epoch': 459.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0566, 'grad_norm': 0.0313061885535717, 'learning_rate': 3.85e-05, 'epoch': 460.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0566, 'grad_norm': 0.05351294204592705, 'learning_rate': 3.8475e-05, 'epoch': 461.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0566, 'grad_norm': 0.06265313923358917, 'learning_rate': 3.845e-05, 'epoch': 462.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0564, 'grad_norm': 0.03330327942967415, 'learning_rate': 3.8425e-05, 'epoch': 463.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0562, 'grad_norm': 0.045466098934412, 'learning_rate': 3.8400000000000005e-05, 'epoch': 464.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0564, 'grad_norm': 0.17465342581272125, 'learning_rate': 3.8375e-05, 'epoch': 465.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0564, 'grad_norm': 0.038368724286556244, 'learning_rate': 3.8350000000000004e-05, 'epoch': 466.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0564, 'grad_norm': 0.06554687768220901, 'learning_rate': 3.8324999999999996e-05, 'epoch': 467.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0564, 'grad_norm': 0.19983823597431183, 'learning_rate': 3.83e-05, 'epoch': 468.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0559, 'grad_norm': 0.05626990273594856, 'learning_rate': 3.8275e-05, 'epoch': 469.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0559, 'grad_norm': 0.04651416838169098, 'learning_rate': 3.825e-05, 'epoch': 470.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0566, 'grad_norm': 0.0636720135807991, 'learning_rate': 3.8225e-05, 'epoch': 471.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0564, 'grad_norm': 0.10482770949602127, 'learning_rate': 3.82e-05, 'epoch': 472.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0562, 'grad_norm': 0.0553305447101593, 'learning_rate': 3.8175e-05, 'epoch': 473.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0559, 'grad_norm': 0.08190596848726273, 'learning_rate': 3.8150000000000006e-05, 'epoch': 474.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0559, 'grad_norm': 0.04779506474733353, 'learning_rate': 3.8125e-05, 'epoch': 475.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0559, 'grad_norm': 0.03553442656993866, 'learning_rate': 3.8100000000000005e-05, 'epoch': 476.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0557, 'grad_norm': 0.05095888674259186, 'learning_rate': 3.8075e-05, 'epoch': 477.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0557, 'grad_norm': 0.05271025374531746, 'learning_rate': 3.805e-05, 'epoch': 478.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0557, 'grad_norm': 0.0835617259144783, 'learning_rate': 3.8025e-05, 'epoch': 479.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0554, 'grad_norm': 0.11022474616765976, 'learning_rate': 3.8e-05, 'epoch': 480.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0559, 'grad_norm': 0.12529316544532776, 'learning_rate': 3.7975e-05, 'epoch': 481.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0554, 'grad_norm': 0.03949960693717003, 'learning_rate': 3.795e-05, 'epoch': 482.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0569, 'grad_norm': 1.4644545316696167, 'learning_rate': 3.7925e-05, 'epoch': 483.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0889, 'grad_norm': 11.125269889831543, 'learning_rate': 3.79e-05, 'epoch': 484.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0625, 'grad_norm': 2.828948736190796, 'learning_rate': 3.7875e-05, 'epoch': 485.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0654, 'grad_norm': 2.4464926719665527, 'learning_rate': 3.7850000000000005e-05, 'epoch': 486.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0659, 'grad_norm': 3.5662384033203125, 'learning_rate': 3.7825e-05, 'epoch': 487.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.1348, 'grad_norm': 14.727472305297852, 'learning_rate': 3.7800000000000004e-05, 'epoch': 488.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0645, 'grad_norm': 1.61885666847229, 'learning_rate': 3.7775e-05, 'epoch': 489.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0698, 'grad_norm': 2.1401479244232178, 'learning_rate': 3.775e-05, 'epoch': 490.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0664, 'grad_norm': 1.9420692920684814, 'learning_rate': 3.7725e-05, 'epoch': 491.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0679, 'grad_norm': 2.5645949840545654, 'learning_rate': 3.77e-05, 'epoch': 492.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0679, 'grad_norm': 1.5482151508331299, 'learning_rate': 3.7675e-05, 'epoch': 493.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0688, 'grad_norm': 1.9519442319869995, 'learning_rate': 3.765e-05, 'epoch': 494.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0654, 'grad_norm': 0.608734130859375, 'learning_rate': 3.7625e-05, 'epoch': 495.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.064, 'grad_norm': 0.38264957070350647, 'learning_rate': 3.76e-05, 'epoch': 496.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0635, 'grad_norm': 0.18002204596996307, 'learning_rate': 3.7575e-05, 'epoch': 497.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.063, 'grad_norm': 0.14440837502479553, 'learning_rate': 3.7550000000000005e-05, 'epoch': 498.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0645, 'grad_norm': 0.2675202786922455, 'learning_rate': 3.7525e-05, 'epoch': 499.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.063, 'grad_norm': 0.13204097747802734, 'learning_rate': 3.7500000000000003e-05, 'epoch': 500.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0625, 'grad_norm': 0.0980323776602745, 'learning_rate': 3.7475e-05, 'epoch': 501.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0625, 'grad_norm': 0.08754590153694153, 'learning_rate': 3.745e-05, 'epoch': 502.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0625, 'grad_norm': 0.1343483030796051, 'learning_rate': 3.7425e-05, 'epoch': 503.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0623, 'grad_norm': 0.09272586554288864, 'learning_rate': 3.74e-05, 'epoch': 504.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.062, 'grad_norm': 0.09467271715402603, 'learning_rate': 3.737500000000001e-05, 'epoch': 505.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0618, 'grad_norm': 0.07947015017271042, 'learning_rate': 3.735e-05, 'epoch': 506.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0618, 'grad_norm': 0.07863203436136246, 'learning_rate': 3.7325000000000006e-05, 'epoch': 507.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0613, 'grad_norm': 0.0578075647354126, 'learning_rate': 3.73e-05, 'epoch': 508.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.061, 'grad_norm': 0.05433749407529831, 'learning_rate': 3.7275000000000005e-05, 'epoch': 509.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.061, 'grad_norm': 0.05301838740706444, 'learning_rate': 3.7250000000000004e-05, 'epoch': 510.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0605, 'grad_norm': 0.057531844824552536, 'learning_rate': 3.7225000000000004e-05, 'epoch': 511.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0603, 'grad_norm': 0.03991764783859253, 'learning_rate': 3.72e-05, 'epoch': 512.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0605, 'grad_norm': 0.03929099440574646, 'learning_rate': 3.7175e-05, 'epoch': 513.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0598, 'grad_norm': 0.03778737038373947, 'learning_rate': 3.715e-05, 'epoch': 514.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0598, 'grad_norm': 0.039240870624780655, 'learning_rate': 3.7125e-05, 'epoch': 515.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0596, 'grad_norm': 0.034672558307647705, 'learning_rate': 3.71e-05, 'epoch': 516.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0593, 'grad_norm': 0.036043889820575714, 'learning_rate': 3.707500000000001e-05, 'epoch': 517.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0593, 'grad_norm': 0.035009101033210754, 'learning_rate': 3.705e-05, 'epoch': 518.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0593, 'grad_norm': 0.034246448427438736, 'learning_rate': 3.7025000000000005e-05, 'epoch': 519.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0591, 'grad_norm': 0.03031769208610058, 'learning_rate': 3.7e-05, 'epoch': 520.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0591, 'grad_norm': 0.034728508442640305, 'learning_rate': 3.6975000000000004e-05, 'epoch': 521.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0588, 'grad_norm': 0.030213620513677597, 'learning_rate': 3.6950000000000004e-05, 'epoch': 522.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0586, 'grad_norm': 0.03828822076320648, 'learning_rate': 3.6925e-05, 'epoch': 523.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0586, 'grad_norm': 0.02944698929786682, 'learning_rate': 3.69e-05, 'epoch': 524.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0583, 'grad_norm': 0.02760928124189377, 'learning_rate': 3.6875e-05, 'epoch': 525.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0581, 'grad_norm': 0.025025244802236557, 'learning_rate': 3.685e-05, 'epoch': 526.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0581, 'grad_norm': 0.025548012927174568, 'learning_rate': 3.6825e-05, 'epoch': 527.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0581, 'grad_norm': 0.02475893497467041, 'learning_rate': 3.68e-05, 'epoch': 528.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0581, 'grad_norm': 0.026159435510635376, 'learning_rate': 3.6775000000000006e-05, 'epoch': 529.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0581, 'grad_norm': 0.02582048811018467, 'learning_rate': 3.675e-05, 'epoch': 530.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0581, 'grad_norm': 0.02230008691549301, 'learning_rate': 3.6725000000000005e-05, 'epoch': 531.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0579, 'grad_norm': 0.024189721792936325, 'learning_rate': 3.6700000000000004e-05, 'epoch': 532.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0576, 'grad_norm': 0.022257572039961815, 'learning_rate': 3.6675000000000004e-05, 'epoch': 533.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0574, 'grad_norm': 0.025176113471388817, 'learning_rate': 3.665e-05, 'epoch': 534.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0576, 'grad_norm': 0.021731283515691757, 'learning_rate': 3.6625e-05, 'epoch': 535.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0574, 'grad_norm': 0.021463986486196518, 'learning_rate': 3.66e-05, 'epoch': 536.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0574, 'grad_norm': 0.021933019161224365, 'learning_rate': 3.6575e-05, 'epoch': 537.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0571, 'grad_norm': 0.019695188850164413, 'learning_rate': 3.655e-05, 'epoch': 538.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0571, 'grad_norm': 0.020676296204328537, 'learning_rate': 3.652500000000001e-05, 'epoch': 539.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0574, 'grad_norm': 0.018865343183279037, 'learning_rate': 3.65e-05, 'epoch': 540.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0571, 'grad_norm': 0.02080487832427025, 'learning_rate': 3.6475000000000006e-05, 'epoch': 541.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0571, 'grad_norm': 0.02063595876097679, 'learning_rate': 3.645e-05, 'epoch': 542.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0569, 'grad_norm': 0.01918598636984825, 'learning_rate': 3.6425000000000004e-05, 'epoch': 543.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0569, 'grad_norm': 0.022110380232334137, 'learning_rate': 3.6400000000000004e-05, 'epoch': 544.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0566, 'grad_norm': 0.018395939841866493, 'learning_rate': 3.6375e-05, 'epoch': 545.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0569, 'grad_norm': 0.01911928318440914, 'learning_rate': 3.635e-05, 'epoch': 546.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0564, 'grad_norm': 0.019513826817274094, 'learning_rate': 3.6325e-05, 'epoch': 547.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0566, 'grad_norm': 0.018034379929304123, 'learning_rate': 3.63e-05, 'epoch': 548.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0564, 'grad_norm': 0.01811384968459606, 'learning_rate': 3.6275e-05, 'epoch': 549.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0562, 'grad_norm': 0.019031565636396408, 'learning_rate': 3.625e-05, 'epoch': 550.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0562, 'grad_norm': 0.018631527200341225, 'learning_rate': 3.6225000000000006e-05, 'epoch': 551.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0562, 'grad_norm': 0.01931292749941349, 'learning_rate': 3.62e-05, 'epoch': 552.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0562, 'grad_norm': 0.02039564773440361, 'learning_rate': 3.6175000000000005e-05, 'epoch': 553.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0559, 'grad_norm': 0.01738310232758522, 'learning_rate': 3.615e-05, 'epoch': 554.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0559, 'grad_norm': 0.018684018403291702, 'learning_rate': 3.6125000000000004e-05, 'epoch': 555.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0562, 'grad_norm': 0.01780979335308075, 'learning_rate': 3.61e-05, 'epoch': 556.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0557, 'grad_norm': 0.017935587093234062, 'learning_rate': 3.6075e-05, 'epoch': 557.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0557, 'grad_norm': 0.016918478533625603, 'learning_rate': 3.605e-05, 'epoch': 558.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0557, 'grad_norm': 0.017911795526742935, 'learning_rate': 3.6025e-05, 'epoch': 559.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0559, 'grad_norm': 0.022491076961159706, 'learning_rate': 3.6e-05, 'epoch': 560.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0557, 'grad_norm': 0.02151642180979252, 'learning_rate': 3.5975e-05, 'epoch': 561.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0554, 'grad_norm': 0.019259542226791382, 'learning_rate': 3.595e-05, 'epoch': 562.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0554, 'grad_norm': 0.01692088507115841, 'learning_rate': 3.5925000000000006e-05, 'epoch': 563.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0554, 'grad_norm': 0.01681431569159031, 'learning_rate': 3.59e-05, 'epoch': 564.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0552, 'grad_norm': 0.017661921679973602, 'learning_rate': 3.5875000000000005e-05, 'epoch': 565.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0554, 'grad_norm': 0.017410067841410637, 'learning_rate': 3.585e-05, 'epoch': 566.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0552, 'grad_norm': 0.0171674732118845, 'learning_rate': 3.5825000000000003e-05, 'epoch': 567.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0552, 'grad_norm': 0.019269993528723717, 'learning_rate': 3.58e-05, 'epoch': 568.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0552, 'grad_norm': 0.01967635564506054, 'learning_rate': 3.5775e-05, 'epoch': 569.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0552, 'grad_norm': 0.031350456178188324, 'learning_rate': 3.575e-05, 'epoch': 570.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0549, 'grad_norm': 0.016339000314474106, 'learning_rate': 3.5725e-05, 'epoch': 571.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0549, 'grad_norm': 0.02221745252609253, 'learning_rate': 3.57e-05, 'epoch': 572.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0549, 'grad_norm': 0.01732652075588703, 'learning_rate': 3.5675e-05, 'epoch': 573.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0549, 'grad_norm': 0.02009471133351326, 'learning_rate': 3.565e-05, 'epoch': 574.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0549, 'grad_norm': 0.017205076292157173, 'learning_rate': 3.5625000000000005e-05, 'epoch': 575.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0547, 'grad_norm': 0.01685711182653904, 'learning_rate': 3.56e-05, 'epoch': 576.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0547, 'grad_norm': 0.018496079370379448, 'learning_rate': 3.5575000000000004e-05, 'epoch': 577.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0547, 'grad_norm': 0.0207411777228117, 'learning_rate': 3.555e-05, 'epoch': 578.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0547, 'grad_norm': 0.023112259805202484, 'learning_rate': 3.5525e-05, 'epoch': 579.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0544, 'grad_norm': 0.02215312048792839, 'learning_rate': 3.55e-05, 'epoch': 580.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0542, 'grad_norm': 0.017262041568756104, 'learning_rate': 3.5475e-05, 'epoch': 581.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0544, 'grad_norm': 0.02482600137591362, 'learning_rate': 3.545e-05, 'epoch': 582.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0544, 'grad_norm': 0.01749364100396633, 'learning_rate': 3.5425e-05, 'epoch': 583.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0542, 'grad_norm': 0.019496237859129906, 'learning_rate': 3.54e-05, 'epoch': 584.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0542, 'grad_norm': 0.018539797514677048, 'learning_rate': 3.5375e-05, 'epoch': 585.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0542, 'grad_norm': 0.019064493477344513, 'learning_rate': 3.535e-05, 'epoch': 586.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0544, 'grad_norm': 0.02242710068821907, 'learning_rate': 3.5325000000000005e-05, 'epoch': 587.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0542, 'grad_norm': 0.023689622059464455, 'learning_rate': 3.53e-05, 'epoch': 588.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0544, 'grad_norm': 0.018704179674386978, 'learning_rate': 3.5275000000000004e-05, 'epoch': 589.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0542, 'grad_norm': 0.03099176473915577, 'learning_rate': 3.525e-05, 'epoch': 590.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.054, 'grad_norm': 0.019442573189735413, 'learning_rate': 3.5225e-05, 'epoch': 591.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.054, 'grad_norm': 0.021044695749878883, 'learning_rate': 3.52e-05, 'epoch': 592.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.054, 'grad_norm': 0.021867161616683006, 'learning_rate': 3.5175e-05, 'epoch': 593.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0537, 'grad_norm': 0.017011845484375954, 'learning_rate': 3.515e-05, 'epoch': 594.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0537, 'grad_norm': 0.021026642993092537, 'learning_rate': 3.5125e-05, 'epoch': 595.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0537, 'grad_norm': 0.016442228108644485, 'learning_rate': 3.51e-05, 'epoch': 596.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0537, 'grad_norm': 0.024399789050221443, 'learning_rate': 3.5075000000000006e-05, 'epoch': 597.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0537, 'grad_norm': 0.019953656941652298, 'learning_rate': 3.505e-05, 'epoch': 598.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0532, 'grad_norm': 0.021159689873456955, 'learning_rate': 3.5025000000000004e-05, 'epoch': 599.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0537, 'grad_norm': 0.026209412142634392, 'learning_rate': 3.5e-05, 'epoch': 600.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0537, 'grad_norm': 0.02079600654542446, 'learning_rate': 3.4975e-05, 'epoch': 601.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0532, 'grad_norm': 0.02284041792154312, 'learning_rate': 3.495e-05, 'epoch': 602.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0535, 'grad_norm': 0.02114950865507126, 'learning_rate': 3.4925e-05, 'epoch': 603.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0535, 'grad_norm': 0.02007213607430458, 'learning_rate': 3.49e-05, 'epoch': 604.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.053, 'grad_norm': 0.018397923558950424, 'learning_rate': 3.4875e-05, 'epoch': 605.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0535, 'grad_norm': 0.02188638597726822, 'learning_rate': 3.485e-05, 'epoch': 606.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0535, 'grad_norm': 0.023595180362462997, 'learning_rate': 3.4825e-05, 'epoch': 607.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0532, 'grad_norm': 0.017216820269823074, 'learning_rate': 3.48e-05, 'epoch': 608.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0532, 'grad_norm': 0.02831961214542389, 'learning_rate': 3.4775000000000005e-05, 'epoch': 609.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0535, 'grad_norm': 0.019940240308642387, 'learning_rate': 3.475e-05, 'epoch': 610.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0532, 'grad_norm': 0.0166151262819767, 'learning_rate': 3.4725000000000004e-05, 'epoch': 611.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0532, 'grad_norm': 0.02130788005888462, 'learning_rate': 3.4699999999999996e-05, 'epoch': 612.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0532, 'grad_norm': 0.025754714384675026, 'learning_rate': 3.4675e-05, 'epoch': 613.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0532, 'grad_norm': 0.038041695952415466, 'learning_rate': 3.465e-05, 'epoch': 614.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.053, 'grad_norm': 0.023443225771188736, 'learning_rate': 3.4625e-05, 'epoch': 615.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.053, 'grad_norm': 0.023806221783161163, 'learning_rate': 3.46e-05, 'epoch': 616.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.053, 'grad_norm': 0.027318879961967468, 'learning_rate': 3.4575e-05, 'epoch': 617.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.053, 'grad_norm': 0.06515920162200928, 'learning_rate': 3.455e-05, 'epoch': 618.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.053, 'grad_norm': 0.021744880825281143, 'learning_rate': 3.4525e-05, 'epoch': 619.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0527, 'grad_norm': 0.017604241147637367, 'learning_rate': 3.45e-05, 'epoch': 620.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0527, 'grad_norm': 0.023845087736845016, 'learning_rate': 3.4475000000000005e-05, 'epoch': 621.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0525, 'grad_norm': 0.027274999767541885, 'learning_rate': 3.445e-05, 'epoch': 622.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0525, 'grad_norm': 0.027417998760938644, 'learning_rate': 3.4425e-05, 'epoch': 623.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0525, 'grad_norm': 0.038217004388570786, 'learning_rate': 3.4399999999999996e-05, 'epoch': 624.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0525, 'grad_norm': 0.026483379304409027, 'learning_rate': 3.4375e-05, 'epoch': 625.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0525, 'grad_norm': 0.019590340554714203, 'learning_rate': 3.435e-05, 'epoch': 626.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0525, 'grad_norm': 0.04257999733090401, 'learning_rate': 3.4325e-05, 'epoch': 627.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0525, 'grad_norm': 0.03142905235290527, 'learning_rate': 3.430000000000001e-05, 'epoch': 628.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0525, 'grad_norm': 0.01882142201066017, 'learning_rate': 3.4275e-05, 'epoch': 629.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0522, 'grad_norm': 0.024011150002479553, 'learning_rate': 3.4250000000000006e-05, 'epoch': 630.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0522, 'grad_norm': 0.09340964257717133, 'learning_rate': 3.4225e-05, 'epoch': 631.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0525, 'grad_norm': 0.01927012763917446, 'learning_rate': 3.4200000000000005e-05, 'epoch': 632.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0522, 'grad_norm': 0.03813948109745979, 'learning_rate': 3.4175000000000004e-05, 'epoch': 633.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0522, 'grad_norm': 0.03802919760346413, 'learning_rate': 3.415e-05, 'epoch': 634.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.052, 'grad_norm': 0.10821326822042465, 'learning_rate': 3.4125e-05, 'epoch': 635.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0522, 'grad_norm': 0.02123929001390934, 'learning_rate': 3.41e-05, 'epoch': 636.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.052, 'grad_norm': 0.02324945479631424, 'learning_rate': 3.4075e-05, 'epoch': 637.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.052, 'grad_norm': 0.02216482162475586, 'learning_rate': 3.405e-05, 'epoch': 638.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.052, 'grad_norm': 0.02755490317940712, 'learning_rate': 3.4025e-05, 'epoch': 639.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.052, 'grad_norm': 0.020635049790143967, 'learning_rate': 3.4000000000000007e-05, 'epoch': 640.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.052, 'grad_norm': 0.05017071217298508, 'learning_rate': 3.3975e-05, 'epoch': 641.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0518, 'grad_norm': 0.025201527401804924, 'learning_rate': 3.3950000000000005e-05, 'epoch': 642.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0518, 'grad_norm': 0.03840203955769539, 'learning_rate': 3.3925e-05, 'epoch': 643.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.052, 'grad_norm': 0.026144584640860558, 'learning_rate': 3.3900000000000004e-05, 'epoch': 644.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0518, 'grad_norm': 0.02791072428226471, 'learning_rate': 3.3875000000000003e-05, 'epoch': 645.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0518, 'grad_norm': 0.03246506303548813, 'learning_rate': 3.385e-05, 'epoch': 646.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0518, 'grad_norm': 0.033772796392440796, 'learning_rate': 3.3825e-05, 'epoch': 647.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0518, 'grad_norm': 0.02949422039091587, 'learning_rate': 3.38e-05, 'epoch': 648.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0518, 'grad_norm': 0.026942094787955284, 'learning_rate': 3.3775e-05, 'epoch': 649.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0518, 'grad_norm': 0.03484584391117096, 'learning_rate': 3.375000000000001e-05, 'epoch': 650.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0515, 'grad_norm': 0.0335075818002224, 'learning_rate': 3.3725e-05, 'epoch': 651.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0518, 'grad_norm': 0.036462217569351196, 'learning_rate': 3.3700000000000006e-05, 'epoch': 652.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0515, 'grad_norm': 0.02653229981660843, 'learning_rate': 3.3675e-05, 'epoch': 653.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0515, 'grad_norm': 0.029068438336253166, 'learning_rate': 3.3650000000000005e-05, 'epoch': 654.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0518, 'grad_norm': 0.11864195764064789, 'learning_rate': 3.3625000000000004e-05, 'epoch': 655.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0515, 'grad_norm': 0.028625333681702614, 'learning_rate': 3.3600000000000004e-05, 'epoch': 656.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0513, 'grad_norm': 0.03248419240117073, 'learning_rate': 3.3575e-05, 'epoch': 657.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0513, 'grad_norm': 0.06678163260221481, 'learning_rate': 3.355e-05, 'epoch': 658.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0515, 'grad_norm': 0.04638155922293663, 'learning_rate': 3.3525e-05, 'epoch': 659.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0513, 'grad_norm': 0.03342427685856819, 'learning_rate': 3.35e-05, 'epoch': 660.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0513, 'grad_norm': 0.030490892007946968, 'learning_rate': 3.3475e-05, 'epoch': 661.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0513, 'grad_norm': 0.030592886731028557, 'learning_rate': 3.345000000000001e-05, 'epoch': 662.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.051, 'grad_norm': 0.02787221409380436, 'learning_rate': 3.3425e-05, 'epoch': 663.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0513, 'grad_norm': 0.031067144125699997, 'learning_rate': 3.3400000000000005e-05, 'epoch': 664.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.051, 'grad_norm': 0.03067859262228012, 'learning_rate': 3.3375e-05, 'epoch': 665.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.051, 'grad_norm': 0.040710754692554474, 'learning_rate': 3.3350000000000004e-05, 'epoch': 666.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.051, 'grad_norm': 0.09548082947731018, 'learning_rate': 3.3325000000000004e-05, 'epoch': 667.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.051, 'grad_norm': 0.043385498225688934, 'learning_rate': 3.33e-05, 'epoch': 668.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.051, 'grad_norm': 0.024150438606739044, 'learning_rate': 3.3275e-05, 'epoch': 669.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.040562957525253296, 'learning_rate': 3.325e-05, 'epoch': 670.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.040626753121614456, 'learning_rate': 3.3225e-05, 'epoch': 671.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.04854758456349373, 'learning_rate': 3.32e-05, 'epoch': 672.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.051, 'grad_norm': 0.030372075736522675, 'learning_rate': 3.3175e-05, 'epoch': 673.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0505, 'grad_norm': 0.027394555509090424, 'learning_rate': 3.3150000000000006e-05, 'epoch': 674.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.03722791001200676, 'learning_rate': 3.3125e-05, 'epoch': 675.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.04869793355464935, 'learning_rate': 3.3100000000000005e-05, 'epoch': 676.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0505, 'grad_norm': 0.025119598954916, 'learning_rate': 3.3075e-05, 'epoch': 677.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.028772441670298576, 'learning_rate': 3.3050000000000004e-05, 'epoch': 678.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0505, 'grad_norm': 0.05395272374153137, 'learning_rate': 3.3025e-05, 'epoch': 679.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0505, 'grad_norm': 0.07421378046274185, 'learning_rate': 3.3e-05, 'epoch': 680.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0505, 'grad_norm': 0.03985963389277458, 'learning_rate': 3.2975e-05, 'epoch': 681.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.02797378972172737, 'learning_rate': 3.295e-05, 'epoch': 682.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0505, 'grad_norm': 0.036921124905347824, 'learning_rate': 3.2925e-05, 'epoch': 683.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0505, 'grad_norm': 0.025985410436987877, 'learning_rate': 3.29e-05, 'epoch': 684.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0503, 'grad_norm': 0.02929236739873886, 'learning_rate': 3.2875e-05, 'epoch': 685.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.08690212666988373, 'learning_rate': 3.2850000000000006e-05, 'epoch': 686.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.05, 'grad_norm': 0.03200673311948776, 'learning_rate': 3.2825e-05, 'epoch': 687.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.05, 'grad_norm': 0.03796710819005966, 'learning_rate': 3.2800000000000004e-05, 'epoch': 688.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.05671483278274536, 'learning_rate': 3.2775e-05, 'epoch': 689.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.05, 'grad_norm': 0.03635067120194435, 'learning_rate': 3.275e-05, 'epoch': 690.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.05, 'grad_norm': 0.030054783448576927, 'learning_rate': 3.2725e-05, 'epoch': 691.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0503, 'grad_norm': 0.02737484872341156, 'learning_rate': 3.27e-05, 'epoch': 692.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.05, 'grad_norm': 0.052700404077768326, 'learning_rate': 3.2675e-05, 'epoch': 693.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.05, 'grad_norm': 0.04913151636719704, 'learning_rate': 3.265e-05, 'epoch': 694.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.05, 'grad_norm': 0.0493701733648777, 'learning_rate': 3.2625e-05, 'epoch': 695.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.05, 'grad_norm': 0.03843819350004196, 'learning_rate': 3.26e-05, 'epoch': 696.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.05, 'grad_norm': 0.03391500562429428, 'learning_rate': 3.2575e-05, 'epoch': 697.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0503, 'grad_norm': 0.050409022718667984, 'learning_rate': 3.2550000000000005e-05, 'epoch': 698.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.05, 'grad_norm': 0.048939578235149384, 'learning_rate': 3.2525e-05, 'epoch': 699.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.05, 'grad_norm': 0.04427880048751831, 'learning_rate': 3.2500000000000004e-05, 'epoch': 700.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0498, 'grad_norm': 0.02914378233253956, 'learning_rate': 3.2474999999999997e-05, 'epoch': 701.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.05, 'grad_norm': 0.05443532392382622, 'learning_rate': 3.245e-05, 'epoch': 702.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0498, 'grad_norm': 0.028187107294797897, 'learning_rate': 3.2425e-05, 'epoch': 703.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0498, 'grad_norm': 0.028851695358753204, 'learning_rate': 3.24e-05, 'epoch': 704.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0496, 'grad_norm': 0.02724153734743595, 'learning_rate': 3.2375e-05, 'epoch': 705.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0496, 'grad_norm': 0.04087889939546585, 'learning_rate': 3.235e-05, 'epoch': 706.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0496, 'grad_norm': 0.028343327343463898, 'learning_rate': 3.2325e-05, 'epoch': 707.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0496, 'grad_norm': 0.033366817981004715, 'learning_rate': 3.2300000000000006e-05, 'epoch': 708.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0498, 'grad_norm': 0.04905378818511963, 'learning_rate': 3.2275e-05, 'epoch': 709.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0496, 'grad_norm': 0.04776177555322647, 'learning_rate': 3.2250000000000005e-05, 'epoch': 710.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0493, 'grad_norm': 0.02509964443743229, 'learning_rate': 3.2225e-05, 'epoch': 711.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0496, 'grad_norm': 0.042602285742759705, 'learning_rate': 3.2200000000000003e-05, 'epoch': 712.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0496, 'grad_norm': 0.03301240876317024, 'learning_rate': 3.2175e-05, 'epoch': 713.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0493, 'grad_norm': 0.055722083896398544, 'learning_rate': 3.215e-05, 'epoch': 714.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0493, 'grad_norm': 0.038022030144929886, 'learning_rate': 3.2125e-05, 'epoch': 715.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.025000181049108505, 'learning_rate': 3.21e-05, 'epoch': 716.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.03859600052237511, 'learning_rate': 3.2075e-05, 'epoch': 717.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.02445191890001297, 'learning_rate': 3.205e-05, 'epoch': 718.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0493, 'grad_norm': 0.04937836900353432, 'learning_rate': 3.2025e-05, 'epoch': 719.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0493, 'grad_norm': 0.032388001680374146, 'learning_rate': 3.2000000000000005e-05, 'epoch': 720.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.047767817974090576, 'learning_rate': 3.1975e-05, 'epoch': 721.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0493, 'grad_norm': 0.036060307174921036, 'learning_rate': 3.1950000000000004e-05, 'epoch': 722.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.0357067845761776, 'learning_rate': 3.1925e-05, 'epoch': 723.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.03099140152335167, 'learning_rate': 3.19e-05, 'epoch': 724.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.062309134751558304, 'learning_rate': 3.1875e-05, 'epoch': 725.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.025691501796245575, 'learning_rate': 3.185e-05, 'epoch': 726.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0488, 'grad_norm': 0.03341527283191681, 'learning_rate': 3.1825e-05, 'epoch': 727.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.042720962315797806, 'learning_rate': 3.18e-05, 'epoch': 728.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0488, 'grad_norm': 0.02211867831647396, 'learning_rate': 3.1775e-05, 'epoch': 729.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.037159692496061325, 'learning_rate': 3.175e-05, 'epoch': 730.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0488, 'grad_norm': 0.0443362221121788, 'learning_rate': 3.1725e-05, 'epoch': 731.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0488, 'grad_norm': 0.029691144824028015, 'learning_rate': 3.1700000000000005e-05, 'epoch': 732.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0483, 'grad_norm': 0.026092510670423508, 'learning_rate': 3.1675e-05, 'epoch': 733.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0483, 'grad_norm': 0.027428038418293, 'learning_rate': 3.1650000000000004e-05, 'epoch': 734.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.06094850227236748, 'learning_rate': 3.1624999999999996e-05, 'epoch': 735.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0486, 'grad_norm': 0.026785491034388542, 'learning_rate': 3.16e-05, 'epoch': 736.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.28965115547180176, 'learning_rate': 3.1575e-05, 'epoch': 737.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0488, 'grad_norm': 0.04766753688454628, 'learning_rate': 3.155e-05, 'epoch': 738.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0486, 'grad_norm': 0.08533497154712677, 'learning_rate': 3.1525e-05, 'epoch': 739.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0496, 'grad_norm': 0.5738277435302734, 'learning_rate': 3.15e-05, 'epoch': 740.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0486, 'grad_norm': 0.12413138896226883, 'learning_rate': 3.1475e-05, 'epoch': 741.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0569, 'grad_norm': 5.336407661437988, 'learning_rate': 3.145e-05, 'epoch': 742.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.05, 'grad_norm': 1.2274502515792847, 'learning_rate': 3.1425e-05, 'epoch': 743.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0503, 'grad_norm': 0.4055827558040619, 'learning_rate': 3.1400000000000004e-05, 'epoch': 744.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0549, 'grad_norm': 1.7351460456848145, 'learning_rate': 3.1375e-05, 'epoch': 745.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.052, 'grad_norm': 0.8310222625732422, 'learning_rate': 3.135e-05, 'epoch': 746.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0518, 'grad_norm': 0.5899397134780884, 'learning_rate': 3.1324999999999996e-05, 'epoch': 747.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.051, 'grad_norm': 0.4387819468975067, 'learning_rate': 3.13e-05, 'epoch': 748.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.051, 'grad_norm': 0.22697202861309052, 'learning_rate': 3.1275e-05, 'epoch': 749.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0513, 'grad_norm': 0.5206001400947571, 'learning_rate': 3.125e-05, 'epoch': 750.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0513, 'grad_norm': 0.22479061782360077, 'learning_rate': 3.122500000000001e-05, 'epoch': 751.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.051, 'grad_norm': 0.0876825600862503, 'learning_rate': 3.12e-05, 'epoch': 752.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0513, 'grad_norm': 0.1254124939441681, 'learning_rate': 3.1175000000000006e-05, 'epoch': 753.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0515, 'grad_norm': 0.13705550134181976, 'learning_rate': 3.115e-05, 'epoch': 754.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.09441355615854263, 'learning_rate': 3.1125000000000004e-05, 'epoch': 755.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.051, 'grad_norm': 0.06430956721305847, 'learning_rate': 3.1100000000000004e-05, 'epoch': 756.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.0530451238155365, 'learning_rate': 3.1075e-05, 'epoch': 757.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.04625667631626129, 'learning_rate': 3.105e-05, 'epoch': 758.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.052117470651865005, 'learning_rate': 3.1025e-05, 'epoch': 759.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0505, 'grad_norm': 0.06421387195587158, 'learning_rate': 3.1e-05, 'epoch': 760.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0508, 'grad_norm': 0.11495694518089294, 'learning_rate': 3.0975e-05, 'epoch': 761.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0505, 'grad_norm': 0.061836909502744675, 'learning_rate': 3.095e-05, 'epoch': 762.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0503, 'grad_norm': 0.044106822460889816, 'learning_rate': 3.0925000000000006e-05, 'epoch': 763.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0503, 'grad_norm': 0.040455251932144165, 'learning_rate': 3.09e-05, 'epoch': 764.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0503, 'grad_norm': 0.03542352840304375, 'learning_rate': 3.0875000000000005e-05, 'epoch': 765.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0503, 'grad_norm': 0.036100368946790695, 'learning_rate': 3.0850000000000004e-05, 'epoch': 766.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0498, 'grad_norm': 0.03392205387353897, 'learning_rate': 3.0825000000000004e-05, 'epoch': 767.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0498, 'grad_norm': 0.045149244368076324, 'learning_rate': 3.08e-05, 'epoch': 768.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0496, 'grad_norm': 0.034507617354393005, 'learning_rate': 3.0775e-05, 'epoch': 769.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0498, 'grad_norm': 0.03638887777924538, 'learning_rate': 3.075e-05, 'epoch': 770.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0496, 'grad_norm': 0.03660127520561218, 'learning_rate': 3.0725e-05, 'epoch': 771.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0493, 'grad_norm': 0.03304678574204445, 'learning_rate': 3.07e-05, 'epoch': 772.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0493, 'grad_norm': 0.031152833253145218, 'learning_rate': 3.067500000000001e-05, 'epoch': 773.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0496, 'grad_norm': 0.029227647930383682, 'learning_rate': 3.065e-05, 'epoch': 774.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.04207073524594307, 'learning_rate': 3.0625000000000006e-05, 'epoch': 775.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0493, 'grad_norm': 0.04575859755277634, 'learning_rate': 3.06e-05, 'epoch': 776.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0493, 'grad_norm': 0.11856832355260849, 'learning_rate': 3.0575000000000005e-05, 'epoch': 777.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0488, 'grad_norm': 0.028346598148345947, 'learning_rate': 3.0550000000000004e-05, 'epoch': 778.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0491, 'grad_norm': 0.029333623126149178, 'learning_rate': 3.0525e-05, 'epoch': 779.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0488, 'grad_norm': 0.030271416530013084, 'learning_rate': 3.05e-05, 'epoch': 780.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0488, 'grad_norm': 0.037866849452257156, 'learning_rate': 3.0475000000000002e-05, 'epoch': 781.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0488, 'grad_norm': 0.027226300910115242, 'learning_rate': 3.045e-05, 'epoch': 782.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0486, 'grad_norm': 0.02480250597000122, 'learning_rate': 3.0425000000000004e-05, 'epoch': 783.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0488, 'grad_norm': 0.031792204827070236, 'learning_rate': 3.04e-05, 'epoch': 784.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0488, 'grad_norm': 0.028891341760754585, 'learning_rate': 3.0375000000000003e-05, 'epoch': 785.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0486, 'grad_norm': 0.025587497279047966, 'learning_rate': 3.035e-05, 'epoch': 786.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0486, 'grad_norm': 0.025761308148503304, 'learning_rate': 3.0325000000000002e-05, 'epoch': 787.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0483, 'grad_norm': 0.02529190480709076, 'learning_rate': 3.03e-05, 'epoch': 788.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0481, 'grad_norm': 0.021647794172167778, 'learning_rate': 3.0275000000000004e-05, 'epoch': 789.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0483, 'grad_norm': 0.026551783084869385, 'learning_rate': 3.025e-05, 'epoch': 790.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0483, 'grad_norm': 0.03449106961488724, 'learning_rate': 3.0225000000000003e-05, 'epoch': 791.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0481, 'grad_norm': 0.023793494328856468, 'learning_rate': 3.02e-05, 'epoch': 792.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0481, 'grad_norm': 0.026830000802874565, 'learning_rate': 3.0175e-05, 'epoch': 793.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0476, 'grad_norm': 0.027175815775990486, 'learning_rate': 3.015e-05, 'epoch': 794.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0479, 'grad_norm': 0.027858253568410873, 'learning_rate': 3.0125000000000004e-05, 'epoch': 795.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0483, 'grad_norm': 0.028641588985919952, 'learning_rate': 3.01e-05, 'epoch': 796.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0481, 'grad_norm': 0.02646554261445999, 'learning_rate': 3.0075000000000003e-05, 'epoch': 797.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0481, 'grad_norm': 0.02480458654463291, 'learning_rate': 3.0050000000000002e-05, 'epoch': 798.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0479, 'grad_norm': 0.04659726470708847, 'learning_rate': 3.0025000000000005e-05, 'epoch': 799.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0481, 'grad_norm': 0.022314462810754776, 'learning_rate': 3e-05, 'epoch': 800.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0479, 'grad_norm': 0.039960816502571106, 'learning_rate': 2.9975000000000004e-05, 'epoch': 801.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0476, 'grad_norm': 0.023595135658979416, 'learning_rate': 2.995e-05, 'epoch': 802.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0476, 'grad_norm': 0.028187796473503113, 'learning_rate': 2.9925000000000002e-05, 'epoch': 803.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0476, 'grad_norm': 0.04397927224636078, 'learning_rate': 2.9900000000000002e-05, 'epoch': 804.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0476, 'grad_norm': 0.027742763981223106, 'learning_rate': 2.9875000000000004e-05, 'epoch': 805.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0474, 'grad_norm': 0.025787368416786194, 'learning_rate': 2.985e-05, 'epoch': 806.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0476, 'grad_norm': 0.027298109605908394, 'learning_rate': 2.9825000000000003e-05, 'epoch': 807.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0474, 'grad_norm': 0.03992524370551109, 'learning_rate': 2.98e-05, 'epoch': 808.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0474, 'grad_norm': 0.02291758544743061, 'learning_rate': 2.9775000000000002e-05, 'epoch': 809.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0476, 'grad_norm': 0.023202529177069664, 'learning_rate': 2.975e-05, 'epoch': 810.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0474, 'grad_norm': 0.04200335964560509, 'learning_rate': 2.9725000000000004e-05, 'epoch': 811.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0474, 'grad_norm': 0.05286886543035507, 'learning_rate': 2.97e-05, 'epoch': 812.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0471, 'grad_norm': 0.028103455901145935, 'learning_rate': 2.9675000000000003e-05, 'epoch': 813.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0471, 'grad_norm': 0.021214032545685768, 'learning_rate': 2.965e-05, 'epoch': 814.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0474, 'grad_norm': 0.020166361704468727, 'learning_rate': 2.9625000000000002e-05, 'epoch': 815.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0471, 'grad_norm': 0.02278890274465084, 'learning_rate': 2.96e-05, 'epoch': 816.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0469, 'grad_norm': 0.03179436922073364, 'learning_rate': 2.9575000000000004e-05, 'epoch': 817.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0471, 'grad_norm': 0.03233223035931587, 'learning_rate': 2.955e-05, 'epoch': 818.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0469, 'grad_norm': 0.06701204180717468, 'learning_rate': 2.9525000000000003e-05, 'epoch': 819.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0471, 'grad_norm': 0.019236018881201744, 'learning_rate': 2.95e-05, 'epoch': 820.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0471, 'grad_norm': 0.02666165865957737, 'learning_rate': 2.9475e-05, 'epoch': 821.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0471, 'grad_norm': 0.03184036165475845, 'learning_rate': 2.945e-05, 'epoch': 822.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0469, 'grad_norm': 0.043036069720983505, 'learning_rate': 2.9425000000000004e-05, 'epoch': 823.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0466, 'grad_norm': 0.05074108764529228, 'learning_rate': 2.94e-05, 'epoch': 824.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0469, 'grad_norm': 0.039473481476306915, 'learning_rate': 2.9375000000000003e-05, 'epoch': 825.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0469, 'grad_norm': 0.024594908580183983, 'learning_rate': 2.935e-05, 'epoch': 826.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0466, 'grad_norm': 0.031485773622989655, 'learning_rate': 2.9325e-05, 'epoch': 827.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0466, 'grad_norm': 0.03046577237546444, 'learning_rate': 2.93e-05, 'epoch': 828.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.048787787556648254, 'learning_rate': 2.9275000000000003e-05, 'epoch': 829.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0466, 'grad_norm': 0.041704922914505005, 'learning_rate': 2.925e-05, 'epoch': 830.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.033008214086294174, 'learning_rate': 2.9225000000000002e-05, 'epoch': 831.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.02878454700112343, 'learning_rate': 2.9199999999999998e-05, 'epoch': 832.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.02839546836912632, 'learning_rate': 2.9175e-05, 'epoch': 833.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.04656178504228592, 'learning_rate': 2.915e-05, 'epoch': 834.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.04671141132712364, 'learning_rate': 2.9125000000000003e-05, 'epoch': 835.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.029230671003460884, 'learning_rate': 2.91e-05, 'epoch': 836.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0466, 'grad_norm': 0.02705337479710579, 'learning_rate': 2.9075000000000002e-05, 'epoch': 837.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.03516225144267082, 'learning_rate': 2.9049999999999998e-05, 'epoch': 838.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.02390303835272789, 'learning_rate': 2.9025e-05, 'epoch': 839.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.06037057191133499, 'learning_rate': 2.9e-05, 'epoch': 840.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.023779314011335373, 'learning_rate': 2.8975000000000003e-05, 'epoch': 841.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.02674097754061222, 'learning_rate': 2.895e-05, 'epoch': 842.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.051599450409412384, 'learning_rate': 2.8925000000000002e-05, 'epoch': 843.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.04618013650178909, 'learning_rate': 2.8899999999999998e-05, 'epoch': 844.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.030593611299991608, 'learning_rate': 2.8875e-05, 'epoch': 845.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.02825767919421196, 'learning_rate': 2.885e-05, 'epoch': 846.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.0325479693710804, 'learning_rate': 2.8825000000000003e-05, 'epoch': 847.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.041743747889995575, 'learning_rate': 2.88e-05, 'epoch': 848.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.045488785952329636, 'learning_rate': 2.8775e-05, 'epoch': 849.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0457, 'grad_norm': 0.04682105407118797, 'learning_rate': 2.8749999999999997e-05, 'epoch': 850.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.028641192242503166, 'learning_rate': 2.8725e-05, 'epoch': 851.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.03691915422677994, 'learning_rate': 2.87e-05, 'epoch': 852.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.03789296746253967, 'learning_rate': 2.8675000000000002e-05, 'epoch': 853.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0457, 'grad_norm': 0.029018113389611244, 'learning_rate': 2.865e-05, 'epoch': 854.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.03344699367880821, 'learning_rate': 2.8625e-05, 'epoch': 855.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.06429360061883926, 'learning_rate': 2.86e-05, 'epoch': 856.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0454, 'grad_norm': 0.026465468108654022, 'learning_rate': 2.8575000000000003e-05, 'epoch': 857.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0457, 'grad_norm': 0.027008242905139923, 'learning_rate': 2.855e-05, 'epoch': 858.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.027079155668616295, 'learning_rate': 2.8525000000000002e-05, 'epoch': 859.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0452, 'grad_norm': 0.030927415937185287, 'learning_rate': 2.8499999999999998e-05, 'epoch': 860.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.1164771169424057, 'learning_rate': 2.8475e-05, 'epoch': 861.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0457, 'grad_norm': 0.024602847173810005, 'learning_rate': 2.845e-05, 'epoch': 862.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0452, 'grad_norm': 0.024154482409358025, 'learning_rate': 2.8425000000000003e-05, 'epoch': 863.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0457, 'grad_norm': 0.054699935019016266, 'learning_rate': 2.84e-05, 'epoch': 864.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.10073590278625488, 'learning_rate': 2.8375000000000002e-05, 'epoch': 865.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0454, 'grad_norm': 0.0437079481780529, 'learning_rate': 2.8349999999999998e-05, 'epoch': 866.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0454, 'grad_norm': 0.04290784150362015, 'learning_rate': 2.8325e-05, 'epoch': 867.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.6167212724685669, 'learning_rate': 2.83e-05, 'epoch': 868.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.31343770027160645, 'learning_rate': 2.8275000000000003e-05, 'epoch': 869.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.30486831068992615, 'learning_rate': 2.825e-05, 'epoch': 870.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.1621541529893875, 'learning_rate': 2.8225e-05, 'epoch': 871.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.08748011291027069, 'learning_rate': 2.8199999999999998e-05, 'epoch': 872.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.20657065510749817, 'learning_rate': 2.8175e-05, 'epoch': 873.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0466, 'grad_norm': 0.22454865276813507, 'learning_rate': 2.815e-05, 'epoch': 874.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.07702966779470444, 'learning_rate': 2.8125000000000003e-05, 'epoch': 875.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.06536201387643814, 'learning_rate': 2.8100000000000005e-05, 'epoch': 876.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.10946273803710938, 'learning_rate': 2.8075e-05, 'epoch': 877.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.10929108411073685, 'learning_rate': 2.8050000000000004e-05, 'epoch': 878.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.5125910043716431, 'learning_rate': 2.8025e-05, 'epoch': 879.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.0673130452632904, 'learning_rate': 2.8000000000000003e-05, 'epoch': 880.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.16542193293571472, 'learning_rate': 2.7975000000000002e-05, 'epoch': 881.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.14852134883403778, 'learning_rate': 2.7950000000000005e-05, 'epoch': 882.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0469, 'grad_norm': 0.8671368360519409, 'learning_rate': 2.7925e-05, 'epoch': 883.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0466, 'grad_norm': 0.5042768716812134, 'learning_rate': 2.7900000000000004e-05, 'epoch': 884.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.10841574519872665, 'learning_rate': 2.7875e-05, 'epoch': 885.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0466, 'grad_norm': 0.11217817664146423, 'learning_rate': 2.7850000000000003e-05, 'epoch': 886.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0474, 'grad_norm': 0.4580274224281311, 'learning_rate': 2.7825000000000002e-05, 'epoch': 887.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0469, 'grad_norm': 0.1670837253332138, 'learning_rate': 2.7800000000000005e-05, 'epoch': 888.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0469, 'grad_norm': 0.08125921338796616, 'learning_rate': 2.7775e-05, 'epoch': 889.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0469, 'grad_norm': 0.14138691127300262, 'learning_rate': 2.7750000000000004e-05, 'epoch': 890.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0471, 'grad_norm': 0.16463859379291534, 'learning_rate': 2.7725e-05, 'epoch': 891.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0469, 'grad_norm': 0.09439919143915176, 'learning_rate': 2.7700000000000002e-05, 'epoch': 892.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0466, 'grad_norm': 0.09213503450155258, 'learning_rate': 2.7675000000000002e-05, 'epoch': 893.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0466, 'grad_norm': 0.05362746864557266, 'learning_rate': 2.7650000000000005e-05, 'epoch': 894.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0466, 'grad_norm': 0.08053470402956009, 'learning_rate': 2.7625e-05, 'epoch': 895.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0466, 'grad_norm': 0.08396462351083755, 'learning_rate': 2.7600000000000003e-05, 'epoch': 896.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0469, 'grad_norm': 0.3569848835468292, 'learning_rate': 2.7575e-05, 'epoch': 897.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.06391320377588272, 'learning_rate': 2.7550000000000002e-05, 'epoch': 898.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0464, 'grad_norm': 0.08166101574897766, 'learning_rate': 2.7525e-05, 'epoch': 899.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0469, 'grad_norm': 0.18346384167671204, 'learning_rate': 2.7500000000000004e-05, 'epoch': 900.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.06535376608371735, 'learning_rate': 2.7475e-05, 'epoch': 901.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.04560617357492447, 'learning_rate': 2.7450000000000003e-05, 'epoch': 902.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.0451262965798378, 'learning_rate': 2.7425e-05, 'epoch': 903.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0461, 'grad_norm': 0.07573708891868591, 'learning_rate': 2.7400000000000002e-05, 'epoch': 904.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.09846775233745575, 'learning_rate': 2.7375e-05, 'epoch': 905.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.047400522977113724, 'learning_rate': 2.7350000000000004e-05, 'epoch': 906.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.05002100020647049, 'learning_rate': 2.7325e-05, 'epoch': 907.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.04810631275177002, 'learning_rate': 2.7300000000000003e-05, 'epoch': 908.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 0.05125273019075394, 'learning_rate': 2.7275e-05, 'epoch': 909.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0457, 'grad_norm': 0.05181552842259407, 'learning_rate': 2.725e-05, 'epoch': 910.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0454, 'grad_norm': 0.08050573617219925, 'learning_rate': 2.7225e-05, 'epoch': 911.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0457, 'grad_norm': 0.08167921006679535, 'learning_rate': 2.7200000000000004e-05, 'epoch': 912.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0454, 'grad_norm': 0.05170813947916031, 'learning_rate': 2.7175e-05, 'epoch': 913.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0457, 'grad_norm': 0.05737466737627983, 'learning_rate': 2.7150000000000003e-05, 'epoch': 914.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0452, 'grad_norm': 0.046258602291345596, 'learning_rate': 2.7125000000000002e-05, 'epoch': 915.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0452, 'grad_norm': 0.0729835107922554, 'learning_rate': 2.7100000000000005e-05, 'epoch': 916.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0449, 'grad_norm': 0.0377633199095726, 'learning_rate': 2.7075e-05, 'epoch': 917.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0452, 'grad_norm': 0.030227825045585632, 'learning_rate': 2.7050000000000004e-05, 'epoch': 918.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0444, 'grad_norm': 0.03411007672548294, 'learning_rate': 2.7025e-05, 'epoch': 919.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0449, 'grad_norm': 0.03798201307654381, 'learning_rate': 2.7000000000000002e-05, 'epoch': 920.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0444, 'grad_norm': 0.03173738345503807, 'learning_rate': 2.6975000000000002e-05, 'epoch': 921.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0447, 'grad_norm': 0.03649662435054779, 'learning_rate': 2.6950000000000005e-05, 'epoch': 922.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0447, 'grad_norm': 0.0366348996758461, 'learning_rate': 2.6925e-05, 'epoch': 923.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0444, 'grad_norm': 0.03426089137792587, 'learning_rate': 2.6900000000000003e-05, 'epoch': 924.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0444, 'grad_norm': 0.037187740206718445, 'learning_rate': 2.6875e-05, 'epoch': 925.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0444, 'grad_norm': 0.03658761456608772, 'learning_rate': 2.6850000000000002e-05, 'epoch': 926.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0447, 'grad_norm': 0.03738157078623772, 'learning_rate': 2.6825e-05, 'epoch': 927.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0444, 'grad_norm': 0.0368315614759922, 'learning_rate': 2.6800000000000004e-05, 'epoch': 928.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0444, 'grad_norm': 0.030504804104566574, 'learning_rate': 2.6775e-05, 'epoch': 929.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0442, 'grad_norm': 0.03301892429590225, 'learning_rate': 2.6750000000000003e-05, 'epoch': 930.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0442, 'grad_norm': 0.04576609283685684, 'learning_rate': 2.6725e-05, 'epoch': 931.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0439, 'grad_norm': 0.031411025673151016, 'learning_rate': 2.6700000000000002e-05, 'epoch': 932.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0439, 'grad_norm': 0.048295632004737854, 'learning_rate': 2.6675e-05, 'epoch': 933.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0444, 'grad_norm': 0.06430181115865707, 'learning_rate': 2.6650000000000004e-05, 'epoch': 934.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0439, 'grad_norm': 0.026368947699666023, 'learning_rate': 2.6625e-05, 'epoch': 935.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0444, 'grad_norm': 0.02791658043861389, 'learning_rate': 2.6600000000000003e-05, 'epoch': 936.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0439, 'grad_norm': 0.03270378336310387, 'learning_rate': 2.6575e-05, 'epoch': 937.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0439, 'grad_norm': 0.04145897924900055, 'learning_rate': 2.655e-05, 'epoch': 938.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0442, 'grad_norm': 0.054130177944898605, 'learning_rate': 2.6525e-05, 'epoch': 939.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0442, 'grad_norm': 0.05548492446541786, 'learning_rate': 2.6500000000000004e-05, 'epoch': 940.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0439, 'grad_norm': 0.058987364172935486, 'learning_rate': 2.6475e-05, 'epoch': 941.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0439, 'grad_norm': 0.035622041672468185, 'learning_rate': 2.6450000000000003e-05, 'epoch': 942.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0439, 'grad_norm': 0.05132883042097092, 'learning_rate': 2.6425e-05, 'epoch': 943.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0439, 'grad_norm': 0.03675040602684021, 'learning_rate': 2.64e-05, 'epoch': 944.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0439, 'grad_norm': 0.04479258880019188, 'learning_rate': 2.6375e-05, 'epoch': 945.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.025035159662365913, 'learning_rate': 2.6350000000000004e-05, 'epoch': 946.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0437, 'grad_norm': 0.02828342467546463, 'learning_rate': 2.6325e-05, 'epoch': 947.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0437, 'grad_norm': 0.04576193541288376, 'learning_rate': 2.6300000000000002e-05, 'epoch': 948.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.05511222407221794, 'learning_rate': 2.6275e-05, 'epoch': 949.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.04063447192311287, 'learning_rate': 2.625e-05, 'epoch': 950.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.0740751400589943, 'learning_rate': 2.6225e-05, 'epoch': 951.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0437, 'grad_norm': 0.18680204451084137, 'learning_rate': 2.6200000000000003e-05, 'epoch': 952.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.04765026271343231, 'learning_rate': 2.6175e-05, 'epoch': 953.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0432, 'grad_norm': 0.0728621706366539, 'learning_rate': 2.6150000000000002e-05, 'epoch': 954.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.1800832897424698, 'learning_rate': 2.6124999999999998e-05, 'epoch': 955.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0432, 'grad_norm': 0.061568766832351685, 'learning_rate': 2.61e-05, 'epoch': 956.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0432, 'grad_norm': 0.039930038154125214, 'learning_rate': 2.6075e-05, 'epoch': 957.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.048642244189977646, 'learning_rate': 2.6050000000000003e-05, 'epoch': 958.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.24120895564556122, 'learning_rate': 2.6025e-05, 'epoch': 959.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.04551159217953682, 'learning_rate': 2.6000000000000002e-05, 'epoch': 960.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.07666763663291931, 'learning_rate': 2.5974999999999998e-05, 'epoch': 961.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.12191961705684662, 'learning_rate': 2.595e-05, 'epoch': 962.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.057943157851696014, 'learning_rate': 2.5925e-05, 'epoch': 963.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.03901905566453934, 'learning_rate': 2.5900000000000003e-05, 'epoch': 964.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.06230456009507179, 'learning_rate': 2.5875e-05, 'epoch': 965.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0432, 'grad_norm': 0.055130451917648315, 'learning_rate': 2.585e-05, 'epoch': 966.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.06514973193407059, 'learning_rate': 2.5824999999999998e-05, 'epoch': 967.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.05439406633377075, 'learning_rate': 2.58e-05, 'epoch': 968.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.08890751749277115, 'learning_rate': 2.5775e-05, 'epoch': 969.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.10057093948125839, 'learning_rate': 2.5750000000000002e-05, 'epoch': 970.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.028979018330574036, 'learning_rate': 2.5725e-05, 'epoch': 971.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.04116855934262276, 'learning_rate': 2.57e-05, 'epoch': 972.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.09292064607143402, 'learning_rate': 2.5675e-05, 'epoch': 973.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0432, 'grad_norm': 0.04186529666185379, 'learning_rate': 2.5650000000000003e-05, 'epoch': 974.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.03582506254315376, 'learning_rate': 2.5625e-05, 'epoch': 975.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.04579835385084152, 'learning_rate': 2.5600000000000002e-05, 'epoch': 976.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.06045495346188545, 'learning_rate': 2.5574999999999998e-05, 'epoch': 977.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.05281418189406395, 'learning_rate': 2.555e-05, 'epoch': 978.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0425, 'grad_norm': 0.037875354290008545, 'learning_rate': 2.5525e-05, 'epoch': 979.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.02568073943257332, 'learning_rate': 2.5500000000000003e-05, 'epoch': 980.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.08434339612722397, 'learning_rate': 2.5475e-05, 'epoch': 981.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.045531388372182846, 'learning_rate': 2.5450000000000002e-05, 'epoch': 982.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0425, 'grad_norm': 0.03564206510782242, 'learning_rate': 2.5424999999999998e-05, 'epoch': 983.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0425, 'grad_norm': 0.034745246171951294, 'learning_rate': 2.54e-05, 'epoch': 984.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.037580981850624084, 'learning_rate': 2.5375e-05, 'epoch': 985.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.032435279339551926, 'learning_rate': 2.5350000000000003e-05, 'epoch': 986.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0425, 'grad_norm': 0.1321408450603485, 'learning_rate': 2.5325e-05, 'epoch': 987.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.03550032526254654, 'learning_rate': 2.5300000000000002e-05, 'epoch': 988.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.1976291984319687, 'learning_rate': 2.5274999999999998e-05, 'epoch': 989.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0425, 'grad_norm': 0.06650671362876892, 'learning_rate': 2.525e-05, 'epoch': 990.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0425, 'grad_norm': 0.049940187484025955, 'learning_rate': 2.5225e-05, 'epoch': 991.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0425, 'grad_norm': 0.04560524597764015, 'learning_rate': 2.5200000000000003e-05, 'epoch': 992.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.05573353171348572, 'learning_rate': 2.5175e-05, 'epoch': 993.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.04684658348560333, 'learning_rate': 2.515e-05, 'epoch': 994.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.06482864171266556, 'learning_rate': 2.5124999999999997e-05, 'epoch': 995.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.0412764698266983, 'learning_rate': 2.51e-05, 'epoch': 996.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.04518234357237816, 'learning_rate': 2.5075e-05, 'epoch': 997.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0425, 'grad_norm': 0.04356495290994644, 'learning_rate': 2.5050000000000002e-05, 'epoch': 998.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.05203187093138695, 'learning_rate': 2.5025e-05, 'epoch': 999.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0425, 'grad_norm': 0.04669634625315666, 'learning_rate': 2.5e-05, 'epoch': 1000.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.07349877804517746, 'learning_rate': 2.4975e-05, 'epoch': 1001.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.051277849823236465, 'learning_rate': 2.495e-05, 'epoch': 1002.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.08463594317436218, 'learning_rate': 2.4925000000000003e-05, 'epoch': 1003.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0422, 'grad_norm': 0.13838668167591095, 'learning_rate': 2.4900000000000002e-05, 'epoch': 1004.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0422, 'grad_norm': 0.07588990032672882, 'learning_rate': 2.4875e-05, 'epoch': 1005.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0422, 'grad_norm': 0.11562700569629669, 'learning_rate': 2.485e-05, 'epoch': 1006.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.06545786559581757, 'learning_rate': 2.4825e-05, 'epoch': 1007.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.05295992270112038, 'learning_rate': 2.48e-05, 'epoch': 1008.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.09602183848619461, 'learning_rate': 2.4775000000000003e-05, 'epoch': 1009.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.08328679949045181, 'learning_rate': 2.4750000000000002e-05, 'epoch': 1010.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.04496043547987938, 'learning_rate': 2.4725e-05, 'epoch': 1011.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.048781249672174454, 'learning_rate': 2.47e-05, 'epoch': 1012.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.0794077143073082, 'learning_rate': 2.4675e-05, 'epoch': 1013.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.07284573465585709, 'learning_rate': 2.465e-05, 'epoch': 1014.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.05031105875968933, 'learning_rate': 2.4625000000000002e-05, 'epoch': 1015.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.05041870102286339, 'learning_rate': 2.46e-05, 'epoch': 1016.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.0833074152469635, 'learning_rate': 2.4575e-05, 'epoch': 1017.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.04321528971195221, 'learning_rate': 2.455e-05, 'epoch': 1018.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.20723265409469604, 'learning_rate': 2.4525e-05, 'epoch': 1019.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.06829046458005905, 'learning_rate': 2.45e-05, 'epoch': 1020.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.14697623252868652, 'learning_rate': 2.4475000000000002e-05, 'epoch': 1021.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.1387738138437271, 'learning_rate': 2.445e-05, 'epoch': 1022.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.13143043220043182, 'learning_rate': 2.4425e-05, 'epoch': 1023.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.03800203651189804, 'learning_rate': 2.44e-05, 'epoch': 1024.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.14231058955192566, 'learning_rate': 2.4375e-05, 'epoch': 1025.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.22434206306934357, 'learning_rate': 2.435e-05, 'epoch': 1026.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.0704207643866539, 'learning_rate': 2.4325000000000002e-05, 'epoch': 1027.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.267907053232193, 'learning_rate': 2.43e-05, 'epoch': 1028.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.07706935703754425, 'learning_rate': 2.4275e-05, 'epoch': 1029.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.0729714184999466, 'learning_rate': 2.425e-05, 'epoch': 1030.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.10032031685113907, 'learning_rate': 2.4225e-05, 'epoch': 1031.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.05030651390552521, 'learning_rate': 2.4200000000000002e-05, 'epoch': 1032.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0413, 'grad_norm': 0.0707244873046875, 'learning_rate': 2.4175e-05, 'epoch': 1033.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0413, 'grad_norm': 0.07700701802968979, 'learning_rate': 2.415e-05, 'epoch': 1034.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.08197517693042755, 'learning_rate': 2.4125e-05, 'epoch': 1035.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0413, 'grad_norm': 0.04606303572654724, 'learning_rate': 2.41e-05, 'epoch': 1036.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.2436162680387497, 'learning_rate': 2.4075e-05, 'epoch': 1037.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.041, 'grad_norm': 0.06927723437547684, 'learning_rate': 2.4050000000000002e-05, 'epoch': 1038.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.041, 'grad_norm': 0.044007666409015656, 'learning_rate': 2.4025e-05, 'epoch': 1039.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.041, 'grad_norm': 0.2287815809249878, 'learning_rate': 2.4e-05, 'epoch': 1040.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.16183462738990784, 'learning_rate': 2.3975e-05, 'epoch': 1041.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0413, 'grad_norm': 0.08889591693878174, 'learning_rate': 2.395e-05, 'epoch': 1042.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0413, 'grad_norm': 0.07733915746212006, 'learning_rate': 2.3925e-05, 'epoch': 1043.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.041, 'grad_norm': 0.0521039217710495, 'learning_rate': 2.39e-05, 'epoch': 1044.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0408, 'grad_norm': 0.04784005880355835, 'learning_rate': 2.3875e-05, 'epoch': 1045.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.041, 'grad_norm': 0.08066121488809586, 'learning_rate': 2.385e-05, 'epoch': 1046.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0408, 'grad_norm': 0.056314513087272644, 'learning_rate': 2.3825e-05, 'epoch': 1047.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0408, 'grad_norm': 0.1653674989938736, 'learning_rate': 2.38e-05, 'epoch': 1048.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0408, 'grad_norm': 0.08589493483304977, 'learning_rate': 2.3775e-05, 'epoch': 1049.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0408, 'grad_norm': 0.164596825838089, 'learning_rate': 2.375e-05, 'epoch': 1050.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0413, 'grad_norm': 0.5157554149627686, 'learning_rate': 2.3725e-05, 'epoch': 1051.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.041, 'grad_norm': 0.07608217746019363, 'learning_rate': 2.37e-05, 'epoch': 1052.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0437, 'grad_norm': 1.7832213640213013, 'learning_rate': 2.3675e-05, 'epoch': 1053.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0413, 'grad_norm': 0.11604062467813492, 'learning_rate': 2.365e-05, 'epoch': 1054.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0732, 'grad_norm': 28.916423797607422, 'learning_rate': 2.3624999999999998e-05, 'epoch': 1055.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.9173190593719482, 'learning_rate': 2.36e-05, 'epoch': 1056.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.4103202223777771, 'learning_rate': 2.3575e-05, 'epoch': 1057.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0723, 'grad_norm': 16.25525665283203, 'learning_rate': 2.355e-05, 'epoch': 1058.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 1.1875609159469604, 'learning_rate': 2.3525e-05, 'epoch': 1059.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0459, 'grad_norm': 1.651329755783081, 'learning_rate': 2.35e-05, 'epoch': 1060.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0457, 'grad_norm': 1.7684024572372437, 'learning_rate': 2.3475e-05, 'epoch': 1061.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0454, 'grad_norm': 0.7575256824493408, 'learning_rate': 2.345e-05, 'epoch': 1062.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0447, 'grad_norm': 0.28138336539268494, 'learning_rate': 2.3425000000000004e-05, 'epoch': 1063.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0471, 'grad_norm': 1.1334835290908813, 'learning_rate': 2.3400000000000003e-05, 'epoch': 1064.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0442, 'grad_norm': 0.20963095128536224, 'learning_rate': 2.3375000000000002e-05, 'epoch': 1065.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0452, 'grad_norm': 0.41467294096946716, 'learning_rate': 2.3350000000000002e-05, 'epoch': 1066.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0466, 'grad_norm': 0.664292573928833, 'learning_rate': 2.3325e-05, 'epoch': 1067.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0454, 'grad_norm': 0.23107868432998657, 'learning_rate': 2.3300000000000004e-05, 'epoch': 1068.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0454, 'grad_norm': 0.3535073697566986, 'learning_rate': 2.3275000000000003e-05, 'epoch': 1069.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0452, 'grad_norm': 0.19373178482055664, 'learning_rate': 2.3250000000000003e-05, 'epoch': 1070.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0452, 'grad_norm': 0.17051410675048828, 'learning_rate': 2.3225000000000002e-05, 'epoch': 1071.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0454, 'grad_norm': 0.18755294382572174, 'learning_rate': 2.32e-05, 'epoch': 1072.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0449, 'grad_norm': 0.09280088543891907, 'learning_rate': 2.3175e-05, 'epoch': 1073.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0449, 'grad_norm': 0.07468518614768982, 'learning_rate': 2.3150000000000004e-05, 'epoch': 1074.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0449, 'grad_norm': 0.298749715089798, 'learning_rate': 2.3125000000000003e-05, 'epoch': 1075.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0447, 'grad_norm': 0.09883633255958557, 'learning_rate': 2.3100000000000002e-05, 'epoch': 1076.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0444, 'grad_norm': 0.11942319571971893, 'learning_rate': 2.3075000000000002e-05, 'epoch': 1077.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0444, 'grad_norm': 0.14307492971420288, 'learning_rate': 2.305e-05, 'epoch': 1078.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0442, 'grad_norm': 0.053733307868242264, 'learning_rate': 2.3025e-05, 'epoch': 1079.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0442, 'grad_norm': 0.05669542774558067, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1080.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0439, 'grad_norm': 0.14557921886444092, 'learning_rate': 2.2975000000000003e-05, 'epoch': 1081.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0442, 'grad_norm': 0.05829600617289543, 'learning_rate': 2.2950000000000002e-05, 'epoch': 1082.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0439, 'grad_norm': 0.057124607264995575, 'learning_rate': 2.2925e-05, 'epoch': 1083.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0437, 'grad_norm': 0.06668464094400406, 'learning_rate': 2.29e-05, 'epoch': 1084.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.05444670468568802, 'learning_rate': 2.2875e-05, 'epoch': 1085.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.06252960860729218, 'learning_rate': 2.2850000000000003e-05, 'epoch': 1086.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.06588917225599289, 'learning_rate': 2.2825000000000003e-05, 'epoch': 1087.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0435, 'grad_norm': 0.04411526769399643, 'learning_rate': 2.2800000000000002e-05, 'epoch': 1088.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0432, 'grad_norm': 0.04483115300536156, 'learning_rate': 2.2775e-05, 'epoch': 1089.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0432, 'grad_norm': 0.04695134237408638, 'learning_rate': 2.275e-05, 'epoch': 1090.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.0443672314286232, 'learning_rate': 2.2725000000000003e-05, 'epoch': 1091.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.043, 'grad_norm': 0.04862441122531891, 'learning_rate': 2.2700000000000003e-05, 'epoch': 1092.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.04838605970144272, 'learning_rate': 2.2675000000000002e-05, 'epoch': 1093.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0425, 'grad_norm': 0.04945850744843483, 'learning_rate': 2.265e-05, 'epoch': 1094.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0427, 'grad_norm': 0.06865101307630539, 'learning_rate': 2.2625e-05, 'epoch': 1095.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0425, 'grad_norm': 0.04860075190663338, 'learning_rate': 2.26e-05, 'epoch': 1096.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.036303021013736725, 'learning_rate': 2.2575000000000003e-05, 'epoch': 1097.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0422, 'grad_norm': 0.07301989942789078, 'learning_rate': 2.2550000000000003e-05, 'epoch': 1098.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.04747938737273216, 'learning_rate': 2.2525000000000002e-05, 'epoch': 1099.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.042, 'grad_norm': 0.04382578283548355, 'learning_rate': 2.25e-05, 'epoch': 1100.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.04179644584655762, 'learning_rate': 2.2475e-05, 'epoch': 1101.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.03657504543662071, 'learning_rate': 2.245e-05, 'epoch': 1102.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.03735889866948128, 'learning_rate': 2.2425000000000003e-05, 'epoch': 1103.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.03021882474422455, 'learning_rate': 2.2400000000000002e-05, 'epoch': 1104.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0417, 'grad_norm': 0.07689075171947479, 'learning_rate': 2.2375000000000002e-05, 'epoch': 1105.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.041, 'grad_norm': 0.036114539951086044, 'learning_rate': 2.235e-05, 'epoch': 1106.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0413, 'grad_norm': 0.028510503470897675, 'learning_rate': 2.2325e-05, 'epoch': 1107.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0413, 'grad_norm': 0.03449477627873421, 'learning_rate': 2.23e-05, 'epoch': 1108.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0413, 'grad_norm': 0.05354892089962959, 'learning_rate': 2.2275000000000003e-05, 'epoch': 1109.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.041, 'grad_norm': 0.04965880885720253, 'learning_rate': 2.2250000000000002e-05, 'epoch': 1110.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0415, 'grad_norm': 0.03929053619503975, 'learning_rate': 2.2225e-05, 'epoch': 1111.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0413, 'grad_norm': 0.055622681975364685, 'learning_rate': 2.22e-05, 'epoch': 1112.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0408, 'grad_norm': 0.03508129343390465, 'learning_rate': 2.2175e-05, 'epoch': 1113.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0405, 'grad_norm': 0.03017503395676613, 'learning_rate': 2.215e-05, 'epoch': 1114.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.041, 'grad_norm': 0.05695157125592232, 'learning_rate': 2.2125000000000002e-05, 'epoch': 1115.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.041, 'grad_norm': 0.05684298276901245, 'learning_rate': 2.2100000000000002e-05, 'epoch': 1116.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0405, 'grad_norm': 0.05104401707649231, 'learning_rate': 2.2075e-05, 'epoch': 1117.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0405, 'grad_norm': 0.03920586779713631, 'learning_rate': 2.205e-05, 'epoch': 1118.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0405, 'grad_norm': 0.03086395375430584, 'learning_rate': 2.2025e-05, 'epoch': 1119.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0405, 'grad_norm': 0.028904030099511147, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1120.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0408, 'grad_norm': 0.04802808538079262, 'learning_rate': 2.1975000000000002e-05, 'epoch': 1121.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0405, 'grad_norm': 0.03355593606829643, 'learning_rate': 2.195e-05, 'epoch': 1122.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0408, 'grad_norm': 0.03146197274327278, 'learning_rate': 2.1925e-05, 'epoch': 1123.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0403, 'grad_norm': 0.050962578505277634, 'learning_rate': 2.19e-05, 'epoch': 1124.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0403, 'grad_norm': 0.035925548523664474, 'learning_rate': 2.1875e-05, 'epoch': 1125.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0405, 'grad_norm': 0.036198485642671585, 'learning_rate': 2.1850000000000003e-05, 'epoch': 1126.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0403, 'grad_norm': 0.048340413719415665, 'learning_rate': 2.1825000000000002e-05, 'epoch': 1127.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.04, 'grad_norm': 0.041109658777713776, 'learning_rate': 2.18e-05, 'epoch': 1128.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0403, 'grad_norm': 0.027619244530797005, 'learning_rate': 2.1775e-05, 'epoch': 1129.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.04, 'grad_norm': 0.050593119114637375, 'learning_rate': 2.175e-05, 'epoch': 1130.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0403, 'grad_norm': 0.05800723657011986, 'learning_rate': 2.1725e-05, 'epoch': 1131.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.04, 'grad_norm': 0.04098375514149666, 'learning_rate': 2.1700000000000002e-05, 'epoch': 1132.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.04, 'grad_norm': 0.04534738510847092, 'learning_rate': 2.1675e-05, 'epoch': 1133.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.04, 'grad_norm': 0.04782339185476303, 'learning_rate': 2.165e-05, 'epoch': 1134.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0398, 'grad_norm': 0.04239245131611824, 'learning_rate': 2.1625e-05, 'epoch': 1135.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0398, 'grad_norm': 0.04254726693034172, 'learning_rate': 2.16e-05, 'epoch': 1136.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0396, 'grad_norm': 0.03729192912578583, 'learning_rate': 2.1575e-05, 'epoch': 1137.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.04, 'grad_norm': 0.08766268193721771, 'learning_rate': 2.1550000000000002e-05, 'epoch': 1138.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0398, 'grad_norm': 0.04153299331665039, 'learning_rate': 2.1525e-05, 'epoch': 1139.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0398, 'grad_norm': 0.05770842730998993, 'learning_rate': 2.15e-05, 'epoch': 1140.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0398, 'grad_norm': 0.042771127074956894, 'learning_rate': 2.1475e-05, 'epoch': 1141.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0396, 'grad_norm': 0.048155494034290314, 'learning_rate': 2.145e-05, 'epoch': 1142.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0393, 'grad_norm': 0.04294028878211975, 'learning_rate': 2.1425e-05, 'epoch': 1143.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.04, 'grad_norm': 0.08663305640220642, 'learning_rate': 2.1400000000000002e-05, 'epoch': 1144.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0398, 'grad_norm': 0.055866360664367676, 'learning_rate': 2.1375e-05, 'epoch': 1145.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0393, 'grad_norm': 0.05890529230237007, 'learning_rate': 2.135e-05, 'epoch': 1146.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0396, 'grad_norm': 0.04545297846198082, 'learning_rate': 2.1325e-05, 'epoch': 1147.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.12463398277759552, 'learning_rate': 2.13e-05, 'epoch': 1148.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0396, 'grad_norm': 0.04862244799733162, 'learning_rate': 2.1275000000000002e-05, 'epoch': 1149.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0393, 'grad_norm': 0.04161492735147476, 'learning_rate': 2.125e-05, 'epoch': 1150.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0398, 'grad_norm': 0.08291274309158325, 'learning_rate': 2.1225e-05, 'epoch': 1151.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0388, 'grad_norm': 0.03885750100016594, 'learning_rate': 2.12e-05, 'epoch': 1152.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0393, 'grad_norm': 0.05834423005580902, 'learning_rate': 2.1175e-05, 'epoch': 1153.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.060149192810058594, 'learning_rate': 2.115e-05, 'epoch': 1154.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.05276137590408325, 'learning_rate': 2.1125000000000002e-05, 'epoch': 1155.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.0461268313229084, 'learning_rate': 2.11e-05, 'epoch': 1156.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0388, 'grad_norm': 0.06647133827209473, 'learning_rate': 2.1075e-05, 'epoch': 1157.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.12113209813833237, 'learning_rate': 2.105e-05, 'epoch': 1158.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.04299294948577881, 'learning_rate': 2.1025e-05, 'epoch': 1159.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0388, 'grad_norm': 0.05447527766227722, 'learning_rate': 2.1e-05, 'epoch': 1160.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0393, 'grad_norm': 0.09500584006309509, 'learning_rate': 2.0975e-05, 'epoch': 1161.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0388, 'grad_norm': 0.03563746064901352, 'learning_rate': 2.095e-05, 'epoch': 1162.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.049558911472558975, 'learning_rate': 2.0925e-05, 'epoch': 1163.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.04475995525717735, 'learning_rate': 2.09e-05, 'epoch': 1164.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0386, 'grad_norm': 0.0469864159822464, 'learning_rate': 2.0875e-05, 'epoch': 1165.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0386, 'grad_norm': 0.06397701054811478, 'learning_rate': 2.085e-05, 'epoch': 1166.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.09173732250928879, 'learning_rate': 2.0825e-05, 'epoch': 1167.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0386, 'grad_norm': 0.05654925853013992, 'learning_rate': 2.08e-05, 'epoch': 1168.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0386, 'grad_norm': 0.04396006464958191, 'learning_rate': 2.0775e-05, 'epoch': 1169.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0386, 'grad_norm': 0.06882429867982864, 'learning_rate': 2.075e-05, 'epoch': 1170.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.08699730783700943, 'learning_rate': 2.0725e-05, 'epoch': 1171.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0386, 'grad_norm': 0.09051524102687836, 'learning_rate': 2.07e-05, 'epoch': 1172.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0386, 'grad_norm': 0.06000586971640587, 'learning_rate': 2.0675e-05, 'epoch': 1173.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.0726967304944992, 'learning_rate': 2.065e-05, 'epoch': 1174.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.04604373499751091, 'learning_rate': 2.0625e-05, 'epoch': 1175.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.09672830998897552, 'learning_rate': 2.06e-05, 'epoch': 1176.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0386, 'grad_norm': 0.04094807431101799, 'learning_rate': 2.0575e-05, 'epoch': 1177.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.04317271709442139, 'learning_rate': 2.055e-05, 'epoch': 1178.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.04606802016496658, 'learning_rate': 2.0525e-05, 'epoch': 1179.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.08222514390945435, 'learning_rate': 2.05e-05, 'epoch': 1180.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.045637551695108414, 'learning_rate': 2.0475e-05, 'epoch': 1181.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0381, 'grad_norm': 0.06926264613866806, 'learning_rate': 2.045e-05, 'epoch': 1182.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0378, 'grad_norm': 0.04074203595519066, 'learning_rate': 2.0425e-05, 'epoch': 1183.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0381, 'grad_norm': 0.06284985691308975, 'learning_rate': 2.04e-05, 'epoch': 1184.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0381, 'grad_norm': 0.05280076712369919, 'learning_rate': 2.0375e-05, 'epoch': 1185.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.10435079038143158, 'learning_rate': 2.035e-05, 'epoch': 1186.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0381, 'grad_norm': 0.09481894224882126, 'learning_rate': 2.0325e-05, 'epoch': 1187.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0378, 'grad_norm': 0.060025542974472046, 'learning_rate': 2.0300000000000002e-05, 'epoch': 1188.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.07269084453582764, 'learning_rate': 2.0275e-05, 'epoch': 1189.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.21972046792507172, 'learning_rate': 2.025e-05, 'epoch': 1190.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0378, 'grad_norm': 0.057044848799705505, 'learning_rate': 2.0225000000000004e-05, 'epoch': 1191.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0388, 'grad_norm': 1.2739975452423096, 'learning_rate': 2.0200000000000003e-05, 'epoch': 1192.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0386, 'grad_norm': 0.41771265864372253, 'learning_rate': 2.0175000000000003e-05, 'epoch': 1193.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0403, 'grad_norm': 1.1355799436569214, 'learning_rate': 2.0150000000000002e-05, 'epoch': 1194.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.09777127951383591, 'learning_rate': 2.0125e-05, 'epoch': 1195.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0742, 'grad_norm': 20.004297256469727, 'learning_rate': 2.01e-05, 'epoch': 1196.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0393, 'grad_norm': 0.5058379173278809, 'learning_rate': 2.0075000000000003e-05, 'epoch': 1197.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0388, 'grad_norm': 0.18739263713359833, 'learning_rate': 2.0050000000000003e-05, 'epoch': 1198.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0413, 'grad_norm': 0.8124637007713318, 'learning_rate': 2.0025000000000002e-05, 'epoch': 1199.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0393, 'grad_norm': 0.19529446959495544, 'learning_rate': 2e-05, 'epoch': 1200.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.04, 'grad_norm': 0.2065085470676422, 'learning_rate': 1.9975e-05, 'epoch': 1201.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0396, 'grad_norm': 0.17003104090690613, 'learning_rate': 1.995e-05, 'epoch': 1202.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0398, 'grad_norm': 0.17031851410865784, 'learning_rate': 1.9925000000000003e-05, 'epoch': 1203.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.041, 'grad_norm': 0.5650390982627869, 'learning_rate': 1.9900000000000003e-05, 'epoch': 1204.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0398, 'grad_norm': 0.1299060434103012, 'learning_rate': 1.9875000000000002e-05, 'epoch': 1205.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0396, 'grad_norm': 0.07634484022855759, 'learning_rate': 1.985e-05, 'epoch': 1206.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0393, 'grad_norm': 0.08876526355743408, 'learning_rate': 1.9825e-05, 'epoch': 1207.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0393, 'grad_norm': 0.19322535395622253, 'learning_rate': 1.9800000000000004e-05, 'epoch': 1208.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0396, 'grad_norm': 0.14558197557926178, 'learning_rate': 1.9775000000000003e-05, 'epoch': 1209.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.10909002274274826, 'learning_rate': 1.9750000000000002e-05, 'epoch': 1210.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.10026698559522629, 'learning_rate': 1.9725000000000002e-05, 'epoch': 1211.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0388, 'grad_norm': 0.0731041431427002, 'learning_rate': 1.97e-05, 'epoch': 1212.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0393, 'grad_norm': 0.0838065892457962, 'learning_rate': 1.9675e-05, 'epoch': 1213.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.06106792017817497, 'learning_rate': 1.9650000000000003e-05, 'epoch': 1214.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.15777254104614258, 'learning_rate': 1.9625000000000003e-05, 'epoch': 1215.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0388, 'grad_norm': 0.1171388104557991, 'learning_rate': 1.9600000000000002e-05, 'epoch': 1216.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0391, 'grad_norm': 0.15087391436100006, 'learning_rate': 1.9575e-05, 'epoch': 1217.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0381, 'grad_norm': 0.07491196691989899, 'learning_rate': 1.955e-05, 'epoch': 1218.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0386, 'grad_norm': 0.0841609314084053, 'learning_rate': 1.9525e-05, 'epoch': 1219.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.05337900668382645, 'learning_rate': 1.9500000000000003e-05, 'epoch': 1220.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.10552261769771576, 'learning_rate': 1.9475000000000002e-05, 'epoch': 1221.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0381, 'grad_norm': 0.07188847661018372, 'learning_rate': 1.9450000000000002e-05, 'epoch': 1222.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0381, 'grad_norm': 0.07750604301691055, 'learning_rate': 1.9425e-05, 'epoch': 1223.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.06513477861881256, 'learning_rate': 1.94e-05, 'epoch': 1224.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0381, 'grad_norm': 0.06945726275444031, 'learning_rate': 1.9375e-05, 'epoch': 1225.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0378, 'grad_norm': 0.07277466356754303, 'learning_rate': 1.9350000000000003e-05, 'epoch': 1226.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0381, 'grad_norm': 0.06836042553186417, 'learning_rate': 1.9325000000000002e-05, 'epoch': 1227.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0378, 'grad_norm': 0.08336286246776581, 'learning_rate': 1.93e-05, 'epoch': 1228.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0376, 'grad_norm': 0.04442354291677475, 'learning_rate': 1.9275e-05, 'epoch': 1229.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0376, 'grad_norm': 0.050349265336990356, 'learning_rate': 1.925e-05, 'epoch': 1230.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.07140595465898514, 'learning_rate': 1.9225e-05, 'epoch': 1231.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0376, 'grad_norm': 0.09469185769557953, 'learning_rate': 1.9200000000000003e-05, 'epoch': 1232.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.0678139328956604, 'learning_rate': 1.9175000000000002e-05, 'epoch': 1233.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.04717409983277321, 'learning_rate': 1.915e-05, 'epoch': 1234.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.04499293491244316, 'learning_rate': 1.9125e-05, 'epoch': 1235.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0376, 'grad_norm': 0.043220724910497665, 'learning_rate': 1.91e-05, 'epoch': 1236.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.09118928760290146, 'learning_rate': 1.9075000000000003e-05, 'epoch': 1237.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.11048506945371628, 'learning_rate': 1.9050000000000002e-05, 'epoch': 1238.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.04180799424648285, 'learning_rate': 1.9025e-05, 'epoch': 1239.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0369, 'grad_norm': 0.043208736926317215, 'learning_rate': 1.9e-05, 'epoch': 1240.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.07485322654247284, 'learning_rate': 1.8975e-05, 'epoch': 1241.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.17927180230617523, 'learning_rate': 1.895e-05, 'epoch': 1242.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0369, 'grad_norm': 0.061065517365932465, 'learning_rate': 1.8925000000000003e-05, 'epoch': 1243.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0369, 'grad_norm': 0.05616159737110138, 'learning_rate': 1.8900000000000002e-05, 'epoch': 1244.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.06884675472974777, 'learning_rate': 1.8875e-05, 'epoch': 1245.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.05438508465886116, 'learning_rate': 1.885e-05, 'epoch': 1246.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.06615713983774185, 'learning_rate': 1.8825e-05, 'epoch': 1247.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0369, 'grad_norm': 0.04499807208776474, 'learning_rate': 1.88e-05, 'epoch': 1248.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0369, 'grad_norm': 0.04977688565850258, 'learning_rate': 1.8775000000000002e-05, 'epoch': 1249.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.05111236870288849, 'learning_rate': 1.8750000000000002e-05, 'epoch': 1250.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.15790654718875885, 'learning_rate': 1.8725e-05, 'epoch': 1251.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.055701471865177155, 'learning_rate': 1.87e-05, 'epoch': 1252.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.0700768455862999, 'learning_rate': 1.8675e-05, 'epoch': 1253.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.0546167828142643, 'learning_rate': 1.865e-05, 'epoch': 1254.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.08011095225811005, 'learning_rate': 1.8625000000000002e-05, 'epoch': 1255.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.04488420486450195, 'learning_rate': 1.86e-05, 'epoch': 1256.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.05900593474507332, 'learning_rate': 1.8575e-05, 'epoch': 1257.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.038572605699300766, 'learning_rate': 1.855e-05, 'epoch': 1258.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.1421930491924286, 'learning_rate': 1.8525e-05, 'epoch': 1259.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.052492331713438034, 'learning_rate': 1.85e-05, 'epoch': 1260.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.05420759320259094, 'learning_rate': 1.8475000000000002e-05, 'epoch': 1261.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.06304223835468292, 'learning_rate': 1.845e-05, 'epoch': 1262.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.12372442334890366, 'learning_rate': 1.8425e-05, 'epoch': 1263.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.060231760144233704, 'learning_rate': 1.84e-05, 'epoch': 1264.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0364, 'grad_norm': 0.03719170391559601, 'learning_rate': 1.8375e-05, 'epoch': 1265.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.0696156844496727, 'learning_rate': 1.8350000000000002e-05, 'epoch': 1266.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.12519103288650513, 'learning_rate': 1.8325e-05, 'epoch': 1267.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.08329124003648758, 'learning_rate': 1.83e-05, 'epoch': 1268.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0359, 'grad_norm': 0.08380346745252609, 'learning_rate': 1.8275e-05, 'epoch': 1269.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.0943332388997078, 'learning_rate': 1.825e-05, 'epoch': 1270.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0364, 'grad_norm': 0.14044547080993652, 'learning_rate': 1.8225e-05, 'epoch': 1271.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0356, 'grad_norm': 0.08831848204135895, 'learning_rate': 1.8200000000000002e-05, 'epoch': 1272.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.1006455048918724, 'learning_rate': 1.8175e-05, 'epoch': 1273.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0359, 'grad_norm': 0.16729198396205902, 'learning_rate': 1.815e-05, 'epoch': 1274.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.07340503484010696, 'learning_rate': 1.8125e-05, 'epoch': 1275.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0356, 'grad_norm': 0.06523296982049942, 'learning_rate': 1.81e-05, 'epoch': 1276.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0359, 'grad_norm': 0.10394947230815887, 'learning_rate': 1.8075e-05, 'epoch': 1277.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0356, 'grad_norm': 0.09505865722894669, 'learning_rate': 1.805e-05, 'epoch': 1278.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0356, 'grad_norm': 0.05344795063138008, 'learning_rate': 1.8025e-05, 'epoch': 1279.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.1443297415971756, 'learning_rate': 1.8e-05, 'epoch': 1280.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0356, 'grad_norm': 0.08975328505039215, 'learning_rate': 1.7975e-05, 'epoch': 1281.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.41327357292175293, 'learning_rate': 1.795e-05, 'epoch': 1282.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.07069816440343857, 'learning_rate': 1.7925e-05, 'epoch': 1283.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.9874077439308167, 'learning_rate': 1.79e-05, 'epoch': 1284.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.29735052585601807, 'learning_rate': 1.7875e-05, 'epoch': 1285.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0386, 'grad_norm': 1.9455039501190186, 'learning_rate': 1.785e-05, 'epoch': 1286.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0369, 'grad_norm': 0.2911708354949951, 'learning_rate': 1.7825e-05, 'epoch': 1287.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.21771371364593506, 'learning_rate': 1.78e-05, 'epoch': 1288.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0388, 'grad_norm': 1.611987590789795, 'learning_rate': 1.7775e-05, 'epoch': 1289.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.16174402832984924, 'learning_rate': 1.775e-05, 'epoch': 1290.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.5669229030609131, 'learning_rate': 1.7725e-05, 'epoch': 1291.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.33600008487701416, 'learning_rate': 1.77e-05, 'epoch': 1292.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.14967089891433716, 'learning_rate': 1.7675e-05, 'epoch': 1293.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0369, 'grad_norm': 0.2068520188331604, 'learning_rate': 1.765e-05, 'epoch': 1294.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.2653520405292511, 'learning_rate': 1.7625e-05, 'epoch': 1295.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.1419033408164978, 'learning_rate': 1.76e-05, 'epoch': 1296.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0369, 'grad_norm': 0.08633831888437271, 'learning_rate': 1.7575e-05, 'epoch': 1297.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0364, 'grad_norm': 0.1381973773241043, 'learning_rate': 1.755e-05, 'epoch': 1298.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0369, 'grad_norm': 0.13213594257831573, 'learning_rate': 1.7525e-05, 'epoch': 1299.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.09656365215778351, 'learning_rate': 1.75e-05, 'epoch': 1300.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0364, 'grad_norm': 0.07644594460725784, 'learning_rate': 1.7475e-05, 'epoch': 1301.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.0966741070151329, 'learning_rate': 1.745e-05, 'epoch': 1302.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0364, 'grad_norm': 0.09093551337718964, 'learning_rate': 1.7425e-05, 'epoch': 1303.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0364, 'grad_norm': 0.18237638473510742, 'learning_rate': 1.74e-05, 'epoch': 1304.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0359, 'grad_norm': 0.0995275229215622, 'learning_rate': 1.7375e-05, 'epoch': 1305.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0359, 'grad_norm': 0.09006468206644058, 'learning_rate': 1.7349999999999998e-05, 'epoch': 1306.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0359, 'grad_norm': 0.06022730469703674, 'learning_rate': 1.7325e-05, 'epoch': 1307.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.05581868439912796, 'learning_rate': 1.73e-05, 'epoch': 1308.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.08484270423650742, 'learning_rate': 1.7275e-05, 'epoch': 1309.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0354, 'grad_norm': 0.07917962968349457, 'learning_rate': 1.725e-05, 'epoch': 1310.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0356, 'grad_norm': 0.06527982652187347, 'learning_rate': 1.7225e-05, 'epoch': 1311.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0354, 'grad_norm': 0.055633340030908585, 'learning_rate': 1.7199999999999998e-05, 'epoch': 1312.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0359, 'grad_norm': 0.18378998339176178, 'learning_rate': 1.7175e-05, 'epoch': 1313.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0356, 'grad_norm': 0.05722540616989136, 'learning_rate': 1.7150000000000004e-05, 'epoch': 1314.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0354, 'grad_norm': 0.06983768939971924, 'learning_rate': 1.7125000000000003e-05, 'epoch': 1315.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0354, 'grad_norm': 0.13193753361701965, 'learning_rate': 1.7100000000000002e-05, 'epoch': 1316.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0354, 'grad_norm': 0.08799333870410919, 'learning_rate': 1.7075e-05, 'epoch': 1317.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0354, 'grad_norm': 0.1020410805940628, 'learning_rate': 1.705e-05, 'epoch': 1318.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0349, 'grad_norm': 0.07580167055130005, 'learning_rate': 1.7025e-05, 'epoch': 1319.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0354, 'grad_norm': 0.08367525786161423, 'learning_rate': 1.7000000000000003e-05, 'epoch': 1320.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0354, 'grad_norm': 0.12261532247066498, 'learning_rate': 1.6975000000000003e-05, 'epoch': 1321.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0352, 'grad_norm': 0.05071849748492241, 'learning_rate': 1.6950000000000002e-05, 'epoch': 1322.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0352, 'grad_norm': 0.061154842376708984, 'learning_rate': 1.6925e-05, 'epoch': 1323.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0352, 'grad_norm': 0.07321269065141678, 'learning_rate': 1.69e-05, 'epoch': 1324.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0352, 'grad_norm': 0.08476298302412033, 'learning_rate': 1.6875000000000004e-05, 'epoch': 1325.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0352, 'grad_norm': 0.18748614192008972, 'learning_rate': 1.6850000000000003e-05, 'epoch': 1326.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0349, 'grad_norm': 0.05550254136323929, 'learning_rate': 1.6825000000000002e-05, 'epoch': 1327.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0349, 'grad_norm': 0.06808184087276459, 'learning_rate': 1.6800000000000002e-05, 'epoch': 1328.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0349, 'grad_norm': 0.07389987260103226, 'learning_rate': 1.6775e-05, 'epoch': 1329.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0347, 'grad_norm': 0.495329350233078, 'learning_rate': 1.675e-05, 'epoch': 1330.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0349, 'grad_norm': 0.04843631014227867, 'learning_rate': 1.6725000000000003e-05, 'epoch': 1331.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0356, 'grad_norm': 0.17428670823574066, 'learning_rate': 1.6700000000000003e-05, 'epoch': 1332.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0359, 'grad_norm': 0.640841543674469, 'learning_rate': 1.6675000000000002e-05, 'epoch': 1333.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0352, 'grad_norm': 0.09103874862194061, 'learning_rate': 1.665e-05, 'epoch': 1334.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0356, 'grad_norm': 0.3315197229385376, 'learning_rate': 1.6625e-05, 'epoch': 1335.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0378, 'grad_norm': 3.407552480697632, 'learning_rate': 1.66e-05, 'epoch': 1336.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0352, 'grad_norm': 0.14361299574375153, 'learning_rate': 1.6575000000000003e-05, 'epoch': 1337.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.45234325528144836, 'learning_rate': 1.6550000000000002e-05, 'epoch': 1338.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0364, 'grad_norm': 0.24219532310962677, 'learning_rate': 1.6525000000000002e-05, 'epoch': 1339.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0364, 'grad_norm': 0.258518248796463, 'learning_rate': 1.65e-05, 'epoch': 1340.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 2.181666851043701, 'learning_rate': 1.6475e-05, 'epoch': 1341.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0359, 'grad_norm': 0.4042659103870392, 'learning_rate': 1.645e-05, 'epoch': 1342.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0518, 'grad_norm': 19.691932678222656, 'learning_rate': 1.6425000000000003e-05, 'epoch': 1343.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.4167565703392029, 'learning_rate': 1.6400000000000002e-05, 'epoch': 1344.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.3475431799888611, 'learning_rate': 1.6375e-05, 'epoch': 1345.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0393, 'grad_norm': 1.7524561882019043, 'learning_rate': 1.635e-05, 'epoch': 1346.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.2908124029636383, 'learning_rate': 1.6325e-05, 'epoch': 1347.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0369, 'grad_norm': 0.2016146034002304, 'learning_rate': 1.63e-05, 'epoch': 1348.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0449, 'grad_norm': 7.867116451263428, 'learning_rate': 1.6275000000000003e-05, 'epoch': 1349.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0386, 'grad_norm': 0.6209650039672852, 'learning_rate': 1.6250000000000002e-05, 'epoch': 1350.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0381, 'grad_norm': 0.4106666147708893, 'learning_rate': 1.6225e-05, 'epoch': 1351.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.825145959854126, 'learning_rate': 1.62e-05, 'epoch': 1352.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.2151266485452652, 'learning_rate': 1.6175e-05, 'epoch': 1353.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0403, 'grad_norm': 2.389725685119629, 'learning_rate': 1.6150000000000003e-05, 'epoch': 1354.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0381, 'grad_norm': 0.8587801456451416, 'learning_rate': 1.6125000000000002e-05, 'epoch': 1355.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.32337674498558044, 'learning_rate': 1.6100000000000002e-05, 'epoch': 1356.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0393, 'grad_norm': 1.5866111516952515, 'learning_rate': 1.6075e-05, 'epoch': 1357.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0376, 'grad_norm': 0.1835222989320755, 'learning_rate': 1.605e-05, 'epoch': 1358.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0388, 'grad_norm': 0.36030134558677673, 'learning_rate': 1.6025e-05, 'epoch': 1359.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0386, 'grad_norm': 0.3071727454662323, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1360.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0383, 'grad_norm': 0.30203238129615784, 'learning_rate': 1.5975000000000002e-05, 'epoch': 1361.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0381, 'grad_norm': 0.19307941198349, 'learning_rate': 1.595e-05, 'epoch': 1362.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.3633204400539398, 'learning_rate': 1.5925e-05, 'epoch': 1363.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0374, 'grad_norm': 0.15396903455257416, 'learning_rate': 1.59e-05, 'epoch': 1364.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0378, 'grad_norm': 0.4827505648136139, 'learning_rate': 1.5875e-05, 'epoch': 1365.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0371, 'grad_norm': 0.27925702929496765, 'learning_rate': 1.5850000000000002e-05, 'epoch': 1366.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.11279790848493576, 'learning_rate': 1.5825000000000002e-05, 'epoch': 1367.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.18873539566993713, 'learning_rate': 1.58e-05, 'epoch': 1368.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0366, 'grad_norm': 0.1198204904794693, 'learning_rate': 1.5775e-05, 'epoch': 1369.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.13853022456169128, 'learning_rate': 1.575e-05, 'epoch': 1370.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0364, 'grad_norm': 0.11392658948898315, 'learning_rate': 1.5725e-05, 'epoch': 1371.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0369, 'grad_norm': 0.129709392786026, 'learning_rate': 1.5700000000000002e-05, 'epoch': 1372.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.0710492953658104, 'learning_rate': 1.5675e-05, 'epoch': 1373.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0364, 'grad_norm': 0.13763733208179474, 'learning_rate': 1.565e-05, 'epoch': 1374.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.17144683003425598, 'learning_rate': 1.5625e-05, 'epoch': 1375.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0359, 'grad_norm': 0.17443661391735077, 'learning_rate': 1.56e-05, 'epoch': 1376.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0359, 'grad_norm': 0.08070908486843109, 'learning_rate': 1.5575e-05, 'epoch': 1377.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.08546414226293564, 'learning_rate': 1.5550000000000002e-05, 'epoch': 1378.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.23380142450332642, 'learning_rate': 1.5525e-05, 'epoch': 1379.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0361, 'grad_norm': 0.14635105431079865, 'learning_rate': 1.55e-05, 'epoch': 1380.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0359, 'grad_norm': 0.14129699766635895, 'learning_rate': 1.5475e-05, 'epoch': 1381.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0354, 'grad_norm': 0.0976211428642273, 'learning_rate': 1.545e-05, 'epoch': 1382.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0356, 'grad_norm': 0.08007801324129105, 'learning_rate': 1.5425000000000002e-05, 'epoch': 1383.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0352, 'grad_norm': 0.07290008664131165, 'learning_rate': 1.54e-05, 'epoch': 1384.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0359, 'grad_norm': 0.3593371510505676, 'learning_rate': 1.5375e-05, 'epoch': 1385.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0354, 'grad_norm': 0.047596611082553864, 'learning_rate': 1.535e-05, 'epoch': 1386.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0352, 'grad_norm': 0.07102130353450775, 'learning_rate': 1.5325e-05, 'epoch': 1387.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0349, 'grad_norm': 0.08459043502807617, 'learning_rate': 1.53e-05, 'epoch': 1388.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0352, 'grad_norm': 0.08893444389104843, 'learning_rate': 1.5275000000000002e-05, 'epoch': 1389.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0349, 'grad_norm': 0.0757628083229065, 'learning_rate': 1.525e-05, 'epoch': 1390.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0349, 'grad_norm': 0.06836660206317902, 'learning_rate': 1.5225e-05, 'epoch': 1391.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0349, 'grad_norm': 0.10153691470623016, 'learning_rate': 1.52e-05, 'epoch': 1392.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0352, 'grad_norm': 0.065933957695961, 'learning_rate': 1.5175e-05, 'epoch': 1393.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0347, 'grad_norm': 0.06792909651994705, 'learning_rate': 1.515e-05, 'epoch': 1394.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0349, 'grad_norm': 0.06365584582090378, 'learning_rate': 1.5125e-05, 'epoch': 1395.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0344, 'grad_norm': 0.07529566437005997, 'learning_rate': 1.51e-05, 'epoch': 1396.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0349, 'grad_norm': 0.0520985908806324, 'learning_rate': 1.5075e-05, 'epoch': 1397.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0342, 'grad_norm': 0.06449199467897415, 'learning_rate': 1.505e-05, 'epoch': 1398.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0344, 'grad_norm': 0.06927797198295593, 'learning_rate': 1.5025000000000001e-05, 'epoch': 1399.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0344, 'grad_norm': 0.16209569573402405, 'learning_rate': 1.5e-05, 'epoch': 1400.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0344, 'grad_norm': 0.10058381408452988, 'learning_rate': 1.4975e-05, 'epoch': 1401.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0342, 'grad_norm': 0.05578665807843208, 'learning_rate': 1.4950000000000001e-05, 'epoch': 1402.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0344, 'grad_norm': 0.11822859197854996, 'learning_rate': 1.4925e-05, 'epoch': 1403.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0342, 'grad_norm': 0.10968958586454391, 'learning_rate': 1.49e-05, 'epoch': 1404.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0342, 'grad_norm': 0.0885763019323349, 'learning_rate': 1.4875e-05, 'epoch': 1405.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0344, 'grad_norm': 0.09627319127321243, 'learning_rate': 1.485e-05, 'epoch': 1406.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0339, 'grad_norm': 0.09097122400999069, 'learning_rate': 1.4825e-05, 'epoch': 1407.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0342, 'grad_norm': 0.07056903094053268, 'learning_rate': 1.48e-05, 'epoch': 1408.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0339, 'grad_norm': 0.09389089047908783, 'learning_rate': 1.4775e-05, 'epoch': 1409.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0339, 'grad_norm': 0.06885074824094772, 'learning_rate': 1.475e-05, 'epoch': 1410.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0342, 'grad_norm': 0.19528941810131073, 'learning_rate': 1.4725e-05, 'epoch': 1411.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0339, 'grad_norm': 0.18470092117786407, 'learning_rate': 1.47e-05, 'epoch': 1412.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0339, 'grad_norm': 0.08261774480342865, 'learning_rate': 1.4675e-05, 'epoch': 1413.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0334, 'grad_norm': 0.08494305610656738, 'learning_rate': 1.465e-05, 'epoch': 1414.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0337, 'grad_norm': 0.05991346016526222, 'learning_rate': 1.4625e-05, 'epoch': 1415.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0337, 'grad_norm': 0.07702601701021194, 'learning_rate': 1.4599999999999999e-05, 'epoch': 1416.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0337, 'grad_norm': 0.05659959837794304, 'learning_rate': 1.4575e-05, 'epoch': 1417.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0339, 'grad_norm': 0.10002455115318298, 'learning_rate': 1.455e-05, 'epoch': 1418.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0337, 'grad_norm': 0.1427823007106781, 'learning_rate': 1.4524999999999999e-05, 'epoch': 1419.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0334, 'grad_norm': 0.0900038331747055, 'learning_rate': 1.45e-05, 'epoch': 1420.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0332, 'grad_norm': 0.0775398463010788, 'learning_rate': 1.4475e-05, 'epoch': 1421.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0337, 'grad_norm': 0.06980782747268677, 'learning_rate': 1.4449999999999999e-05, 'epoch': 1422.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0337, 'grad_norm': 0.07079392671585083, 'learning_rate': 1.4425e-05, 'epoch': 1423.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0337, 'grad_norm': 0.09952662140130997, 'learning_rate': 1.44e-05, 'epoch': 1424.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0334, 'grad_norm': 0.05605548992753029, 'learning_rate': 1.4374999999999999e-05, 'epoch': 1425.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0334, 'grad_norm': 0.07971075922250748, 'learning_rate': 1.435e-05, 'epoch': 1426.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0332, 'grad_norm': 0.0849456936120987, 'learning_rate': 1.4325e-05, 'epoch': 1427.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0334, 'grad_norm': 0.05535108596086502, 'learning_rate': 1.43e-05, 'epoch': 1428.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0334, 'grad_norm': 0.08271471410989761, 'learning_rate': 1.4275e-05, 'epoch': 1429.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0334, 'grad_norm': 0.07895921170711517, 'learning_rate': 1.4249999999999999e-05, 'epoch': 1430.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0332, 'grad_norm': 0.05916828289628029, 'learning_rate': 1.4225e-05, 'epoch': 1431.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0332, 'grad_norm': 0.15983836352825165, 'learning_rate': 1.42e-05, 'epoch': 1432.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0332, 'grad_norm': 0.11888080090284348, 'learning_rate': 1.4174999999999999e-05, 'epoch': 1433.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.033, 'grad_norm': 0.14123231172561646, 'learning_rate': 1.415e-05, 'epoch': 1434.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0332, 'grad_norm': 0.07133132219314575, 'learning_rate': 1.4125e-05, 'epoch': 1435.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.033, 'grad_norm': 0.06565385311841965, 'learning_rate': 1.4099999999999999e-05, 'epoch': 1436.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0332, 'grad_norm': 0.14502888917922974, 'learning_rate': 1.4075e-05, 'epoch': 1437.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0327, 'grad_norm': 0.13519449532032013, 'learning_rate': 1.4050000000000003e-05, 'epoch': 1438.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.033, 'grad_norm': 0.07825282216072083, 'learning_rate': 1.4025000000000002e-05, 'epoch': 1439.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0332, 'grad_norm': 0.10654464364051819, 'learning_rate': 1.4000000000000001e-05, 'epoch': 1440.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0327, 'grad_norm': 0.28453296422958374, 'learning_rate': 1.3975000000000003e-05, 'epoch': 1441.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.033, 'grad_norm': 0.199945330619812, 'learning_rate': 1.3950000000000002e-05, 'epoch': 1442.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0332, 'grad_norm': 0.05699894577264786, 'learning_rate': 1.3925000000000001e-05, 'epoch': 1443.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.033, 'grad_norm': 0.13594771921634674, 'learning_rate': 1.3900000000000002e-05, 'epoch': 1444.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.033, 'grad_norm': 0.07149427384138107, 'learning_rate': 1.3875000000000002e-05, 'epoch': 1445.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0332, 'grad_norm': 0.13251610100269318, 'learning_rate': 1.3850000000000001e-05, 'epoch': 1446.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0332, 'grad_norm': 0.08995863795280457, 'learning_rate': 1.3825000000000002e-05, 'epoch': 1447.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.033, 'grad_norm': 0.09407280385494232, 'learning_rate': 1.3800000000000002e-05, 'epoch': 1448.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0327, 'grad_norm': 0.1073051318526268, 'learning_rate': 1.3775000000000001e-05, 'epoch': 1449.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0327, 'grad_norm': 0.0972982868552208, 'learning_rate': 1.3750000000000002e-05, 'epoch': 1450.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0327, 'grad_norm': 0.05200989171862602, 'learning_rate': 1.3725000000000002e-05, 'epoch': 1451.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0327, 'grad_norm': 0.10918492078781128, 'learning_rate': 1.3700000000000001e-05, 'epoch': 1452.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.033, 'grad_norm': 0.16296063363552094, 'learning_rate': 1.3675000000000002e-05, 'epoch': 1453.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.033, 'grad_norm': 0.09476274251937866, 'learning_rate': 1.3650000000000001e-05, 'epoch': 1454.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.033, 'grad_norm': 0.14325584471225739, 'learning_rate': 1.3625e-05, 'epoch': 1455.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.033, 'grad_norm': 0.13008557260036469, 'learning_rate': 1.3600000000000002e-05, 'epoch': 1456.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.07043969631195068, 'learning_rate': 1.3575000000000001e-05, 'epoch': 1457.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0327, 'grad_norm': 0.15129680931568146, 'learning_rate': 1.3550000000000002e-05, 'epoch': 1458.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.07467663288116455, 'learning_rate': 1.3525000000000002e-05, 'epoch': 1459.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.07599826902151108, 'learning_rate': 1.3500000000000001e-05, 'epoch': 1460.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.11417141556739807, 'learning_rate': 1.3475000000000002e-05, 'epoch': 1461.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.06606926769018173, 'learning_rate': 1.3450000000000002e-05, 'epoch': 1462.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.1059143990278244, 'learning_rate': 1.3425000000000001e-05, 'epoch': 1463.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.07222452759742737, 'learning_rate': 1.3400000000000002e-05, 'epoch': 1464.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0327, 'grad_norm': 0.21113058924674988, 'learning_rate': 1.3375000000000002e-05, 'epoch': 1465.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.19792938232421875, 'learning_rate': 1.3350000000000001e-05, 'epoch': 1466.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.08934023231267929, 'learning_rate': 1.3325000000000002e-05, 'epoch': 1467.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0327, 'grad_norm': 0.19021537899971008, 'learning_rate': 1.3300000000000001e-05, 'epoch': 1468.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.094734787940979, 'learning_rate': 1.3275e-05, 'epoch': 1469.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.11831767857074738, 'learning_rate': 1.3250000000000002e-05, 'epoch': 1470.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.1386331021785736, 'learning_rate': 1.3225000000000001e-05, 'epoch': 1471.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.05303078889846802, 'learning_rate': 1.32e-05, 'epoch': 1472.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.141766756772995, 'learning_rate': 1.3175000000000002e-05, 'epoch': 1473.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.07707476615905762, 'learning_rate': 1.3150000000000001e-05, 'epoch': 1474.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.07770466059446335, 'learning_rate': 1.3125e-05, 'epoch': 1475.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.07268457859754562, 'learning_rate': 1.3100000000000002e-05, 'epoch': 1476.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0327, 'grad_norm': 0.42950576543807983, 'learning_rate': 1.3075000000000001e-05, 'epoch': 1477.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.060499563813209534, 'learning_rate': 1.305e-05, 'epoch': 1478.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.2213393747806549, 'learning_rate': 1.3025000000000002e-05, 'epoch': 1479.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.16605210304260254, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1480.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.13249418139457703, 'learning_rate': 1.2975e-05, 'epoch': 1481.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.12746669352054596, 'learning_rate': 1.2950000000000001e-05, 'epoch': 1482.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.08809831738471985, 'learning_rate': 1.2925e-05, 'epoch': 1483.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.07509952038526535, 'learning_rate': 1.29e-05, 'epoch': 1484.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.19147898256778717, 'learning_rate': 1.2875000000000001e-05, 'epoch': 1485.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.10315005481243134, 'learning_rate': 1.285e-05, 'epoch': 1486.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.16588209569454193, 'learning_rate': 1.2825000000000002e-05, 'epoch': 1487.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.15433020889759064, 'learning_rate': 1.2800000000000001e-05, 'epoch': 1488.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.09773076325654984, 'learning_rate': 1.2775e-05, 'epoch': 1489.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.11207053810358047, 'learning_rate': 1.2750000000000002e-05, 'epoch': 1490.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0312, 'grad_norm': 0.12169717252254486, 'learning_rate': 1.2725000000000001e-05, 'epoch': 1491.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.057846106588840485, 'learning_rate': 1.27e-05, 'epoch': 1492.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.08888314664363861, 'learning_rate': 1.2675000000000001e-05, 'epoch': 1493.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.0664529874920845, 'learning_rate': 1.2650000000000001e-05, 'epoch': 1494.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.07453145831823349, 'learning_rate': 1.2625e-05, 'epoch': 1495.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.09979495406150818, 'learning_rate': 1.2600000000000001e-05, 'epoch': 1496.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.1792050004005432, 'learning_rate': 1.2575e-05, 'epoch': 1497.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0312, 'grad_norm': 0.06304901093244553, 'learning_rate': 1.255e-05, 'epoch': 1498.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.15242987871170044, 'learning_rate': 1.2525000000000001e-05, 'epoch': 1499.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.18376725912094116, 'learning_rate': 1.25e-05, 'epoch': 1500.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0312, 'grad_norm': 0.09142190217971802, 'learning_rate': 1.2475e-05, 'epoch': 1501.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0311, 'grad_norm': 0.07527343928813934, 'learning_rate': 1.2450000000000001e-05, 'epoch': 1502.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.08854477107524872, 'learning_rate': 1.2425e-05, 'epoch': 1503.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0309, 'grad_norm': 0.09074155986309052, 'learning_rate': 1.24e-05, 'epoch': 1504.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.05390014871954918, 'learning_rate': 1.2375000000000001e-05, 'epoch': 1505.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.7223828434944153, 'learning_rate': 1.235e-05, 'epoch': 1506.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.12796930968761444, 'learning_rate': 1.2325e-05, 'epoch': 1507.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0342, 'grad_norm': 2.8568010330200195, 'learning_rate': 1.23e-05, 'epoch': 1508.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.3138482868671417, 'learning_rate': 1.2275e-05, 'epoch': 1509.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.19311608374118805, 'learning_rate': 1.225e-05, 'epoch': 1510.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.17892220616340637, 'learning_rate': 1.2225e-05, 'epoch': 1511.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.4993755519390106, 'learning_rate': 1.22e-05, 'epoch': 1512.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.5093179941177368, 'learning_rate': 1.2175e-05, 'epoch': 1513.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.1676219254732132, 'learning_rate': 1.215e-05, 'epoch': 1514.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.033, 'grad_norm': 0.39411649107933044, 'learning_rate': 1.2125e-05, 'epoch': 1515.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.3808359205722809, 'learning_rate': 1.2100000000000001e-05, 'epoch': 1516.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.19556035101413727, 'learning_rate': 1.2075e-05, 'epoch': 1517.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.1397380530834198, 'learning_rate': 1.205e-05, 'epoch': 1518.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.26475125551223755, 'learning_rate': 1.2025000000000001e-05, 'epoch': 1519.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0327, 'grad_norm': 0.4238133430480957, 'learning_rate': 1.2e-05, 'epoch': 1520.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0322, 'grad_norm': 0.17844587564468384, 'learning_rate': 1.1975e-05, 'epoch': 1521.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.09715595096349716, 'learning_rate': 1.195e-05, 'epoch': 1522.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.12344886362552643, 'learning_rate': 1.1925e-05, 'epoch': 1523.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.15565605461597443, 'learning_rate': 1.19e-05, 'epoch': 1524.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.1921338587999344, 'learning_rate': 1.1875e-05, 'epoch': 1525.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.15604503452777863, 'learning_rate': 1.185e-05, 'epoch': 1526.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0312, 'grad_norm': 0.09516201168298721, 'learning_rate': 1.1825e-05, 'epoch': 1527.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.6375218629837036, 'learning_rate': 1.18e-05, 'epoch': 1528.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.12754565477371216, 'learning_rate': 1.1775e-05, 'epoch': 1529.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.13921572268009186, 'learning_rate': 1.175e-05, 'epoch': 1530.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.18013213574886322, 'learning_rate': 1.1725e-05, 'epoch': 1531.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.43692541122436523, 'learning_rate': 1.1700000000000001e-05, 'epoch': 1532.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0312, 'grad_norm': 0.16652193665504456, 'learning_rate': 1.1675000000000001e-05, 'epoch': 1533.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.2933274805545807, 'learning_rate': 1.1650000000000002e-05, 'epoch': 1534.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.10341335088014603, 'learning_rate': 1.1625000000000001e-05, 'epoch': 1535.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.30141034722328186, 'learning_rate': 1.16e-05, 'epoch': 1536.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.1303909868001938, 'learning_rate': 1.1575000000000002e-05, 'epoch': 1537.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.2085302323102951, 'learning_rate': 1.1550000000000001e-05, 'epoch': 1538.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.11129138618707657, 'learning_rate': 1.1525e-05, 'epoch': 1539.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0312, 'grad_norm': 0.15760959684848785, 'learning_rate': 1.1500000000000002e-05, 'epoch': 1540.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.031, 'grad_norm': 0.1118856817483902, 'learning_rate': 1.1475000000000001e-05, 'epoch': 1541.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0312, 'grad_norm': 0.19659344851970673, 'learning_rate': 1.145e-05, 'epoch': 1542.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0311, 'grad_norm': 0.08123715221881866, 'learning_rate': 1.1425000000000002e-05, 'epoch': 1543.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0311, 'grad_norm': 0.1350221037864685, 'learning_rate': 1.1400000000000001e-05, 'epoch': 1544.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.031, 'grad_norm': 0.1065862849354744, 'learning_rate': 1.1375e-05, 'epoch': 1545.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0312, 'grad_norm': 0.10697013139724731, 'learning_rate': 1.1350000000000001e-05, 'epoch': 1546.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0311, 'grad_norm': 0.10941918939352036, 'learning_rate': 1.1325e-05, 'epoch': 1547.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0311, 'grad_norm': 0.19705873727798462, 'learning_rate': 1.13e-05, 'epoch': 1548.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0312, 'grad_norm': 0.2807956039905548, 'learning_rate': 1.1275000000000001e-05, 'epoch': 1549.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0311, 'grad_norm': 0.09362536668777466, 'learning_rate': 1.125e-05, 'epoch': 1550.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0308, 'grad_norm': 0.10189224034547806, 'learning_rate': 1.1225e-05, 'epoch': 1551.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0306, 'grad_norm': 0.1142888143658638, 'learning_rate': 1.1200000000000001e-05, 'epoch': 1552.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.031, 'grad_norm': 0.06849708408117294, 'learning_rate': 1.1175e-05, 'epoch': 1553.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0304, 'grad_norm': 0.28144001960754395, 'learning_rate': 1.115e-05, 'epoch': 1554.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0306, 'grad_norm': 0.08123624324798584, 'learning_rate': 1.1125000000000001e-05, 'epoch': 1555.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0304, 'grad_norm': 0.0659724548459053, 'learning_rate': 1.11e-05, 'epoch': 1556.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0306, 'grad_norm': 0.09785109013319016, 'learning_rate': 1.1075e-05, 'epoch': 1557.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0309, 'grad_norm': 0.11901194602251053, 'learning_rate': 1.1050000000000001e-05, 'epoch': 1558.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0306, 'grad_norm': 0.1044810488820076, 'learning_rate': 1.1025e-05, 'epoch': 1559.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.38259318470954895, 'learning_rate': 1.1000000000000001e-05, 'epoch': 1560.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0308, 'grad_norm': 0.08320263028144836, 'learning_rate': 1.0975e-05, 'epoch': 1561.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0308, 'grad_norm': 0.22675159573554993, 'learning_rate': 1.095e-05, 'epoch': 1562.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0303, 'grad_norm': 0.15423709154129028, 'learning_rate': 1.0925000000000001e-05, 'epoch': 1563.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0302, 'grad_norm': 0.057013802230358124, 'learning_rate': 1.09e-05, 'epoch': 1564.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0306, 'grad_norm': 0.10878866910934448, 'learning_rate': 1.0875e-05, 'epoch': 1565.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0306, 'grad_norm': 0.09013181924819946, 'learning_rate': 1.0850000000000001e-05, 'epoch': 1566.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0308, 'grad_norm': 0.11086126416921616, 'learning_rate': 1.0825e-05, 'epoch': 1567.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0303, 'grad_norm': 0.10411278158426285, 'learning_rate': 1.08e-05, 'epoch': 1568.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0303, 'grad_norm': 0.08949611335992813, 'learning_rate': 1.0775000000000001e-05, 'epoch': 1569.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0303, 'grad_norm': 0.14434944093227386, 'learning_rate': 1.075e-05, 'epoch': 1570.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0303, 'grad_norm': 0.22115205228328705, 'learning_rate': 1.0725e-05, 'epoch': 1571.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0305, 'grad_norm': 0.32185792922973633, 'learning_rate': 1.0700000000000001e-05, 'epoch': 1572.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0303, 'grad_norm': 0.10137022286653519, 'learning_rate': 1.0675e-05, 'epoch': 1573.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0299, 'grad_norm': 0.1257985383272171, 'learning_rate': 1.065e-05, 'epoch': 1574.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0304, 'grad_norm': 0.17414936423301697, 'learning_rate': 1.0625e-05, 'epoch': 1575.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0302, 'grad_norm': 0.19723057746887207, 'learning_rate': 1.06e-05, 'epoch': 1576.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0308, 'grad_norm': 0.3134707808494568, 'learning_rate': 1.0575e-05, 'epoch': 1577.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0304, 'grad_norm': 0.1807241439819336, 'learning_rate': 1.055e-05, 'epoch': 1578.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0303, 'grad_norm': 0.33570578694343567, 'learning_rate': 1.0525e-05, 'epoch': 1579.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0334, 'grad_norm': 5.117767810821533, 'learning_rate': 1.05e-05, 'epoch': 1580.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0299, 'grad_norm': 0.09315019100904465, 'learning_rate': 1.0475e-05, 'epoch': 1581.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.031, 'grad_norm': 0.27934741973876953, 'learning_rate': 1.045e-05, 'epoch': 1582.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0339, 'grad_norm': 8.141093254089355, 'learning_rate': 1.0425e-05, 'epoch': 1583.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 1.1032342910766602, 'learning_rate': 1.04e-05, 'epoch': 1584.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0306, 'grad_norm': 0.14776434004306793, 'learning_rate': 1.0375e-05, 'epoch': 1585.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0356, 'grad_norm': 6.448035717010498, 'learning_rate': 1.035e-05, 'epoch': 1586.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0586, 'grad_norm': 32.95664978027344, 'learning_rate': 1.0325e-05, 'epoch': 1587.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0327, 'grad_norm': 0.7274344563484192, 'learning_rate': 1.03e-05, 'epoch': 1588.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.30510589480400085, 'learning_rate': 1.0275e-05, 'epoch': 1589.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 1.2491387128829956, 'learning_rate': 1.025e-05, 'epoch': 1590.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.33389168977737427, 'learning_rate': 1.0225e-05, 'epoch': 1591.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0325, 'grad_norm': 0.4483674168586731, 'learning_rate': 1.02e-05, 'epoch': 1592.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.032, 'grad_norm': 0.22998255491256714, 'learning_rate': 1.0175e-05, 'epoch': 1593.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.27395159006118774, 'learning_rate': 1.0150000000000001e-05, 'epoch': 1594.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.28954416513442993, 'learning_rate': 1.0125e-05, 'epoch': 1595.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0311, 'grad_norm': 0.18392205238342285, 'learning_rate': 1.0100000000000002e-05, 'epoch': 1596.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 0.36695683002471924, 'learning_rate': 1.0075000000000001e-05, 'epoch': 1597.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0312, 'grad_norm': 0.3697933852672577, 'learning_rate': 1.005e-05, 'epoch': 1598.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0309, 'grad_norm': 0.19079771637916565, 'learning_rate': 1.0025000000000001e-05, 'epoch': 1599.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0309, 'grad_norm': 0.14313486218452454, 'learning_rate': 1e-05, 'epoch': 1600.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0317, 'grad_norm': 0.2564142048358917, 'learning_rate': 9.975e-06, 'epoch': 1601.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0311, 'grad_norm': 0.15057657659053802, 'learning_rate': 9.950000000000001e-06, 'epoch': 1602.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0308, 'grad_norm': 0.1495533436536789, 'learning_rate': 9.925e-06, 'epoch': 1603.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0308, 'grad_norm': 0.1523968130350113, 'learning_rate': 9.900000000000002e-06, 'epoch': 1604.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0308, 'grad_norm': 0.09531211107969284, 'learning_rate': 9.875000000000001e-06, 'epoch': 1605.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0305, 'grad_norm': 0.07045856863260269, 'learning_rate': 9.85e-06, 'epoch': 1606.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.031, 'grad_norm': 0.40031030774116516, 'learning_rate': 9.825000000000002e-06, 'epoch': 1607.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0309, 'grad_norm': 0.17720697820186615, 'learning_rate': 9.800000000000001e-06, 'epoch': 1608.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0302, 'grad_norm': 0.09233319759368896, 'learning_rate': 9.775e-06, 'epoch': 1609.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0302, 'grad_norm': 0.06743963062763214, 'learning_rate': 9.750000000000002e-06, 'epoch': 1610.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0303, 'grad_norm': 0.11001894623041153, 'learning_rate': 9.725000000000001e-06, 'epoch': 1611.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0304, 'grad_norm': 0.13089072704315186, 'learning_rate': 9.7e-06, 'epoch': 1612.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.03, 'grad_norm': 0.06942341476678848, 'learning_rate': 9.675000000000001e-06, 'epoch': 1613.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0305, 'grad_norm': 0.13674801588058472, 'learning_rate': 9.65e-06, 'epoch': 1614.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0303, 'grad_norm': 0.10150282829999924, 'learning_rate': 9.625e-06, 'epoch': 1615.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0302, 'grad_norm': 0.10106944292783737, 'learning_rate': 9.600000000000001e-06, 'epoch': 1616.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0302, 'grad_norm': 0.18558369576931, 'learning_rate': 9.575e-06, 'epoch': 1617.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0297, 'grad_norm': 0.12763702869415283, 'learning_rate': 9.55e-06, 'epoch': 1618.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.03, 'grad_norm': 0.2276102900505066, 'learning_rate': 9.525000000000001e-06, 'epoch': 1619.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.03, 'grad_norm': 0.12084527313709259, 'learning_rate': 9.5e-06, 'epoch': 1620.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0298, 'grad_norm': 0.17094242572784424, 'learning_rate': 9.475e-06, 'epoch': 1621.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0295, 'grad_norm': 0.13001154363155365, 'learning_rate': 9.450000000000001e-06, 'epoch': 1622.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0294, 'grad_norm': 0.08036082983016968, 'learning_rate': 9.425e-06, 'epoch': 1623.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0297, 'grad_norm': 0.09176648408174515, 'learning_rate': 9.4e-06, 'epoch': 1624.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0297, 'grad_norm': 0.08634976297616959, 'learning_rate': 9.375000000000001e-06, 'epoch': 1625.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0294, 'grad_norm': 0.10391147434711456, 'learning_rate': 9.35e-06, 'epoch': 1626.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0298, 'grad_norm': 0.09660045057535172, 'learning_rate': 9.325e-06, 'epoch': 1627.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0292, 'grad_norm': 0.06974630057811737, 'learning_rate': 9.3e-06, 'epoch': 1628.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0294, 'grad_norm': 0.13222137093544006, 'learning_rate': 9.275e-06, 'epoch': 1629.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0293, 'grad_norm': 0.06675024330615997, 'learning_rate': 9.25e-06, 'epoch': 1630.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0288, 'grad_norm': 0.07200446724891663, 'learning_rate': 9.225e-06, 'epoch': 1631.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0295, 'grad_norm': 0.06667929142713547, 'learning_rate': 9.2e-06, 'epoch': 1632.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0295, 'grad_norm': 0.0785173773765564, 'learning_rate': 9.175000000000001e-06, 'epoch': 1633.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0293, 'grad_norm': 0.09579568356275558, 'learning_rate': 9.15e-06, 'epoch': 1634.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0292, 'grad_norm': 0.10571590065956116, 'learning_rate': 9.125e-06, 'epoch': 1635.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0293, 'grad_norm': 0.1495138704776764, 'learning_rate': 9.100000000000001e-06, 'epoch': 1636.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0293, 'grad_norm': 0.05587809160351753, 'learning_rate': 9.075e-06, 'epoch': 1637.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0292, 'grad_norm': 0.06727618724107742, 'learning_rate': 9.05e-06, 'epoch': 1638.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0293, 'grad_norm': 0.10726068168878555, 'learning_rate': 9.025e-06, 'epoch': 1639.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0292, 'grad_norm': 0.07119882106781006, 'learning_rate': 9e-06, 'epoch': 1640.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0289, 'grad_norm': 0.15727002918720245, 'learning_rate': 8.975e-06, 'epoch': 1641.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0293, 'grad_norm': 0.09468158334493637, 'learning_rate': 8.95e-06, 'epoch': 1642.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0294, 'grad_norm': 0.12037784606218338, 'learning_rate': 8.925e-06, 'epoch': 1643.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0288, 'grad_norm': 0.12972886860370636, 'learning_rate': 8.9e-06, 'epoch': 1644.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0291, 'grad_norm': 0.4309021234512329, 'learning_rate': 8.875e-06, 'epoch': 1645.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0293, 'grad_norm': 0.1335800588130951, 'learning_rate': 8.85e-06, 'epoch': 1646.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0294, 'grad_norm': 0.23492726683616638, 'learning_rate': 8.825e-06, 'epoch': 1647.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0288, 'grad_norm': 0.1052338257431984, 'learning_rate': 8.8e-06, 'epoch': 1648.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0291, 'grad_norm': 0.13490521907806396, 'learning_rate': 8.775e-06, 'epoch': 1649.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0288, 'grad_norm': 0.08217499405145645, 'learning_rate': 8.75e-06, 'epoch': 1650.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0288, 'grad_norm': 0.10119687020778656, 'learning_rate': 8.725e-06, 'epoch': 1651.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0289, 'grad_norm': 0.08567096292972565, 'learning_rate': 8.7e-06, 'epoch': 1652.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0291, 'grad_norm': 0.12286996841430664, 'learning_rate': 8.674999999999999e-06, 'epoch': 1653.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0283, 'grad_norm': 0.0763874500989914, 'learning_rate': 8.65e-06, 'epoch': 1654.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0288, 'grad_norm': 0.10663369297981262, 'learning_rate': 8.625e-06, 'epoch': 1655.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0288, 'grad_norm': 0.10595938563346863, 'learning_rate': 8.599999999999999e-06, 'epoch': 1656.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0289, 'grad_norm': 0.1045956239104271, 'learning_rate': 8.575000000000002e-06, 'epoch': 1657.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0289, 'grad_norm': 0.1101696714758873, 'learning_rate': 8.550000000000001e-06, 'epoch': 1658.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0289, 'grad_norm': 0.11918997019529343, 'learning_rate': 8.525e-06, 'epoch': 1659.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0282, 'grad_norm': 0.09324002265930176, 'learning_rate': 8.500000000000002e-06, 'epoch': 1660.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0288, 'grad_norm': 0.22741243243217468, 'learning_rate': 8.475000000000001e-06, 'epoch': 1661.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0292, 'grad_norm': 0.16207492351531982, 'learning_rate': 8.45e-06, 'epoch': 1662.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0289, 'grad_norm': 0.08672656863927841, 'learning_rate': 8.425000000000001e-06, 'epoch': 1663.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0286, 'grad_norm': 0.06998859345912933, 'learning_rate': 8.400000000000001e-06, 'epoch': 1664.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0289, 'grad_norm': 0.09221488237380981, 'learning_rate': 8.375e-06, 'epoch': 1665.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0283, 'grad_norm': 0.06927058100700378, 'learning_rate': 8.350000000000001e-06, 'epoch': 1666.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0289, 'grad_norm': 0.11194604635238647, 'learning_rate': 8.325e-06, 'epoch': 1667.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0288, 'grad_norm': 0.14936912059783936, 'learning_rate': 8.3e-06, 'epoch': 1668.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0288, 'grad_norm': 0.11808827519416809, 'learning_rate': 8.275000000000001e-06, 'epoch': 1669.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0286, 'grad_norm': 0.09703308343887329, 'learning_rate': 8.25e-06, 'epoch': 1670.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0286, 'grad_norm': 0.0842292532324791, 'learning_rate': 8.225e-06, 'epoch': 1671.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0286, 'grad_norm': 0.2220396250486374, 'learning_rate': 8.200000000000001e-06, 'epoch': 1672.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0283, 'grad_norm': 0.21840083599090576, 'learning_rate': 8.175e-06, 'epoch': 1673.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0286, 'grad_norm': 0.13670629262924194, 'learning_rate': 8.15e-06, 'epoch': 1674.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0281, 'grad_norm': 0.07109319418668747, 'learning_rate': 8.125000000000001e-06, 'epoch': 1675.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0288, 'grad_norm': 0.08557509630918503, 'learning_rate': 8.1e-06, 'epoch': 1676.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0286, 'grad_norm': 0.1219589039683342, 'learning_rate': 8.075000000000001e-06, 'epoch': 1677.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0282, 'grad_norm': 0.24029377102851868, 'learning_rate': 8.050000000000001e-06, 'epoch': 1678.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0283, 'grad_norm': 0.15844695270061493, 'learning_rate': 8.025e-06, 'epoch': 1679.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0284, 'grad_norm': 0.09732667356729507, 'learning_rate': 8.000000000000001e-06, 'epoch': 1680.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0284, 'grad_norm': 0.14842629432678223, 'learning_rate': 7.975e-06, 'epoch': 1681.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0287, 'grad_norm': 0.12642182409763336, 'learning_rate': 7.95e-06, 'epoch': 1682.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0284, 'grad_norm': 0.20957349240779877, 'learning_rate': 7.925000000000001e-06, 'epoch': 1683.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0284, 'grad_norm': 0.11093133687973022, 'learning_rate': 7.9e-06, 'epoch': 1684.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.11040855199098587, 'learning_rate': 7.875e-06, 'epoch': 1685.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.07503968477249146, 'learning_rate': 7.850000000000001e-06, 'epoch': 1686.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0284, 'grad_norm': 0.20924174785614014, 'learning_rate': 7.825e-06, 'epoch': 1687.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0286, 'grad_norm': 0.06810259819030762, 'learning_rate': 7.8e-06, 'epoch': 1688.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0283, 'grad_norm': 0.14508268237113953, 'learning_rate': 7.775000000000001e-06, 'epoch': 1689.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0283, 'grad_norm': 0.07727692276239395, 'learning_rate': 7.75e-06, 'epoch': 1690.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0287, 'grad_norm': 0.16198225319385529, 'learning_rate': 7.725e-06, 'epoch': 1691.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0286, 'grad_norm': 0.10613217949867249, 'learning_rate': 7.7e-06, 'epoch': 1692.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0288, 'grad_norm': 0.7091542482376099, 'learning_rate': 7.675e-06, 'epoch': 1693.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0287, 'grad_norm': 0.34399428963661194, 'learning_rate': 7.65e-06, 'epoch': 1694.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0283, 'grad_norm': 0.12926088273525238, 'learning_rate': 7.625e-06, 'epoch': 1695.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0289, 'grad_norm': 0.35319921374320984, 'learning_rate': 7.6e-06, 'epoch': 1696.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0282, 'grad_norm': 0.17307259142398834, 'learning_rate': 7.575e-06, 'epoch': 1697.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0283, 'grad_norm': 0.07233558595180511, 'learning_rate': 7.55e-06, 'epoch': 1698.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0282, 'grad_norm': 0.15426196157932281, 'learning_rate': 7.525e-06, 'epoch': 1699.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0287, 'grad_norm': 0.18498027324676514, 'learning_rate': 7.5e-06, 'epoch': 1700.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0284, 'grad_norm': 0.2786749303340912, 'learning_rate': 7.4750000000000004e-06, 'epoch': 1701.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0288, 'grad_norm': 0.24618960916996002, 'learning_rate': 7.45e-06, 'epoch': 1702.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0287, 'grad_norm': 0.11027876287698746, 'learning_rate': 7.425e-06, 'epoch': 1703.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0282, 'grad_norm': 0.15097777545452118, 'learning_rate': 7.4e-06, 'epoch': 1704.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0282, 'grad_norm': 0.16206671297550201, 'learning_rate': 7.375e-06, 'epoch': 1705.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0282, 'grad_norm': 0.1473342627286911, 'learning_rate': 7.35e-06, 'epoch': 1706.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0283, 'grad_norm': 0.11712539196014404, 'learning_rate': 7.325e-06, 'epoch': 1707.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0283, 'grad_norm': 0.26053154468536377, 'learning_rate': 7.2999999999999996e-06, 'epoch': 1708.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.12766237556934357, 'learning_rate': 7.275e-06, 'epoch': 1709.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0284, 'grad_norm': 0.20593425631523132, 'learning_rate': 7.25e-06, 'epoch': 1710.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.12394486367702484, 'learning_rate': 7.2249999999999994e-06, 'epoch': 1711.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0281, 'grad_norm': 0.11291798949241638, 'learning_rate': 7.2e-06, 'epoch': 1712.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.08920100331306458, 'learning_rate': 7.175e-06, 'epoch': 1713.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.1013813242316246, 'learning_rate': 7.15e-06, 'epoch': 1714.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0284, 'grad_norm': 0.35768333077430725, 'learning_rate': 7.1249999999999995e-06, 'epoch': 1715.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.25118616223335266, 'learning_rate': 7.1e-06, 'epoch': 1716.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0284, 'grad_norm': 0.318156361579895, 'learning_rate': 7.075e-06, 'epoch': 1717.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0282, 'grad_norm': 0.06388875097036362, 'learning_rate': 7.049999999999999e-06, 'epoch': 1718.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.17661957442760468, 'learning_rate': 7.025000000000001e-06, 'epoch': 1719.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0281, 'grad_norm': 0.20743218064308167, 'learning_rate': 7.000000000000001e-06, 'epoch': 1720.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.054446347057819366, 'learning_rate': 6.975000000000001e-06, 'epoch': 1721.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.11255234479904175, 'learning_rate': 6.950000000000001e-06, 'epoch': 1722.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.09158465266227722, 'learning_rate': 6.925000000000001e-06, 'epoch': 1723.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.08794519305229187, 'learning_rate': 6.900000000000001e-06, 'epoch': 1724.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.13822729885578156, 'learning_rate': 6.875000000000001e-06, 'epoch': 1725.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.18174982070922852, 'learning_rate': 6.8500000000000005e-06, 'epoch': 1726.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.1029469445347786, 'learning_rate': 6.825000000000001e-06, 'epoch': 1727.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0276, 'grad_norm': 0.1849028468132019, 'learning_rate': 6.800000000000001e-06, 'epoch': 1728.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.08305751532316208, 'learning_rate': 6.775000000000001e-06, 'epoch': 1729.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.198261097073555, 'learning_rate': 6.750000000000001e-06, 'epoch': 1730.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0283, 'grad_norm': 0.579565703868866, 'learning_rate': 6.725000000000001e-06, 'epoch': 1731.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.1450188159942627, 'learning_rate': 6.700000000000001e-06, 'epoch': 1732.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.13384020328521729, 'learning_rate': 6.6750000000000005e-06, 'epoch': 1733.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.17676065862178802, 'learning_rate': 6.650000000000001e-06, 'epoch': 1734.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0276, 'grad_norm': 0.14332632720470428, 'learning_rate': 6.625000000000001e-06, 'epoch': 1735.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0276, 'grad_norm': 0.09263138473033905, 'learning_rate': 6.6e-06, 'epoch': 1736.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0286, 'grad_norm': 0.5668694972991943, 'learning_rate': 6.5750000000000006e-06, 'epoch': 1737.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0276, 'grad_norm': 0.1869245022535324, 'learning_rate': 6.550000000000001e-06, 'epoch': 1738.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.12175408750772476, 'learning_rate': 6.525e-06, 'epoch': 1739.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.4049127995967865, 'learning_rate': 6.5000000000000004e-06, 'epoch': 1740.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0283, 'grad_norm': 0.19534331560134888, 'learning_rate': 6.475000000000001e-06, 'epoch': 1741.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.14702698588371277, 'learning_rate': 6.45e-06, 'epoch': 1742.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.09817185252904892, 'learning_rate': 6.425e-06, 'epoch': 1743.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.20745974779129028, 'learning_rate': 6.4000000000000006e-06, 'epoch': 1744.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0281, 'grad_norm': 0.18306848406791687, 'learning_rate': 6.375000000000001e-06, 'epoch': 1745.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0282, 'grad_norm': 0.14986169338226318, 'learning_rate': 6.35e-06, 'epoch': 1746.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0271, 'grad_norm': 0.06283579021692276, 'learning_rate': 6.3250000000000004e-06, 'epoch': 1747.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.17583011090755463, 'learning_rate': 6.300000000000001e-06, 'epoch': 1748.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0275, 'grad_norm': 0.07108130306005478, 'learning_rate': 6.275e-06, 'epoch': 1749.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0275, 'grad_norm': 0.15944835543632507, 'learning_rate': 6.25e-06, 'epoch': 1750.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0282, 'grad_norm': 0.3318237364292145, 'learning_rate': 6.2250000000000005e-06, 'epoch': 1751.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.17111891508102417, 'learning_rate': 6.2e-06, 'epoch': 1752.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.10171183943748474, 'learning_rate': 6.175e-06, 'epoch': 1753.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0281, 'grad_norm': 0.37096548080444336, 'learning_rate': 6.15e-06, 'epoch': 1754.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0281, 'grad_norm': 0.495874285697937, 'learning_rate': 6.125e-06, 'epoch': 1755.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0276, 'grad_norm': 0.07587163895368576, 'learning_rate': 6.1e-06, 'epoch': 1756.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.027, 'grad_norm': 0.10804467648267746, 'learning_rate': 6.075e-06, 'epoch': 1757.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0276, 'grad_norm': 0.21033425629138947, 'learning_rate': 6.0500000000000005e-06, 'epoch': 1758.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.10184940695762634, 'learning_rate': 6.025e-06, 'epoch': 1759.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0295, 'grad_norm': 2.6331870555877686, 'learning_rate': 6e-06, 'epoch': 1760.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.09005124866962433, 'learning_rate': 5.975e-06, 'epoch': 1761.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0271, 'grad_norm': 0.12037960439920425, 'learning_rate': 5.95e-06, 'epoch': 1762.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.03, 'grad_norm': 2.8081135749816895, 'learning_rate': 5.925e-06, 'epoch': 1763.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.3241584002971649, 'learning_rate': 5.9e-06, 'epoch': 1764.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0284, 'grad_norm': 0.21255233883857727, 'learning_rate': 5.875e-06, 'epoch': 1765.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.265240877866745, 'learning_rate': 5.850000000000001e-06, 'epoch': 1766.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0283, 'grad_norm': 0.6063230037689209, 'learning_rate': 5.825000000000001e-06, 'epoch': 1767.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0281, 'grad_norm': 0.49297353625297546, 'learning_rate': 5.8e-06, 'epoch': 1768.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0281, 'grad_norm': 0.1502312421798706, 'learning_rate': 5.775000000000001e-06, 'epoch': 1769.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.18775098025798798, 'learning_rate': 5.750000000000001e-06, 'epoch': 1770.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0315, 'grad_norm': 3.6689600944519043, 'learning_rate': 5.725e-06, 'epoch': 1771.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0281, 'grad_norm': 0.3682865798473358, 'learning_rate': 5.7000000000000005e-06, 'epoch': 1772.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.13171857595443726, 'learning_rate': 5.675000000000001e-06, 'epoch': 1773.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.10193050652742386, 'learning_rate': 5.65e-06, 'epoch': 1774.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.23138613998889923, 'learning_rate': 5.625e-06, 'epoch': 1775.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.14918985962867737, 'learning_rate': 5.600000000000001e-06, 'epoch': 1776.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.18341004848480225, 'learning_rate': 5.575e-06, 'epoch': 1777.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.09500747919082642, 'learning_rate': 5.55e-06, 'epoch': 1778.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.3202964961528778, 'learning_rate': 5.5250000000000005e-06, 'epoch': 1779.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0282, 'grad_norm': 0.39594969153404236, 'learning_rate': 5.500000000000001e-06, 'epoch': 1780.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.24410384893417358, 'learning_rate': 5.475e-06, 'epoch': 1781.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.23034627735614777, 'learning_rate': 5.45e-06, 'epoch': 1782.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.4444173574447632, 'learning_rate': 5.4250000000000006e-06, 'epoch': 1783.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.09321439266204834, 'learning_rate': 5.4e-06, 'epoch': 1784.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.027, 'grad_norm': 0.09770208597183228, 'learning_rate': 5.375e-06, 'epoch': 1785.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.14247600734233856, 'learning_rate': 5.3500000000000004e-06, 'epoch': 1786.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0276, 'grad_norm': 0.2322949767112732, 'learning_rate': 5.325e-06, 'epoch': 1787.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0275, 'grad_norm': 0.13512179255485535, 'learning_rate': 5.3e-06, 'epoch': 1788.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0275, 'grad_norm': 0.10670115053653717, 'learning_rate': 5.275e-06, 'epoch': 1789.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0275, 'grad_norm': 0.15457728505134583, 'learning_rate': 5.25e-06, 'epoch': 1790.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0275, 'grad_norm': 0.12653708457946777, 'learning_rate': 5.225e-06, 'epoch': 1791.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.1539999544620514, 'learning_rate': 5.2e-06, 'epoch': 1792.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0269, 'grad_norm': 0.06252708286046982, 'learning_rate': 5.175e-06, 'epoch': 1793.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0269, 'grad_norm': 0.09212888032197952, 'learning_rate': 5.15e-06, 'epoch': 1794.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.12002779543399811, 'learning_rate': 5.125e-06, 'epoch': 1795.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.21252579987049103, 'learning_rate': 5.1e-06, 'epoch': 1796.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0272, 'grad_norm': 0.09165043383836746, 'learning_rate': 5.0750000000000005e-06, 'epoch': 1797.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0271, 'grad_norm': 0.09589268267154694, 'learning_rate': 5.050000000000001e-06, 'epoch': 1798.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0275, 'grad_norm': 0.11109866946935654, 'learning_rate': 5.025e-06, 'epoch': 1799.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.31061452627182007, 'learning_rate': 5e-06, 'epoch': 1800.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0272, 'grad_norm': 0.11833816766738892, 'learning_rate': 4.975000000000001e-06, 'epoch': 1801.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0271, 'grad_norm': 0.14940345287322998, 'learning_rate': 4.950000000000001e-06, 'epoch': 1802.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0275, 'grad_norm': 0.18057966232299805, 'learning_rate': 4.925e-06, 'epoch': 1803.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.027, 'grad_norm': 0.10761380195617676, 'learning_rate': 4.9000000000000005e-06, 'epoch': 1804.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.07434499263763428, 'learning_rate': 4.875000000000001e-06, 'epoch': 1805.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0271, 'grad_norm': 0.17486998438835144, 'learning_rate': 4.85e-06, 'epoch': 1806.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0267, 'grad_norm': 0.10248740017414093, 'learning_rate': 4.825e-06, 'epoch': 1807.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.4161514937877655, 'learning_rate': 4.800000000000001e-06, 'epoch': 1808.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.3712843060493469, 'learning_rate': 4.775e-06, 'epoch': 1809.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.1080019399523735, 'learning_rate': 4.75e-06, 'epoch': 1810.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.15765982866287231, 'learning_rate': 4.7250000000000005e-06, 'epoch': 1811.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.33367612957954407, 'learning_rate': 4.7e-06, 'epoch': 1812.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0276, 'grad_norm': 0.8648853898048401, 'learning_rate': 4.675e-06, 'epoch': 1813.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.288481205701828, 'learning_rate': 4.65e-06, 'epoch': 1814.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0271, 'grad_norm': 0.11109614372253418, 'learning_rate': 4.625e-06, 'epoch': 1815.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.11929187923669815, 'learning_rate': 4.6e-06, 'epoch': 1816.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0269, 'grad_norm': 0.21685084700584412, 'learning_rate': 4.575e-06, 'epoch': 1817.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0275, 'grad_norm': 0.3716677129268646, 'learning_rate': 4.5500000000000005e-06, 'epoch': 1818.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0271, 'grad_norm': 0.30635881423950195, 'learning_rate': 4.525e-06, 'epoch': 1819.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 2.3889527320861816, 'learning_rate': 4.5e-06, 'epoch': 1820.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0267, 'grad_norm': 0.15247175097465515, 'learning_rate': 4.475e-06, 'epoch': 1821.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.11739489436149597, 'learning_rate': 4.45e-06, 'epoch': 1822.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0272, 'grad_norm': 0.19083009660243988, 'learning_rate': 4.425e-06, 'epoch': 1823.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0271, 'grad_norm': 0.1544007956981659, 'learning_rate': 4.4e-06, 'epoch': 1824.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0275, 'grad_norm': 0.335065633058548, 'learning_rate': 4.375e-06, 'epoch': 1825.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0276, 'grad_norm': 0.2966172695159912, 'learning_rate': 4.35e-06, 'epoch': 1826.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0272, 'grad_norm': 0.29401400685310364, 'learning_rate': 4.325e-06, 'epoch': 1827.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0271, 'grad_norm': 0.12239871919155121, 'learning_rate': 4.2999999999999995e-06, 'epoch': 1828.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0272, 'grad_norm': 0.35521167516708374, 'learning_rate': 4.2750000000000006e-06, 'epoch': 1829.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0267, 'grad_norm': 0.09985706210136414, 'learning_rate': 4.250000000000001e-06, 'epoch': 1830.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 1.7825034856796265, 'learning_rate': 4.225e-06, 'epoch': 1831.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 2.3334076404571533, 'learning_rate': 4.2000000000000004e-06, 'epoch': 1832.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0269, 'grad_norm': 0.16027748584747314, 'learning_rate': 4.175000000000001e-06, 'epoch': 1833.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.21682430803775787, 'learning_rate': 4.15e-06, 'epoch': 1834.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0272, 'grad_norm': 0.21153973042964935, 'learning_rate': 4.125e-06, 'epoch': 1835.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0271, 'grad_norm': 0.2139047235250473, 'learning_rate': 4.1000000000000006e-06, 'epoch': 1836.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0281, 'grad_norm': 0.8040847778320312, 'learning_rate': 4.075e-06, 'epoch': 1837.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0271, 'grad_norm': 0.37166133522987366, 'learning_rate': 4.05e-06, 'epoch': 1838.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0266, 'grad_norm': 0.11115242540836334, 'learning_rate': 4.0250000000000004e-06, 'epoch': 1839.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0266, 'grad_norm': 0.1109141856431961, 'learning_rate': 4.000000000000001e-06, 'epoch': 1840.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0277, 'grad_norm': 0.7902786731719971, 'learning_rate': 3.975e-06, 'epoch': 1841.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0278, 'grad_norm': 0.6046635508537292, 'learning_rate': 3.95e-06, 'epoch': 1842.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0442, 'grad_norm': 24.737943649291992, 'learning_rate': 3.9250000000000005e-06, 'epoch': 1843.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.027, 'grad_norm': 0.14953593909740448, 'learning_rate': 3.9e-06, 'epoch': 1844.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0275, 'grad_norm': 0.18365207314491272, 'learning_rate': 3.875e-06, 'epoch': 1845.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0266, 'grad_norm': 0.10139491409063339, 'learning_rate': 3.85e-06, 'epoch': 1846.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0272, 'grad_norm': 0.20272652804851532, 'learning_rate': 3.825e-06, 'epoch': 1847.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0276, 'grad_norm': 0.26726436614990234, 'learning_rate': 3.8e-06, 'epoch': 1848.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.027, 'grad_norm': 0.23071879148483276, 'learning_rate': 3.775e-06, 'epoch': 1849.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0276, 'grad_norm': 0.7067304253578186, 'learning_rate': 3.75e-06, 'epoch': 1850.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.027, 'grad_norm': 0.25991660356521606, 'learning_rate': 3.725e-06, 'epoch': 1851.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.027, 'grad_norm': 0.160883367061615, 'learning_rate': 3.7e-06, 'epoch': 1852.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0276, 'grad_norm': 0.2908037304878235, 'learning_rate': 3.675e-06, 'epoch': 1853.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0275, 'grad_norm': 0.2743346095085144, 'learning_rate': 3.6499999999999998e-06, 'epoch': 1854.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.028, 'grad_norm': 0.47366857528686523, 'learning_rate': 3.625e-06, 'epoch': 1855.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0281, 'grad_norm': 0.6030586361885071, 'learning_rate': 3.6e-06, 'epoch': 1856.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.1418781578540802, 'learning_rate': 3.575e-06, 'epoch': 1857.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.17589060962200165, 'learning_rate': 3.55e-06, 'epoch': 1858.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0269, 'grad_norm': 0.08504030108451843, 'learning_rate': 3.5249999999999997e-06, 'epoch': 1859.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.22744396328926086, 'learning_rate': 3.5000000000000004e-06, 'epoch': 1860.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0275, 'grad_norm': 0.29271697998046875, 'learning_rate': 3.4750000000000006e-06, 'epoch': 1861.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.027, 'grad_norm': 0.16736793518066406, 'learning_rate': 3.4500000000000004e-06, 'epoch': 1862.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0271, 'grad_norm': 0.26893776655197144, 'learning_rate': 3.4250000000000002e-06, 'epoch': 1863.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.19344189763069153, 'learning_rate': 3.4000000000000005e-06, 'epoch': 1864.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0271, 'grad_norm': 0.17987221479415894, 'learning_rate': 3.3750000000000003e-06, 'epoch': 1865.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0272, 'grad_norm': 0.19512447714805603, 'learning_rate': 3.3500000000000005e-06, 'epoch': 1866.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0273, 'grad_norm': 0.2399817556142807, 'learning_rate': 3.3250000000000004e-06, 'epoch': 1867.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0266, 'grad_norm': 0.11365007609128952, 'learning_rate': 3.3e-06, 'epoch': 1868.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.1300642043352127, 'learning_rate': 3.2750000000000004e-06, 'epoch': 1869.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0267, 'grad_norm': 0.21653418242931366, 'learning_rate': 3.2500000000000002e-06, 'epoch': 1870.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.027, 'grad_norm': 0.24550408124923706, 'learning_rate': 3.225e-06, 'epoch': 1871.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.09455780684947968, 'learning_rate': 3.2000000000000003e-06, 'epoch': 1872.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.1838407814502716, 'learning_rate': 3.175e-06, 'epoch': 1873.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0269, 'grad_norm': 0.18590572476387024, 'learning_rate': 3.1500000000000003e-06, 'epoch': 1874.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.07139823585748672, 'learning_rate': 3.125e-06, 'epoch': 1875.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0266, 'grad_norm': 0.10956729203462601, 'learning_rate': 3.1e-06, 'epoch': 1876.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0267, 'grad_norm': 0.09975671768188477, 'learning_rate': 3.075e-06, 'epoch': 1877.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.1546364724636078, 'learning_rate': 3.05e-06, 'epoch': 1878.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0266, 'grad_norm': 0.17062760889530182, 'learning_rate': 3.0250000000000003e-06, 'epoch': 1879.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.11607631295919418, 'learning_rate': 3e-06, 'epoch': 1880.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.12192908674478531, 'learning_rate': 2.975e-06, 'epoch': 1881.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0266, 'grad_norm': 0.11202505230903625, 'learning_rate': 2.95e-06, 'epoch': 1882.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0267, 'grad_norm': 0.06736111640930176, 'learning_rate': 2.9250000000000004e-06, 'epoch': 1883.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.09811057150363922, 'learning_rate': 2.9e-06, 'epoch': 1884.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.1343996226787567, 'learning_rate': 2.8750000000000004e-06, 'epoch': 1885.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.2279784381389618, 'learning_rate': 2.8500000000000002e-06, 'epoch': 1886.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0266, 'grad_norm': 0.07981094717979431, 'learning_rate': 2.825e-06, 'epoch': 1887.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.08465379476547241, 'learning_rate': 2.8000000000000003e-06, 'epoch': 1888.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0266, 'grad_norm': 0.07010342180728912, 'learning_rate': 2.775e-06, 'epoch': 1889.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0267, 'grad_norm': 0.07246331125497818, 'learning_rate': 2.7500000000000004e-06, 'epoch': 1890.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0267, 'grad_norm': 0.1503191888332367, 'learning_rate': 2.725e-06, 'epoch': 1891.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.12437152862548828, 'learning_rate': 2.7e-06, 'epoch': 1892.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.6184778213500977, 'learning_rate': 2.6750000000000002e-06, 'epoch': 1893.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.027, 'grad_norm': 0.14890186488628387, 'learning_rate': 2.65e-06, 'epoch': 1894.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.14747144281864166, 'learning_rate': 2.625e-06, 'epoch': 1895.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.10097230225801468, 'learning_rate': 2.6e-06, 'epoch': 1896.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.1574963480234146, 'learning_rate': 2.575e-06, 'epoch': 1897.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0269, 'grad_norm': 0.16615964472293854, 'learning_rate': 2.55e-06, 'epoch': 1898.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.14659257233142853, 'learning_rate': 2.5250000000000004e-06, 'epoch': 1899.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.08336188644170761, 'learning_rate': 2.5e-06, 'epoch': 1900.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0266, 'grad_norm': 0.11945731937885284, 'learning_rate': 2.4750000000000004e-06, 'epoch': 1901.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.1430152803659439, 'learning_rate': 2.4500000000000003e-06, 'epoch': 1902.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.10443655401468277, 'learning_rate': 2.425e-06, 'epoch': 1903.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.05918215960264206, 'learning_rate': 2.4000000000000003e-06, 'epoch': 1904.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0266, 'grad_norm': 0.11348651349544525, 'learning_rate': 2.375e-06, 'epoch': 1905.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.08483394980430603, 'learning_rate': 2.35e-06, 'epoch': 1906.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0267, 'grad_norm': 0.21005752682685852, 'learning_rate': 2.325e-06, 'epoch': 1907.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.17762942612171173, 'learning_rate': 2.3e-06, 'epoch': 1908.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.18788576126098633, 'learning_rate': 2.2750000000000002e-06, 'epoch': 1909.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.1349932849407196, 'learning_rate': 2.25e-06, 'epoch': 1910.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.09456437826156616, 'learning_rate': 2.225e-06, 'epoch': 1911.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.07061820477247238, 'learning_rate': 2.2e-06, 'epoch': 1912.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.13486939668655396, 'learning_rate': 2.175e-06, 'epoch': 1913.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.11584611237049103, 'learning_rate': 2.1499999999999997e-06, 'epoch': 1914.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.14267736673355103, 'learning_rate': 2.1250000000000004e-06, 'epoch': 1915.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.11140066385269165, 'learning_rate': 2.1000000000000002e-06, 'epoch': 1916.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.14262722432613373, 'learning_rate': 2.075e-06, 'epoch': 1917.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.1716662049293518, 'learning_rate': 2.0500000000000003e-06, 'epoch': 1918.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.12369739264249802, 'learning_rate': 2.025e-06, 'epoch': 1919.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.1125226691365242, 'learning_rate': 2.0000000000000003e-06, 'epoch': 1920.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.17923271656036377, 'learning_rate': 1.975e-06, 'epoch': 1921.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.10898524522781372, 'learning_rate': 1.95e-06, 'epoch': 1922.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.11543191224336624, 'learning_rate': 1.925e-06, 'epoch': 1923.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.07840318232774734, 'learning_rate': 1.9e-06, 'epoch': 1924.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0259, 'grad_norm': 0.07870715856552124, 'learning_rate': 1.875e-06, 'epoch': 1925.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.1751900464296341, 'learning_rate': 1.85e-06, 'epoch': 1926.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0259, 'grad_norm': 0.07268025726079941, 'learning_rate': 1.8249999999999999e-06, 'epoch': 1927.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.07900591194629669, 'learning_rate': 1.8e-06, 'epoch': 1928.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.1448940932750702, 'learning_rate': 1.775e-06, 'epoch': 1929.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0259, 'grad_norm': 0.18113161623477936, 'learning_rate': 1.7500000000000002e-06, 'epoch': 1930.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.10134919732809067, 'learning_rate': 1.7250000000000002e-06, 'epoch': 1931.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.08759766072034836, 'learning_rate': 1.7000000000000002e-06, 'epoch': 1932.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.14782555401325226, 'learning_rate': 1.6750000000000003e-06, 'epoch': 1933.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.14745508134365082, 'learning_rate': 1.65e-06, 'epoch': 1934.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.449470192193985, 'learning_rate': 1.6250000000000001e-06, 'epoch': 1935.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.08895069360733032, 'learning_rate': 1.6000000000000001e-06, 'epoch': 1936.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0258, 'grad_norm': 0.09409104287624359, 'learning_rate': 1.5750000000000002e-06, 'epoch': 1937.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.10465093702077866, 'learning_rate': 1.55e-06, 'epoch': 1938.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.07508104294538498, 'learning_rate': 1.525e-06, 'epoch': 1939.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.12551075220108032, 'learning_rate': 1.5e-06, 'epoch': 1940.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.08684850484132767, 'learning_rate': 1.475e-06, 'epoch': 1941.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.26825660467147827, 'learning_rate': 1.45e-06, 'epoch': 1942.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0259, 'grad_norm': 0.11009228229522705, 'learning_rate': 1.4250000000000001e-06, 'epoch': 1943.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0259, 'grad_norm': 0.11224422603845596, 'learning_rate': 1.4000000000000001e-06, 'epoch': 1944.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.09638779610395432, 'learning_rate': 1.3750000000000002e-06, 'epoch': 1945.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0259, 'grad_norm': 0.0781392827630043, 'learning_rate': 1.35e-06, 'epoch': 1946.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.1371145248413086, 'learning_rate': 1.325e-06, 'epoch': 1947.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.11818578094244003, 'learning_rate': 1.3e-06, 'epoch': 1948.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.10691948235034943, 'learning_rate': 1.275e-06, 'epoch': 1949.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.06827953457832336, 'learning_rate': 1.25e-06, 'epoch': 1950.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.09132787585258484, 'learning_rate': 1.2250000000000001e-06, 'epoch': 1951.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0259, 'grad_norm': 0.1893148124217987, 'learning_rate': 1.2000000000000002e-06, 'epoch': 1952.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.156972274184227, 'learning_rate': 1.175e-06, 'epoch': 1953.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.1431649625301361, 'learning_rate': 1.15e-06, 'epoch': 1954.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0266, 'grad_norm': 0.19349852204322815, 'learning_rate': 1.125e-06, 'epoch': 1955.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.28573712706565857, 'learning_rate': 1.1e-06, 'epoch': 1956.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.14835141599178314, 'learning_rate': 1.0749999999999999e-06, 'epoch': 1957.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.06066839024424553, 'learning_rate': 1.0500000000000001e-06, 'epoch': 1958.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0259, 'grad_norm': 0.1314309537410736, 'learning_rate': 1.0250000000000001e-06, 'epoch': 1959.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.13302671909332275, 'learning_rate': 1.0000000000000002e-06, 'epoch': 1960.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.09828196465969086, 'learning_rate': 9.75e-07, 'epoch': 1961.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0258, 'grad_norm': 0.1404898315668106, 'learning_rate': 9.5e-07, 'epoch': 1962.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.1180754080414772, 'learning_rate': 9.25e-07, 'epoch': 1963.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.22799672186374664, 'learning_rate': 9e-07, 'epoch': 1964.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.17815649509429932, 'learning_rate': 8.750000000000001e-07, 'epoch': 1965.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.10651526600122452, 'learning_rate': 8.500000000000001e-07, 'epoch': 1966.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.11709987372159958, 'learning_rate': 8.25e-07, 'epoch': 1967.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0258, 'grad_norm': 0.12337256222963333, 'learning_rate': 8.000000000000001e-07, 'epoch': 1968.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.1107262521982193, 'learning_rate': 7.75e-07, 'epoch': 1969.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0265, 'grad_norm': 0.1593112349510193, 'learning_rate': 7.5e-07, 'epoch': 1970.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.062461577355861664, 'learning_rate': 7.25e-07, 'epoch': 1971.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.1632167100906372, 'learning_rate': 7.000000000000001e-07, 'epoch': 1972.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0259, 'grad_norm': 0.13518869876861572, 'learning_rate': 6.75e-07, 'epoch': 1973.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.09486188739538193, 'learning_rate': 6.5e-07, 'epoch': 1974.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.07818252593278885, 'learning_rate': 6.25e-07, 'epoch': 1975.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0259, 'grad_norm': 0.0815672054886818, 'learning_rate': 6.000000000000001e-07, 'epoch': 1976.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0258, 'grad_norm': 0.1048148050904274, 'learning_rate': 5.75e-07, 'epoch': 1977.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0259, 'grad_norm': 0.055014170706272125, 'learning_rate': 5.5e-07, 'epoch': 1978.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0259, 'grad_norm': 0.06661725789308548, 'learning_rate': 5.250000000000001e-07, 'epoch': 1979.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.11590518802404404, 'learning_rate': 5.000000000000001e-07, 'epoch': 1980.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.13840176165103912, 'learning_rate': 4.75e-07, 'epoch': 1981.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.07706907391548157, 'learning_rate': 4.5e-07, 'epoch': 1982.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.090004101395607, 'learning_rate': 4.2500000000000006e-07, 'epoch': 1983.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.13153183460235596, 'learning_rate': 4.0000000000000003e-07, 'epoch': 1984.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.11117132008075714, 'learning_rate': 3.75e-07, 'epoch': 1985.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0262, 'grad_norm': 0.141654834151268, 'learning_rate': 3.5000000000000004e-07, 'epoch': 1986.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.09138894081115723, 'learning_rate': 3.25e-07, 'epoch': 1987.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0266, 'grad_norm': 0.34772226214408875, 'learning_rate': 3.0000000000000004e-07, 'epoch': 1988.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.11525920778512955, 'learning_rate': 2.75e-07, 'epoch': 1989.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0259, 'grad_norm': 0.29194721579551697, 'learning_rate': 2.5000000000000004e-07, 'epoch': 1990.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0264, 'grad_norm': 0.18181632459163666, 'learning_rate': 2.25e-07, 'epoch': 1991.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.11591286957263947, 'learning_rate': 2.0000000000000002e-07, 'epoch': 1992.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.026, 'grad_norm': 0.13936172425746918, 'learning_rate': 1.7500000000000002e-07, 'epoch': 1993.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.14417321979999542, 'learning_rate': 1.5000000000000002e-07, 'epoch': 1994.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0256, 'grad_norm': 0.12338459491729736, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1995.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.15032295882701874, 'learning_rate': 1.0000000000000001e-07, 'epoch': 1996.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0258, 'grad_norm': 0.1120944619178772, 'learning_rate': 7.500000000000001e-08, 'epoch': 1997.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0256, 'grad_norm': 0.17725245654582977, 'learning_rate': 5.0000000000000004e-08, 'epoch': 1998.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0261, 'grad_norm': 0.07203240692615509, 'learning_rate': 2.5000000000000002e-08, 'epoch': 1999.0}
input_ids shape:  torch.Size([1, 243])
prompt_answer_ids shape:  torch.Size([1, 133])
labels shape:  torch.Size([1, 133])
num_segments:  1
segment_length:  243
prompt_answer_embs shape:  torch.Size([1, 133, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 243
segment_input_ids shape:  torch.Size([1, 243])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 244])
mem_flag shape:  torch.Size([1, 244])
segment_input_embedding shape:  torch.Size([1, 244, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 244, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 133])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 133, 128256])
effective_logits shape:  torch.Size([132, 128256])
target_ids shape:  torch.Size([132])
{'loss': 0.0258, 'grad_norm': 0.13413642346858978, 'learning_rate': 0.0, 'epoch': 2000.0}
{'train_runtime': 455.7597, 'train_samples_per_second': 4.388, 'train_steps_per_second': 4.388, 'train_loss': 0.09623345947265625, 'epoch': 2000.0}
***** train metrics *****
  epoch                    =     2000.0
  total_flos               =        0GF
  train_loss               =     0.0962
  train_runtime            = 0:07:35.75
  train_samples_per_second =      4.388
  train_steps_per_second   =      4.388
input_ids shape:  torch.Size([1, 131])
prompt_answer_ids shape:  torch.Size([1, 85])
labels shape:  torch.Size([1, 85])
num_segments:  1
segment_length:  131
prompt_answer_embs shape:  torch.Size([1, 85, 2048])
max_compressed_length:  1
compress_outputs shape:  torch.Size([1, 2048])
===============Segment 0=======================
start_idx: 0 | end_idx: 131
segment_input_ids shape:  torch.Size([1, 131])
append_sequence shape:  torch.Size([1, 1])
segment_input_ids shape after concat:  torch.Size([1, 132])
mem_flag shape:  torch.Size([1, 132])
segment_input_embedding shape:  torch.Size([1, 132, 2048])
Populated segment_input_embedding memory tokens
segment_compress_outputs (last hidden state) shape:  torch.Size([1, 132, 2048])
Filled in compressed memory for memory segment 0.
===============Segment 0 END=======================
decoder_mem_flag shape:  torch.Size([1, 85])
Populated decoder memory tokens with compressed outputs.
Populated decoder special memory tokens.
decoder_outputs logits shape:  torch.Size([1, 85, 128261])
effective_logits shape:  torch.Size([84, 128261])
target_ids shape:  torch.Size([84])
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 791.68it/s]
***** eval metrics *****
  epoch                   =     2000.0
  eval_loss               =     2.7031
  eval_runtime            = 0:00:00.08
  eval_samples_per_second =     11.396
  eval_steps_per_second   =     11.396
Freezing the decoder...
trainable params: 13639680 || all params: 2485278720 || trainable%: 0.5488189268365039
Enabling gradient checkpointing...
Loading trained checkpoint from ./output
Running inference
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.06s/it]
=========================== START ============================
Current line:  Four adults with 32 teeth went to the dentist for a checkup after realizing they were having severe tooth pain. They were found to have different numbers of damaged teeth, and each person had some teeth removed. The first person had 1/4 of all his teeth removed, and the second person had 3/8 of his teeth removed, the third person had half of his teeth removed, while the last person only had 4 teeth removed. What's the total number of teeth removed at the dental clinic?
input_ids shape:  torch.Size([1, 105])
memory_slots shape:  torch.Size([1, 2048])
prompt_ids shape:  torch.Size([1, 1])
prompt_answer_embs shape:  torch.Size([1, 1, 2048])
decoder_input_embeddings shape:  torch.Size([1, 2, 2048])
output shape:  torch.Size([1, 2, 2048])
=========================== END ============================
Four adults with 32 teeth went to the dentist for a checkup after realizing they were having severe tooth pain. They were found to have different numbers of damaged teeth, and each person had some teeth removed. The first person had 1/4 of all his teeth removed, and the second person had 3/8 of his teeth removed, the third person had half of his teeth removed, while the last person only had 4 teeth removed. What's the total number of teeth removed at the dental clinic?
<|begin_of_text|>def count_unique_elements(my_list)  // count the number of unique elements in a list  // my_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  // count the number of unique elements in a list  // count_unique_elements([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])  // count the number of unique elements in a list  // count_unique_elements([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])  // count the number of unique elements in a list  // count_unique_elements([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])  // count the number of unique elements in a list  // count_unique_elements([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])  // count the number of unique elements in a list  // count_unique_elements([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])  // count the number of unique elements in a list  // count_unique_elements([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])  // count the number of unique elements in a list  // count_unique_elements([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])  // count the number of unique elements in a list  // count_unique_elements([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])  // count the number of unique elements in a list  // count_unique_elements([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])  // count the number of unique elements in a list  // count_unique_elements([1, 2, 3, 4, 5, 6, 7, 8, 9,
=========================================================================
